<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第五章：多模态任务实验设计</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">LLM 后训练实验设计指南</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第一章：后训练基础理论</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第二章：实验代码基础设施</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第三章：数据工程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第四章：纯语言任务实验设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第五章：多模态任务实验设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第六章：强化学习与人类反馈</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第七章：训练循环与迭代优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第八章：评估与基准测试</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第九章：生产部署与监控</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十章：案例研究与最佳实践</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="_1">第五章：多模态任务实验设计</h1>
<p>本章深入探讨多模态大语言模型的后训练实验设计，涵盖视觉、音频、视频等模态与语言的融合方法。我们将系统学习如何设计跨模态对齐实验、处理模态间的异质性挑战，以及构建统一的多模态表示空间。通过本章学习，您将掌握构建生产级多模态模型的完整实验流程。</p>
<h2 id="51-">5.1 视觉-语言对齐基础</h2>
<p>视觉-语言对齐是多模态模型的核心挑战。不同于文本的离散表示，视觉信号是连续的高维数据，如何在保持语义一致性的同时实现高效对齐，是实验设计的关键考量。</p>
<h3 id="511">5.1.1 对齐范式演进</h3>
<p>多模态对齐经历了从简单特征拼接到深度语义融合的演进过程：</p>
<p><strong>早期方法（2015-2018）</strong>：</p>
<ul>
<li>特征级联：简单将 CNN 特征与词嵌入拼接</li>
<li>双塔架构：独立编码后计算相似度</li>
<li>问题：模态间隙（modality gap）严重，语义对齐效果差</li>
</ul>
<p><strong>中期发展（2018-2021）</strong>：</p>
<ul>
<li>注意力机制引入：ViLBERT、LXMERT 等使用 co-attention</li>
<li>预训练任务设计：Masked Language Modeling + Masked Region Modeling</li>
<li>突破：CLIP 的对比学习范式，实现零样本迁移</li>
</ul>
<p><strong>当前前沿（2021-2025）</strong>：</p>
<ul>
<li>统一架构：Flamingo、BLIP-2 的 Q-Former 设计</li>
<li>大规模预训练：LAION-5B 等十亿级数据集</li>
<li>效率优化：FLIP 的稀疏采样，节省 2/3 计算</li>
</ul>
<div class="codehilite"><pre><span></span><code>演进路径：
Feature Concat → Dual Encoder → Cross Attention → Unified Architecture
     ↓              ↓                ↓                    ↓
  低效对齐      模态隔离         计算密集           统一表示空间
</code></pre></div>

<h3 id="512-clip">5.1.2 CLIP 及其变体</h3>
<p>CLIP（Contrastive Language-Image Pre-training）奠定了现代视觉-语言对齐的基础：</p>
<p><strong>核心设计</strong>：</p>
<div class="codehilite"><pre><span></span><code>Image Encoder: ResNet/ViT → I_emb ∈ R^d
Text Encoder: Transformer → T_emb ∈ R^d
对齐目标: maximize cos(I_emb, T_emb) for matched pairs
</code></pre></div>

<p><strong>关键创新</strong>：</p>
<ol>
<li><strong>对称损失</strong>：图像→文本 和 文本→图像 双向对比</li>
<li><strong>温度参数</strong>：τ = 0.07，控制分布锐度</li>
<li><strong>大批量训练</strong>：32K batch size，充分利用负样本</li>
</ol>
<p><strong>CLIP 变体对比</strong>：</p>
<p>| 模型 | 创新点 | 性能提升 | 计算成本 |</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>创新点</th>
<th>性能提升</th>
<th>计算成本</th>
</tr>
</thead>
<tbody>
<tr>
<td>CLIP</td>
<td>基础对比学习</td>
<td>Baseline</td>
<td>1.0x</td>
</tr>
<tr>
<td>ALIGN</td>
<td>噪声数据训练</td>
<td>+2% Zero-shot</td>
<td>1.2x</td>
</tr>
<tr>
<td>FLIP</td>
<td>随机 Mask 50% patches</td>
<td>-1% 精度，-2.5x 训练时间</td>
<td>0.4x</td>
</tr>
<tr>
<td>OpenCLIP</td>
<td>扩展到 ViT-G/14</td>
<td>+5% ImageNet</td>
<td>3.0x</td>
</tr>
<tr>
<td>EVA-CLIP</td>
<td>改进初始化与优化器</td>
<td>+3% 均值精度</td>
<td>1.1x</td>
</tr>
</tbody>
</table>
<p><strong>实验设计要点</strong>：</p>
<ul>
<li>数据质量 vs 数量权衡：ALIGN 证明 1B 噪声数据可行</li>
<li>编码器容量分配：视觉编码器通常需要更大容量</li>
<li>训练稳定性：梯度累积 + mixed precision 关键</li>
</ul>
<h3 id="513">5.1.3 对比学习损失设计</h3>
<p>对比学习损失是多模态对齐的核心，其设计直接影响模型性能：</p>
<p><strong>InfoNCE 损失</strong>：
$$\mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(s_{ii}/\tau)}{\sum_{j=1}^{N} \exp(s_{ij}/\tau)}$$
其中 $s_{ij} = \text{cos}(f_I(x_i), f_T(t_j))$ 为相似度得分。</p>
<p><strong>改进方向</strong>：</p>
<ol>
<li><strong>难负样本挖掘</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 伪代码</span>
<span class="n">hard_negatives</span> <span class="o">=</span> <span class="n">top_k</span><span class="p">(</span><span class="n">similarity_scores</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">exclude_positive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">pos_score</span><span class="o">/</span><span class="n">τ</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">pos_score</span><span class="o">/</span><span class="n">τ</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">neg</span><span class="o">/</span><span class="n">τ</span><span class="p">)</span> <span class="k">for</span> <span class="n">neg</span> <span class="ow">in</span> <span class="n">hard_negatives</span><span class="p">)))</span>
</code></pre></div>

<ol start="2">
<li>
<p><strong>多粒度对比</strong>：
- Global：整图-整句对比
- Regional：区域-短语对比<br />
- Patch：图块-词汇对比</p>
</li>
<li>
<p><strong>软标签对比</strong>：
考虑标注不确定性，使用软标签：
$$\mathcal{L}_{\text{soft}} = -\sum_{j} y_j \log p_j$$
其中 $y_j$ 为软标签分布。</p>
</li>
</ol>
<p><strong>实验技巧</strong>：</p>
<ul>
<li>温度参数调优：τ ∈ [0.01, 0.1]，过小导致梯度爆炸</li>
<li>批量大小效应：批量翻倍，性能提升约 1-2%</li>
<li>负样本队列：维护动态负样本 bank，提升多样性</li>
</ul>
<h3 id="514">5.1.4 负样本采样策略</h3>
<p>负样本质量直接决定对比学习效果：</p>
<p><strong>采样策略对比</strong>：</p>
<div class="codehilite"><pre><span></span><code>随机采样：
├── 优点：实现简单，无偏
└── 缺点：包含大量简单负样本，学习效率低

难例挖掘：
├── 优点：加速收敛，提升区分能力
└── 缺点：可能过拟合，需要 curriculum

混合策略：
├── 80% 随机 + 20% 难例
└── 平衡探索与利用
</code></pre></div>

<p><strong>高级采样技术</strong>：</p>
<ol>
<li><strong>跨批次负样本</strong>（MoCo 风格）：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">NegativeBank</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">65536</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">)))</span>
</code></pre></div>

<ol start="2">
<li>
<p><strong>语义层次采样</strong>：
- Level 1：完全无关（猫图片 vs 汽车描述）
- Level 2：领域相关（狗图片 vs 猫描述）<br />
- Level 3：细粒度区分（哈士奇 vs 阿拉斯加描述）</p>
</li>
<li>
<p><strong>动态难度调整</strong>：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code>训练初期：70% easy + 30% hard
训练中期：50% easy + 50% hard  
训练后期：30% easy + 70% hard
</code></pre></div>

<p><strong>实验建议</strong>：</p>
<ul>
<li>监控负样本相似度分布，避免 collapse</li>
<li>使用 gradient accumulation 模拟大批量</li>
<li>定期评估 retrieval metrics，不只看 loss</li>
</ul>
<h2 id="52">5.2 图像理解与生成的统一建模</h2>
<p>统一建模是多模态领域的圣杯——用单一模型同时处理理解和生成任务。这不仅简化了系统架构，还能实现任务间的知识迁移。</p>
<h3 id="521-">5.2.1 编码器-解码器架构设计</h3>
<p>现代统一架构需要平衡理解的精确性和生成的多样性：</p>
<p><strong>架构演进</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="err">传统分离式：</span>
<span class="n">Vision</span><span class="w"> </span><span class="n">Encoder</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">Understanding</span><span class="w"> </span><span class="n">Tasks</span>
<span class="n">Text</span><span class="w"> </span><span class="n">Decoder</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">Generation</span><span class="w"> </span><span class="n">Tasks</span>
<span class="err">问题：任务孤立，无法共享表示</span>

<span class="err">早期统一（</span><span class="n">DALL</span><span class="o">-</span><span class="n">E</span><span class="err">）：</span>
<span class="n">Text</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Image</span><span class="w"> </span><span class="n">Tokens</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">Autoregressive</span><span class="w"> </span><span class="n">Transformer</span>
<span class="err">问题：图像离散化损失严重</span>

<span class="err">当前主流（</span><span class="n">Flamingo</span><span class="o">/</span><span class="n">BLIP</span><span class="o">-</span><span class="mh">2</span><span class="err">）：</span>
<span class="n">Frozen</span><span class="w"> </span><span class="n">Vision</span><span class="w"> </span><span class="n">Encoder</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">Perceiver</span><span class="w"> </span><span class="n">Resampler</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">LLM</span><span class="w"> </span><span class="n">Decoder</span>
<span class="err">优势：保留预训练权重，高效适配</span>
</code></pre></div>

<p><strong>关键设计选择</strong>：</p>
<ol>
<li>
<p><strong>Vision Encoder 选择</strong>：
   - CLIP ViT-L/14：平衡性能与效率
   - EVA-02 ViT-E：极致性能，5B 参数
   - ConvNeXt V2：更好的局部特征</p>
</li>
<li>
<p><strong>连接层设计</strong>：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">PerceiverResampler</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_latents</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latents</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_latents</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_attend</span> <span class="o">=</span> <span class="n">CrossAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_attend</span> <span class="o">=</span> <span class="n">SelfAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latents</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depth</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attend</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">visual_features</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attend</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">x</span>  <span class="c1"># [64, 1024] 固定长度输出</span>
</code></pre></div>

<ol start="3">
<li><strong>Decoder 适配</strong>：
   - Prefix Tuning：视觉特征作为 prefix
   - Adapter Layers：在 FFN 后插入适配层
   - LoRA：低秩适配，参数效率最高</li>
</ol>
<p><strong>实验技巧</strong>：</p>
<ul>
<li>冻结策略：先冻结 encoder，后期联合微调</li>
<li>学习率调度：encoder 1e-5, connector 1e-4, decoder 2e-5</li>
<li>数据配比：理解:生成 = 3:1 初期，逐步平衡</li>
</ul>
<h3 id="522-vs">5.2.2 自回归 vs 扩散模型集成</h3>
<p>两大生成范式的优劣与集成策略：</p>
<p><strong>范式对比</strong>：</p>
<p>| 特性 | 自回归（AR） | 扩散模型（DM） | 混合方案 |</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>自回归（AR）</th>
<th>扩散模型（DM）</th>
<th>混合方案</th>
</tr>
</thead>
<tbody>
<tr>
<td>生成质量</td>
<td>中等</td>
<td>高</td>
<td>高</td>
</tr>
<tr>
<td>推理速度</td>
<td>快（单次）</td>
<td>慢（多步）</td>
<td>中等</td>
</tr>
<tr>
<td>可控性</td>
<td>强（token级）</td>
<td>弱（全局）</td>
<td>强</td>
</tr>
<tr>
<td>训练稳定性</td>
<td>高</td>
<td>中等</td>
<td>中等</td>
</tr>
<tr>
<td>内存需求</td>
<td>低</td>
<td>高</td>
<td>高</td>
</tr>
</tbody>
</table>
<p><strong>集成架构</strong>：</p>
<div class="codehilite"><pre><span></span><code>输入文本 → LLM → 决策：{理解任务 → AR 输出}
                     {生成任务 → 触发 DM}

Diffusion 分支：
LLM embeddings → Cross-Attention → U-Net → 图像
                     ↑
                 Text Condition
</code></pre></div>

<p><strong>CM3Leon 式统一</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">UnifiedModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">image</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;understand&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;understand&quot;</span><span class="p">:</span>
            <span class="c1"># 图像 → 文本</span>
            <span class="n">img_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ar_generate</span><span class="p">(</span><span class="n">concat</span><span class="p">([</span><span class="n">img_tokens</span><span class="p">,</span> <span class="n">text</span><span class="p">]))</span>
        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;generate&quot;</span><span class="p">:</span>
            <span class="c1"># 文本 → 图像</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_diffusion</span><span class="p">:</span>
                <span class="n">text_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">diffusion_decode</span><span class="p">(</span><span class="n">text_emb</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ar_generate_image</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div>

<p><strong>训练策略</strong>：</p>
<ol>
<li>阶段一：分别预训练 AR 和 DM 分支</li>
<li>阶段二：冻结 DM，训练 AR→DM 接口</li>
<li>阶段三：联合微调，平衡两种损失</li>
</ol>
<h3 id="523-token">5.2.3 图像 Token 化策略</h3>
<p>Token 化质量决定了模型理解和生成的上限：</p>
<p><strong>主流方法</strong>：</p>
<ol>
<li><strong>VQ-VAE 系列</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code>原始 VQ-VAE: 32×32 → 8×8 tokens (压缩率 16)
VQ-VAE-2: 层级结构，top: 32×32, bottom: 64×64
问题：码本坍塌，重建质量受限
</code></pre></div>

<ol start="2">
<li><strong>VQGAN</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 关键改进：感知损失 + 对抗训练</span>
<span class="n">L_total</span> <span class="o">=</span> <span class="n">L_recon</span> <span class="o">+</span> <span class="n">λ_p</span><span class="o">*</span><span class="n">L_perceptual</span> <span class="o">+</span> <span class="n">λ_g</span><span class="o">*</span><span class="n">L_gan</span> <span class="o">+</span> <span class="n">λ_c</span><span class="o">*</span><span class="n">L_codebook</span>

<span class="c1"># 码本大小影响：</span>
<span class="o">|</span><span class="n">Codebook</span><span class="o">|</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">:</span> <span class="n">重建</span> <span class="n">PSNR</span> <span class="o">~</span><span class="mi">23</span><span class="n">dB</span>
<span class="o">|</span><span class="n">Codebook</span><span class="o">|</span> <span class="o">=</span> <span class="mi">8192</span><span class="p">:</span> <span class="n">重建</span> <span class="n">PSNR</span> <span class="o">~</span><span class="mi">26</span><span class="n">dB</span>
<span class="o">|</span><span class="n">Codebook</span><span class="o">|</span> <span class="o">=</span> <span class="mi">16384</span><span class="p">:</span> <span class="n">重建</span> <span class="n">PSNR</span> <span class="o">~</span><span class="mi">27</span><span class="n">dB</span> <span class="p">(</span><span class="n">收益递减</span><span class="p">)</span>
</code></pre></div>

<ol start="3">
<li><strong>连续 Token（SEED, LaVIT）</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">ContinuousTokenizer</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="c1"># 不量化，直接输出连续特征</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  <span class="c1"># [B, 256, 16, 16]</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>  <span class="c1"># [B, 256, D]</span>
        <span class="k">return</span> <span class="n">tokens</span>  <span class="c1"># 连续值，无码本</span>
</code></pre></div>

<p><strong>分辨率处理</strong>：</p>
<div class="codehilite"><pre><span></span><code>固定分辨率：
├── 简单但损失信息
└── 448×448 是常见选择

动态分辨率（Qwen-VL）：
├── 保持宽高比
├── Padding 到最近的 14 的倍数
└── 位置编码需要 2D 插值

NaViT 风格打包：
├── 不同分辨率图像打包成序列
├── 添加分辨率 token 标记边界
└── 计算效率最高
</code></pre></div>

<p><strong>实验要点</strong>：</p>
<ul>
<li>Token 数量权衡：256 tokens 够用，1024 tokens 细节更好</li>
<li>重建质量监控：FID &lt; 5 可接受，&lt; 2 优秀</li>
<li>语义保持：用 CLIP score 验证语义一致性</li>
</ul>
<h3 id="524">5.2.4 分辨率自适应训练</h3>
<p>处理真实世界多样化分辨率的关键技术：</p>
<p><strong>挑战与解决方案</strong>：</p>
<div class="codehilite"><pre><span></span><code>挑战：

1. 训练数据分辨率不一（224×224 到 4K）
2. 推理需求多样（缩略图 vs 细节图）
3. 计算资源限制

解决方案矩阵：
              低分辨率      中分辨率      高分辨率
训练阶段1：    100%          -            -
训练阶段2：     60%         30%          10%
训练阶段3：     30%         40%          30%
</code></pre></div>

<p><strong>Pix2Struct 方法</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">variable_resolution_encode</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">max_patches</span><span class="o">=</span><span class="mi">2048</span><span class="p">):</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>

    <span class="c1"># 自适应决定 patch 数量</span>
    <span class="n">aspect_ratio</span> <span class="o">=</span> <span class="n">w</span> <span class="o">/</span> <span class="n">h</span>
    <span class="k">if</span> <span class="n">aspect_ratio</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">max_patches</span> <span class="o">*</span> <span class="n">aspect_ratio</span><span class="p">))</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_patches</span> <span class="o">/</span> <span class="n">cols</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">max_patches</span> <span class="o">/</span> <span class="n">aspect_ratio</span><span class="p">))</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_patches</span> <span class="o">/</span> <span class="n">rows</span><span class="p">)</span>

    <span class="c1"># 动态 patch embedding</span>
    <span class="n">patches</span> <span class="o">=</span> <span class="n">extract_patches</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">patches</span><span class="p">,</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span>  <span class="c1"># 返回布局信息</span>
</code></pre></div>

<p><strong>位置编码适配</strong>：</p>
<ol>
<li><strong>2D 正弦编码插值</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">interpolate_pos_encoding</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span> <span class="n">new_size</span><span class="p">):</span>
    <span class="c1"># pos_embed: [1, N, D], N = 14×14 = 196</span>
    <span class="n">old_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">pos_embed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">old_size</span><span class="p">,</span> <span class="n">old_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">pos_embed</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> 
                              <span class="n">size</span><span class="o">=</span><span class="n">new_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bicubic&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pos_embed</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<ol start="2">
<li><strong>RoPE 2D 扩展</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">rope_2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="c1"># 为 h 和 w 维度分别计算 RoPE</span>
    <span class="n">pos_h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">pos_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># 应用旋转位置编码</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos_h</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pos_w</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div>

<p><strong>多尺度训练策略</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Curriculum</span><span class="w"> </span><span class="nv">Learning</span>：
<span class="nv">Week</span><span class="w"> </span><span class="mi">1</span><span class="o">-</span><span class="mi">2</span>:<span class="w"> </span><span class="mi">224</span>×<span class="mi">224</span><span class="w"> </span><span class="nv">only</span>
<span class="nv">Week</span><span class="w"> </span><span class="mi">3</span><span class="o">-</span><span class="mi">4</span>:<span class="w"> </span><span class="mi">224</span>×<span class="mi">224</span><span class="w"> </span><span class="ss">(</span><span class="mi">70</span><span class="o">%</span><span class="ss">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">448</span>×<span class="mi">448</span><span class="w"> </span><span class="ss">(</span><span class="mi">30</span><span class="o">%</span><span class="ss">)</span>
<span class="nv">Week</span><span class="w"> </span><span class="mi">5</span><span class="o">-</span><span class="mi">6</span>:<span class="w"> </span><span class="mi">224</span>×<span class="mi">224</span><span class="w"> </span><span class="ss">(</span><span class="mi">40</span><span class="o">%</span><span class="ss">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">448</span>×<span class="mi">448</span><span class="w"> </span><span class="ss">(</span><span class="mi">40</span><span class="o">%</span><span class="ss">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">896</span>×<span class="mi">896</span><span class="w"> </span><span class="ss">(</span><span class="mi">20</span><span class="o">%</span><span class="ss">)</span>
<span class="nv">Week</span><span class="w"> </span><span class="mi">7</span><span class="o">+</span>:<span class="w">  </span>动态采样，根据<span class="w"> </span><span class="nv">loss</span><span class="w"> </span>调整

数据增强：

<span class="o">-</span><span class="w"> </span><span class="k">Random</span><span class="w"> </span><span class="nv">Crop</span>:<span class="w"> </span>保持目标可见前提下
<span class="o">-</span><span class="w"> </span><span class="nv">Multi</span><span class="o">-</span><span class="nv">scale</span><span class="w"> </span><span class="nv">Training</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">8</span><span class="nv">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span>.<span class="mi">2</span><span class="nv">x</span><span class="w"> </span>缩放
<span class="o">-</span><span class="w"> </span><span class="nv">Mixup</span><span class="w"> </span><span class="nv">at</span><span class="w"> </span><span class="nv">Feature</span><span class="w"> </span><span class="nv">Level</span>:<span class="w"> </span>不同分辨率特征混合
</code></pre></div>

<p><strong>效率优化</strong>：</p>
<ul>
<li>Flash Attention：长序列必备</li>
<li>Gradient Checkpointing：用时间换显存</li>
<li>Mixed Resolution Batch：相近分辨率分组</li>
</ul>
<h2 id="53">5.3 音频模态集成</h2>
<p>音频模态带来独特挑战：时序依赖性强、采样率高、信号类型多样（语音、音乐、环境音）。有效的音频集成需要平衡时频域特征提取与计算效率。</p>
<h3 id="531">5.3.1 语音识别与理解</h3>
<p>语音是最重要的音频模态，其与文本的天然对应关系使其成为多模态融合的理想起点：</p>
<p><strong>技术路线演进</strong>：</p>
<div class="codehilite"><pre><span></span><code>传统级联：ASR → 文本 → LLM
├── 优点：模块化，各部分可独立优化
└── 缺点：错误传播，丢失韵律信息

端到端集成：Audio → Encoder → LLM
├── 优点：保留完整音频信息
└── 缺点：需要大量配对数据
</code></pre></div>

<p><strong>Whisper 集成方案</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">WhisperLLMAdapter</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">whisper_model</span><span class="o">=</span><span class="s2">&quot;large-v3&quot;</span><span class="p">,</span> <span class="n">llm_model</span><span class="o">=</span><span class="s2">&quot;llama-7b&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">whisper</span> <span class="o">=</span> <span class="n">load_whisper</span><span class="p">(</span><span class="n">whisper_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="n">load_llm</span><span class="p">(</span><span class="n">llm_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1280</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>  <span class="c1"># Whisper → LLM dim</span>

    <span class="k">def</span> <span class="nf">encode_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_waveform</span><span class="p">):</span>
        <span class="c1"># 提取 Whisper encoder 输出</span>
        <span class="n">mel</span> <span class="o">=</span> <span class="n">log_mel_spectrogram</span><span class="p">(</span><span class="n">audio_waveform</span><span class="p">)</span>
        <span class="n">audio_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">whisper</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">mel</span><span class="p">)</span>  <span class="c1"># [T, 1280]</span>

        <span class="c1"># 投影到 LLM 空间</span>
        <span class="n">audio_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">audio_features</span><span class="p">)</span>  <span class="c1"># [T, 4096]</span>

        <span class="c1"># 降采样（Whisper 50Hz → LLM ~10Hz）</span>
        <span class="n">audio_tokens</span> <span class="o">=</span> <span class="n">audio_tokens</span><span class="p">[::</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># 简单降采样</span>
        <span class="k">return</span> <span class="n">audio_tokens</span>
</code></pre></div>

<p><strong>多语言处理策略</strong>：</p>
<ol>
<li><strong>语言感知编码</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="n">lang_embeddings</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;en&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">768</span><span class="p">),</span>
    <span class="s2">&quot;zh&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">768</span><span class="p">),</span>
    <span class="s2">&quot;es&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">768</span><span class="p">),</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">encode_with_lang</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">detected_lang</span><span class="p">):</span>
    <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
    <span class="n">lang_emb</span> <span class="o">=</span> <span class="n">lang_embeddings</span><span class="p">[</span><span class="n">detected_lang</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">features</span> <span class="o">+</span> <span class="n">lang_emb</span>  <span class="c1"># 语言偏置</span>
</code></pre></div>

<ol start="2">
<li><strong>代码切换处理</strong>（Code-switching）：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="n">输入</span><span class="err">：</span><span class="s">&quot;今天天气 really nice，我们去 shopping 吧&quot;</span>

<span class="n">分段策略</span><span class="err">：</span>
<span class="p">[</span><span class="n">今天天气</span><span class="p">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">zh_encoder</span>
<span class="p">[</span><span class="n">really</span><span class="w"> </span><span class="n">nice</span><span class="p">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">en_encoder</span><span class="w">  </span>
<span class="p">[</span><span class="n">我们去</span><span class="p">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">zh_encoder</span>
<span class="p">[</span><span class="n">shopping</span><span class="p">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">en_encoder</span>
<span class="p">[</span><span class="n">吧</span><span class="p">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">zh_encoder</span>

<span class="n">融合</span><span class="err">：</span><span class="n">Attention</span><span class="w"> </span><span class="n">机制自动学习边界</span>
</code></pre></div>

<p><strong>韵律信息保留</strong>：</p>
<ul>
<li>音高（Pitch）：提取 F0 轨迹，作为额外 channel</li>
<li>能量（Energy）：RMS energy 曲线</li>
<li>语速（Duration）：音素时长信息</li>
<li>情感（Emotion）：预训练情感分类器特征</li>
</ul>
<h3 id="532">5.3.2 音乐与环境音理解</h3>
<p>非语音音频理解需要不同的特征提取和建模策略：</p>
<p><strong>音乐理解层次</strong>：</p>
<div class="codehilite"><pre><span></span><code>低级特征：
├── 节奏（Tempo, Beat）
├── 音高（Pitch, Key）
└── 音色（Timbre）

中级结构：
├── 和弦进行
├── 旋律线条
└── 节奏模式

高级语义：
├── 风格流派
├── 情感表达
└── 结构分析（Verse, Chorus, Bridge）
</code></pre></div>

<p><strong>MusicLM 式建模</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MusicEncoder</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2v_music</span> <span class="o">=</span> <span class="n">load_pretrained</span><span class="p">(</span><span class="s2">&quot;wav2vec2-music&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mulan</span> <span class="o">=</span> <span class="n">load_pretrained</span><span class="p">(</span><span class="s2">&quot;mulan&quot;</span><span class="p">)</span>  <span class="c1"># 音乐-文本对齐</span>

    <span class="k">def</span> <span class="nf">encode_hierarchical</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">):</span>
        <span class="c1"># 声学 tokens (w2v-BERT)</span>
        <span class="n">acoustic_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2v_music</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>  <span class="c1"># 50Hz</span>

        <span class="c1"># 语义 tokens (MuLaN)</span>
        <span class="n">semantic_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mulan</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>  <span class="c1"># 1Hz</span>

        <span class="c1"># 层次化表示</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;fine&quot;</span><span class="p">:</span> <span class="n">acoustic_tokens</span><span class="p">,</span>    <span class="c1"># 细粒度</span>
            <span class="s2">&quot;coarse&quot;</span><span class="p">:</span> <span class="n">semantic_tokens</span><span class="p">,</span>   <span class="c1"># 粗粒度</span>
        <span class="p">}</span>
</code></pre></div>

<p><strong>环境音事件检测</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">AudioEventDetector</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">527</span><span class="p">):</span>  <span class="c1"># AudioSet classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spectrogram</span><span class="p">):</span>
        <span class="c1"># 多尺度特征提取</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">spectrogram</span><span class="p">)</span>

        <span class="c1"># 帧级预测</span>
        <span class="n">frame_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>  <span class="c1"># [T, 527]</span>

        <span class="c1"># 聚合为片段级</span>
        <span class="n">segment_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">frame_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">segment_logits</span>
</code></pre></div>

<p><strong>音频字幕生成</strong>：</p>
<div class="codehilite"><pre><span></span><code>输入：[狗叫声] + [汽车经过] + [雨声]
输出：&quot;雨天街道上，一只狗对着经过的汽车吠叫&quot;

关键：时序关系建模 + 事件共现学习
</code></pre></div>

<h3 id="533">5.3.3 音频编码器选择</h3>
<p>不同音频编码器的特点与适用场景：</p>
<p><strong>主流编码器对比</strong>：</p>
<p>| 编码器 | 预训练数据 | 特点 | 最佳场景 |</p>
<table>
<thead>
<tr>
<th>编码器</th>
<th>预训练数据</th>
<th>特点</th>
<th>最佳场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>Wav2Vec2</td>
<td>960h LibriSpeech</td>
<td>自监督，CPC loss</td>
<td>英文语音</td>
</tr>
<tr>
<td>HuBERT</td>
<td>60k h Libri-Light</td>
<td>Masked prediction</td>
<td>多语言语音</td>
</tr>
<tr>
<td>WavLM</td>
<td>94k h 混合</td>
<td>去噪 + 掩码</td>
<td>噪声鲁棒</td>
</tr>
<tr>
<td>Whisper</td>
<td>680k h 标注</td>
<td>有监督，多任务</td>
<td>通用语音</td>
</tr>
<tr>
<td>BEATs</td>
<td>AudioSet + 私有</td>
<td>音频 MAE</td>
<td>通用音频</td>
</tr>
<tr>
<td>CLAP</td>
<td>LAION-Audio-630K</td>
<td>对比学习</td>
<td>音频-文本对齐</td>
</tr>
</tbody>
</table>
<p><strong>选择决策树</strong>：</p>
<div class="codehilite"><pre><span></span><code>需要语音识别？
├─是→ 需要多语言？
│     ├─是→ Whisper
│     └─否→ Wav2Vec2
└─否→ 需要文本描述？
      ├─是→ CLAP
      └─否→ BEATs
</code></pre></div>

<p><strong>特征提取层级</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">extract_hierarchical_features</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">audio</span><span class="p">):</span>
    <span class="n">features</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Whisper 示例</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">WhisperModel</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        <span class="n">features</span><span class="p">[</span><span class="s1">&#39;conv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>  <span class="c1"># 早期声学特征</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">blocks</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">24</span><span class="p">]:</span>  <span class="c1"># 选择性保存</span>
                <span class="n">features</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;layer_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

    <span class="k">return</span> <span class="n">features</span>  <span class="c1"># 多层级特征</span>
</code></pre></div>

<h3 id="534">5.3.4 时频域特征融合</h3>
<p>有效融合时域和频域信息是音频理解的关键：</p>
<p><strong>特征提取管线</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">AudioFeatureExtractor</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mel_bins</span> <span class="o">=</span> <span class="mi">128</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="mi">160</span>  <span class="c1"># 10ms</span>

    <span class="k">def</span> <span class="nf">extract_all_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">waveform</span><span class="p">):</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># 时域特征</span>
        <span class="n">features</span><span class="p">[</span><span class="s1">&#39;zcr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero_crossing_rate</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>
        <span class="n">features</span><span class="p">[</span><span class="s1">&#39;energy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">short_time_energy</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>

        <span class="c1"># 频域特征  </span>
        <span class="n">stft</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stft</span><span class="p">(</span><span class="n">waveform</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="mi">160</span><span class="p">)</span>
        <span class="n">features</span><span class="p">[</span><span class="s1">&#39;spectral_centroid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spectral_centroid</span><span class="p">(</span><span class="n">stft</span><span class="p">)</span>
        <span class="n">features</span><span class="p">[</span><span class="s1">&#39;spectral_rolloff&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spectral_rolloff</span><span class="p">(</span><span class="n">stft</span><span class="p">)</span>

        <span class="c1"># 时频特征</span>
        <span class="n">features</span><span class="p">[</span><span class="s1">&#39;mel_spec&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mel_spectrogram</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>
        <span class="n">features</span><span class="p">[</span><span class="s1">&#39;mfcc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mfcc</span><span class="p">(</span><span class="n">waveform</span><span class="p">,</span> <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">features</span>
</code></pre></div>

<p><strong>多尺度时间建模</strong>：</p>
<div class="codehilite"><pre><span></span><code>短时窗口（10-30ms）：
└── 捕获音素、音高变化

中时窗口（100-500ms）：  
└── 捕获音节、节拍

长时窗口（1-5s）：
└── 捕获句子、乐句

超长窗口（&gt;10s）：
└── 捕获段落、音乐结构
</code></pre></div>

<p><strong>注意力融合机制</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">TimeFreqAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">freq_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: [Batch, Time, Freq, Dim]</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># 时间维度注意力</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># [B, T, D]</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_attn</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">x_t</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 频率维度注意力  </span>
        <span class="n">x_f</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [B, F, D]</span>
        <span class="n">x_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">freq_attn</span><span class="p">(</span><span class="n">x_f</span><span class="p">,</span> <span class="n">x_f</span><span class="p">,</span> <span class="n">x_f</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 广播并融合</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x_f</span> <span class="o">=</span> <span class="n">x_f</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">x_fused</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_t</span><span class="p">,</span> <span class="n">x_f</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x_fused</span>
</code></pre></div>

<p><strong>实验优化技巧</strong>：</p>
<ul>
<li>SpecAugment：时频域数据增强</li>
<li>混合精度：节省显存，加速训练</li>
<li>渐进式分辨率：从低分辨率开始训练</li>
</ul>
<h2 id="54">5.4 视频理解的时序建模</h2>
<p>视频作为最复杂的多模态数据，不仅包含视觉和音频信息，还具有强烈的时序依赖性。有效的时序建模是视频理解的核心，决定了模型能否捕获动作、事件和叙事结构。</p>
<h3 id="541">5.4.1 帧采样策略</h3>
<p>视频的高维特性（典型 30fps）使得处理所有帧在计算上不可行。智能的帧采样策略需要在信息保留和计算效率间取得平衡。</p>
<p><strong>采样方法对比</strong>：</p>
<div class="codehilite"><pre><span></span><code>均匀采样（Uniform Sampling）：
├── 实现：每隔 k 帧采样一次
├── 优点：简单，保持时序均匀性
├── 缺点：可能错过关键帧
└── 适用：动作均匀分布的视频

密集采样（Dense Sampling）：
├── 实现：在短时间窗口内密集采样
├── 优点：捕获细粒度动作
├── 缺点：长程依赖建模困难
└── 适用：动作识别任务

稀疏采样（Sparse Sampling）：
├── 实现：大间隔采样，覆盖整个视频
├── 优点：捕获全局结构
├── 缺点：丢失局部细节
└── 适用：视频分类、摘要

自适应采样（Adaptive Sampling）：
├── 实现：基于内容变化动态调整
├── 优点：信息保留最优
├── 缺点：计算开销大
└── 适用：事件检测、高光提取
</code></pre></div>

<p><strong>TSN（Temporal Segment Networks）采样</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">tsn_sampling</span><span class="p">(</span><span class="n">video_frames</span><span class="p">,</span> <span class="n">num_segments</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;TSN 的分段采样策略&quot;&quot;&quot;</span>
    <span class="n">total_frames</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">video_frames</span><span class="p">)</span>
    <span class="n">segment_len</span> <span class="o">=</span> <span class="n">total_frames</span> <span class="o">//</span> <span class="n">num_segments</span>

    <span class="n">sampled_frames</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_segments</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">segment_len</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">segment_len</span><span class="p">,</span> <span class="n">total_frames</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;uniform&#39;</span><span class="p">:</span>
            <span class="c1"># 每段中间帧</span>
            <span class="n">frame_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">end</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
            <span class="c1"># 每段随机采样</span>
            <span class="n">frame_idx</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;dense&#39;</span><span class="p">:</span>
            <span class="c1"># 每段采样多帧</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="n">sampled_frames</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">video_frames</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
            <span class="k">continue</span>

        <span class="n">sampled_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">video_frames</span><span class="p">[</span><span class="n">frame_idx</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">sampled_frames</span>
</code></pre></div>

<p><strong>时序jittering增强</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">TemporalJitter</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_jitter</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_jitter</span> <span class="o">=</span> <span class="n">max_jitter</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame_indices</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;训练时添加时序扰动，提升泛化&quot;&quot;&quot;</span>
        <span class="n">jittered</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">frame_indices</span><span class="p">:</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_jitter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_jitter</span><span class="p">)</span>
            <span class="n">new_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="n">offset</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">frame_indices</span><span class="p">))</span>
            <span class="n">jittered</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">jittered</span>
</code></pre></div>

<p><strong>关键帧检测采样</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">keyframe_sampling</span><span class="p">(</span><span class="n">video</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;基于内容变化的关键帧采样&quot;&quot;&quot;</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_frame</span> <span class="o">=</span> <span class="n">video</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_frame</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">video</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="c1"># 计算帧间差异</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">compute_frame_difference</span><span class="p">(</span><span class="n">prev_frame</span><span class="p">,</span> <span class="n">frame</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">diff</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
            <span class="n">prev_frame</span> <span class="o">=</span> <span class="n">frame</span>

    <span class="k">return</span> <span class="n">frames</span>

<span class="k">def</span> <span class="nf">compute_frame_difference</span><span class="p">(</span><span class="n">frame1</span><span class="p">,</span> <span class="n">frame2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;使用直方图差异 + 光流幅度&quot;&quot;&quot;</span>
    <span class="c1"># 颜色直方图差异</span>
    <span class="n">hist1</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">calcHist</span><span class="p">([</span><span class="n">frame1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">256</span><span class="p">])</span>
    <span class="n">hist2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">calcHist</span><span class="p">([</span><span class="n">frame2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">256</span><span class="p">])</span>
    <span class="n">hist_diff</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">compareHist</span><span class="p">(</span><span class="n">hist1</span><span class="p">,</span> <span class="n">hist2</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">HISTCMP_CHISQR</span><span class="p">)</span>

    <span class="c1"># 光流幅度（可选）</span>
    <span class="n">flow</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">calcOpticalFlowFarneback</span><span class="p">(</span><span class="n">gray1</span><span class="p">,</span> <span class="n">gray2</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">magnitude</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">flow</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">flow</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">hist_diff</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">magnitude</span>
</code></pre></div>

<p><strong>实验建议</strong>：</p>
<ul>
<li>短视频（&lt;10s）：8-16 帧足够</li>
<li>长视频（&gt;60s）：32-64 帧，分层采样</li>
<li>动作识别：密集采样 + TSM（Temporal Shift Module）</li>
<li>视频问答：稀疏采样 + 关键帧检测</li>
</ul>
<h3 id="542">5.4.2 时序注意力机制</h3>
<p>时序注意力是视频理解的核心，需要有效建模帧间关系while控制计算复杂度。</p>
<p><strong>时空注意力分解</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">SpaceTimeAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;时空注意力分解，降低复杂度 O(T²S²) → O(T²+S²)&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temporal_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: [B, T, S, D] - Batch, Time, Space, Dim</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># 空间注意力（独立处理每帧）</span>
        <span class="n">x_spatial</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="o">*</span><span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
        <span class="n">x_spatial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_attn</span><span class="p">(</span><span class="n">x_spatial</span><span class="p">,</span> <span class="n">x_spatial</span><span class="p">,</span> <span class="n">x_spatial</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x_spatial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x_spatial</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="o">*</span><span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">D</span><span class="p">))</span>
        <span class="n">x_spatial</span> <span class="o">=</span> <span class="n">x_spatial</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>

        <span class="c1"># 时间注意力（跨帧建模）</span>
        <span class="n">x_temporal</span> <span class="o">=</span> <span class="n">x_spatial</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="o">*</span><span class="n">S</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
        <span class="n">x_temporal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">temporal_attn</span><span class="p">(</span><span class="n">x_temporal</span><span class="p">,</span> <span class="n">x_temporal</span><span class="p">,</span> <span class="n">x_temporal</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x_temporal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x_temporal</span> <span class="o">+</span> <span class="n">x_temporal</span><span class="p">)</span>
        <span class="n">x_temporal</span> <span class="o">=</span> <span class="n">x_temporal</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x_temporal</span>
</code></pre></div>

<p><strong>TimeSformer架构变体</strong>：</p>
<div class="codehilite"><pre><span></span><code>Divided Attention（分离注意力）：
Space Attn → Time Attn
复杂度：O(TS²) + O(T²S)

Joint Attention（联合注意力）：
SpaceTime Attn together
复杂度：O((TS)²) - 计算密集

Axial Attention（轴向注意力）：
Height → Width → Time
复杂度：O(TH²W) + O(THW²) + O(T²HW)
</code></pre></div>

<p><strong>局部时序注意力</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">LocalTemporalAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;局部窗口时序注意力，降低长视频复杂度&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: [B, T, D]</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># 滑动窗口注意力</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="n">start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">window</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>  <span class="c1"># [B, W, D]</span>
            <span class="n">center_idx</span> <span class="o">=</span> <span class="n">t</span> <span class="o">-</span> <span class="n">start</span>

            <span class="c1"># 计算窗口内注意力</span>
            <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span>
                <span class="n">window</span><span class="p">[:,</span> <span class="n">center_idx</span><span class="p">:</span><span class="n">center_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># Query</span>
                <span class="n">window</span><span class="p">,</span>  <span class="c1"># Key</span>
                <span class="n">window</span>   <span class="c1"># Value</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">output</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">attn_out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>

<p><strong>时序位置编码策略</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">temporal_position_encoding</span><span class="p">(</span><span class="n">num_frames</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">max_period</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;为视频帧生成时序位置编码&quot;&quot;&quot;</span>
    <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_frames</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">max_period</span><span class="p">)</span> <span class="o">/</span> <span class="n">dim</span><span class="p">))</span>

    <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_frames</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
    <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
    <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>

    <span class="c1"># 添加帧率自适应</span>
    <span class="k">if</span> <span class="n">frame_rate</span> <span class="o">!=</span> <span class="mi">30</span><span class="p">:</span>  <span class="c1"># 假设30fps为基准</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="mf">30.0</span> <span class="o">/</span> <span class="n">frame_rate</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span> <span class="o">*</span> <span class="n">scale</span>

    <span class="k">return</span> <span class="n">pe</span>
</code></pre></div>

<h3 id="543">5.4.3 长视频处理优化</h3>
<p>长视频（&gt;5分钟）带来严重的内存和计算挑战，需要特殊的优化策略。</p>
<p><strong>层次化处理架构</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">HierarchicalVideoModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;层次化长视频处理&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clip_len</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_len</span> <span class="o">=</span> <span class="n">clip_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

        <span class="c1"># 局部编码器（处理短片段）</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_encoder</span> <span class="o">=</span> <span class="n">VideoEncoder</span><span class="p">(</span><span class="n">num_frames</span><span class="o">=</span><span class="n">clip_len</span><span class="p">)</span>

        <span class="c1"># 全局聚合器（融合片段特征）</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_aggregator</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">4</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video</span><span class="p">):</span>
        <span class="c1"># video: [B, T_total, H, W, C]</span>
        <span class="n">clips</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_clips</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>  <span class="c1"># [B, N_clips, clip_len, H, W, C]</span>

        <span class="c1"># 编码每个片段</span>
        <span class="n">clip_features</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">clips</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_encoder</span><span class="p">(</span><span class="n">clips</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>  <span class="c1"># [B, D]</span>
            <span class="n">clip_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>

        <span class="n">clip_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">clip_features</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [B, N_clips, D]</span>

        <span class="c1"># 全局聚合</span>
        <span class="n">global_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_aggregator</span><span class="p">(</span><span class="n">clip_features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">global_features</span>
</code></pre></div>

<p><strong>内存优化技术</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MemoryEfficientVideoProcessor</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chunk_size</span> <span class="o">=</span> <span class="n">chunk_size</span>

    <span class="k">def</span> <span class="nf">process_video_streaming</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;流式处理，避免一次性加载全部帧&quot;&quot;&quot;</span>
        <span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">chunk</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="n">chunk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">chunk_size</span><span class="p">:</span>
                <span class="c1"># 处理当前chunk</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">chunk_tensor</span> <span class="o">=</span> <span class="n">preprocess_frames</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
                    <span class="n">chunk_features</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">chunk_tensor</span><span class="p">)</span>
                    <span class="n">features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_features</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

                <span class="c1"># 清空chunk，保留部分重叠</span>
                <span class="n">chunk</span> <span class="o">=</span> <span class="n">chunk</span><span class="p">[</span><span class="o">-</span><span class="mi">8</span><span class="p">:]</span>  <span class="c1"># 保留8帧重叠</span>

        <span class="c1"># 处理剩余帧</span>
        <span class="k">if</span> <span class="n">chunk</span><span class="p">:</span>
            <span class="n">chunk_tensor</span> <span class="o">=</span> <span class="n">preprocess_frames</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">chunk_features</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">chunk_tensor</span><span class="p">)</span>
            <span class="n">features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_features</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>

<p><strong>Token压缩策略</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">TokenMerging</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Token合并，减少序列长度&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># tokens: [B, N, D]</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">tokens</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">num_keep</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">scores</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># 基于相似度的合并</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">similarity</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 平均相似度</span>

        <span class="c1"># 保留重要tokens</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">num_keep</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">kept_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">indices</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">D</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">kept_tokens</span>
</code></pre></div>

<h3 id="544">5.4.4 动作识别与事件定位</h3>
<p>动作识别和时序定位是视频理解的核心任务，需要精确捕获动作边界和语义。</p>
<p><strong>双流网络（Two-Stream）架构</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">TwoStreamNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;RGB流 + 光流流的经典架构&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">400</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># RGB流：外观信息</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rgb_stream</span> <span class="o">=</span> <span class="n">ResNet3D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

        <span class="c1"># 光流流：运动信息</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flow_stream</span> <span class="o">=</span> <span class="n">ResNet3D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (u, v)</span>

        <span class="c1"># 融合层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rgb_frames</span><span class="p">,</span> <span class="n">flow_frames</span><span class="p">):</span>
        <span class="n">rgb_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rgb_stream</span><span class="p">(</span><span class="n">rgb_frames</span><span class="p">)</span>
        <span class="n">flow_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow_stream</span><span class="p">(</span><span class="n">flow_frames</span><span class="p">)</span>

        <span class="c1"># 晚期融合</span>
        <span class="n">fused</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">rgb_feat</span><span class="p">,</span> <span class="n">flow_feat</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="p">(</span><span class="n">fused</span><span class="p">)</span>
</code></pre></div>

<p><strong>时序动作定位（TAL）</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">TemporalActionLocalization</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;时序动作定位，输出动作类别和时间边界&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span> <span class="o">=</span> <span class="n">I3D</span><span class="p">()</span>  <span class="c1"># 3D CNN backbone</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 起止时间回归</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video</span><span class="p">):</span>
        <span class="c1"># 提取时序特征</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>  <span class="c1"># [B, C, T]</span>

        <span class="c1"># 逐帧分类</span>
        <span class="n">class_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>  <span class="c1"># [B, num_classes, T]</span>

        <span class="c1"># 边界回归</span>
        <span class="n">boundaries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>  <span class="c1"># [B, 2, T]</span>
        <span class="n">start_offsets</span> <span class="o">=</span> <span class="n">boundaries</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">end_offsets</span> <span class="o">=</span> <span class="n">boundaries</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;class_scores&#39;</span><span class="p">:</span> <span class="n">class_scores</span><span class="p">,</span>
            <span class="s1">&#39;start_offsets&#39;</span><span class="p">:</span> <span class="n">start_offsets</span><span class="p">,</span>
            <span class="s1">&#39;end_offsets&#39;</span><span class="p">:</span> <span class="n">end_offsets</span>
        <span class="p">}</span>
</code></pre></div>

<p><strong>动作质量评估（AQA）</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">ActionQualityAssessment</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;评估动作执行质量，如体操、跳水评分&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">VideoEncoder</span><span class="p">()</span>

        <span class="c1"># 多任务头</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">score_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 分数回归</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>  <span class="c1"># 排序学习</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video</span><span class="p">,</span> <span class="n">pairs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>

        <span class="c1"># 直接分数预测</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># 相对排序学习</span>
        <span class="k">if</span> <span class="n">pairs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feat_a</span><span class="p">,</span> <span class="n">feat_b</span> <span class="o">=</span> <span class="n">pairs</span>
            <span class="n">rank_a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_head</span><span class="p">(</span><span class="n">feat_a</span><span class="p">)</span>
            <span class="n">rank_b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_head</span><span class="p">(</span><span class="n">feat_b</span><span class="p">)</span>
            <span class="n">margin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">rank_a</span> <span class="o">-</span> <span class="n">rank_b</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">margin</span>

        <span class="k">return</span> <span class="n">scores</span>
</code></pre></div>

<p><strong>实验优化要点</strong>：</p>
<ul>
<li>预训练初始化：Kinetics-400/600 预训练权重</li>
<li>多尺度测试：1x, 1.25x, 1.5x 尺度融合</li>
<li>时序增强：速度扰动 [0.5x, 2x]</li>
<li>类别平衡：Focal Loss 处理长尾分布</li>
</ul>
<h2 id="55">5.5 跨模态注意力机制设计</h2>
<p>跨模态注意力是多模态模型的核心组件，决定了不同模态信息如何有效交互和融合。设计高效的跨模态注意力机制需要平衡表达能力、计算效率和训练稳定性。</p>
<h3 id="551-vs">5.5.1 早期融合 vs 晚期融合</h3>
<p>融合时机的选择深刻影响模型的表达能力和计算效率：</p>
<p><strong>融合策略对比</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">早期融合</span><span class="err">（</span><span class="n">Early</span><span class="w"> </span><span class="k">Fusion</span><span class="err">）：</span>
<span class="n">输入层</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="o">[</span><span class="n">Concat/Add</span><span class="o">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">统一处理</span>
<span class="err">├──</span><span class="w"> </span><span class="n">优点</span><span class="err">：</span><span class="n">充分交互</span><span class="err">，</span><span class="n">参数共享</span>
<span class="err">├──</span><span class="w"> </span><span class="n">缺点</span><span class="err">：</span><span class="n">模态差异大</span><span class="err">，</span><span class="n">优化困难</span>
<span class="err">└──</span><span class="w"> </span><span class="n">适用</span><span class="err">：</span><span class="n">模态相似度高的任务</span>

<span class="n">晚期融合</span><span class="err">（</span><span class="n">Late</span><span class="w"> </span><span class="k">Fusion</span><span class="err">）：</span>
<span class="n">独立编码</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">高层特征</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="o">[</span><span class="n">Fusion</span><span class="o">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">输出</span>
<span class="err">├──</span><span class="w"> </span><span class="n">优点</span><span class="err">：</span><span class="n">模块化</span><span class="err">，</span><span class="n">易于优化</span>
<span class="err">├──</span><span class="w"> </span><span class="n">缺点</span><span class="err">：</span><span class="n">交互不充分</span><span class="err">，</span><span class="n">参数冗余</span>
<span class="err">└──</span><span class="w"> </span><span class="n">适用</span><span class="err">：</span><span class="n">模态独立性强的任务</span>

<span class="n">渐进融合</span><span class="err">（</span><span class="n">Progressive</span><span class="w"> </span><span class="k">Fusion</span><span class="err">）：</span>
<span class="n">多层级融合</span><span class="err">，</span><span class="n">逐步加深交互</span>
<span class="err">├──</span><span class="w"> </span><span class="n">优点</span><span class="err">：</span><span class="n">平衡早期和晚期优势</span>
<span class="err">├──</span><span class="w"> </span><span class="n">缺点</span><span class="err">：</span><span class="n">架构复杂</span><span class="err">，</span><span class="n">调参困难</span>
<span class="err">└──</span><span class="w"> </span><span class="n">适用</span><span class="err">：</span><span class="n">复杂多模态理解任务</span>
</code></pre></div>

<p><strong>早期融合实现</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">EarlyFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;早期融合：直接拼接输入&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vision_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">text_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">1024</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 投影到相同维度</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">vision_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>

        <span class="c1"># 融合后的处理</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vision_features</span><span class="p">,</span> <span class="n">text_features</span><span class="p">):</span>
        <span class="c1"># 投影</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_proj</span><span class="p">(</span><span class="n">vision_features</span><span class="p">)</span>  <span class="c1"># [B, Nv, D]</span>
        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_proj</span><span class="p">(</span><span class="n">text_features</span><span class="p">)</span>      <span class="c1"># [B, Nt, D]</span>

        <span class="c1"># 拼接</span>
        <span class="n">fused</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="n">t</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [B, Nv+Nt, D]</span>

        <span class="c1"># 统一处理</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_layers</span><span class="p">(</span><span class="n">fused</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>

<p><strong>晚期融合实现</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">LateFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;晚期融合：独立处理后融合&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 独立编码器</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_encoder</span> <span class="o">=</span> <span class="n">VisionTransformer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="o">=</span> <span class="n">TextTransformer</span><span class="p">()</span>

        <span class="c1"># 融合策略</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">texts</span><span class="p">):</span>
        <span class="c1"># 独立编码</span>
        <span class="n">v_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_encoder</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [B, D]</span>
        <span class="n">t_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     <span class="c1"># [B, D]</span>

        <span class="c1"># 高层融合</span>
        <span class="n">fused</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v_out</span><span class="p">,</span> <span class="n">t_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">fused</span>
</code></pre></div>

<p><strong>渐进融合架构</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">ProgressiveFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;渐进式多层融合&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>

        <span class="c1"># 每3层进行一次融合</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_points</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vision_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">TransformerLayer</span><span class="p">(</span><span class="mi">768</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">TransformerLayer</span><span class="p">(</span><span class="mi">768</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># 跨模态融合层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">CrossModalAttention</span><span class="p">(</span><span class="mi">768</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fusion_points</span><span class="p">))</span>
        <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v_input</span><span class="p">,</span> <span class="n">t_input</span><span class="p">):</span>
        <span class="n">fusion_idx</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="c1"># 独立处理</span>
            <span class="n">v_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">v_input</span><span class="p">)</span>
            <span class="n">t_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">t_input</span><span class="p">)</span>

            <span class="c1"># 在融合点进行跨模态交互</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_points</span><span class="p">:</span>
                <span class="n">v_input</span><span class="p">,</span> <span class="n">t_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention</span><span class="p">[</span><span class="n">fusion_idx</span><span class="p">](</span><span class="n">v_input</span><span class="p">,</span> <span class="n">t_input</span><span class="p">)</span>
                <span class="n">fusion_idx</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">v_input</span><span class="p">,</span> <span class="n">t_input</span>
</code></pre></div>

<h3 id="552">5.5.2 交叉注意力优化</h3>
<p>交叉注意力是实现模态间信息交换的核心机制：</p>
<p><strong>标准交叉注意力</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">CrossModalAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;双向交叉注意力&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v2t_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t2v_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_t</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vision</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="c1"># Vision attending to Text</span>
        <span class="n">v2t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v2t_attn</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">vision</span><span class="p">,</span>
            <span class="n">key</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
            <span class="n">value</span><span class="o">=</span><span class="n">text</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">vision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_v</span><span class="p">(</span><span class="n">vision</span> <span class="o">+</span> <span class="n">v2t</span><span class="p">)</span>

        <span class="c1"># Text attending to Vision</span>
        <span class="n">t2v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t2v_attn</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
            <span class="n">key</span><span class="o">=</span><span class="n">vision</span><span class="p">,</span>
            <span class="n">value</span><span class="o">=</span><span class="n">vision</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_t</span><span class="p">(</span><span class="n">text</span> <span class="o">+</span> <span class="n">t2v</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">vision</span><span class="p">,</span> <span class="n">text</span>
</code></pre></div>

<p><strong>稀疏交叉注意力</strong>（降低复杂度）：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">SparseBlockAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;块稀疏模式的交叉注意力&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">block_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">key_value</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># 将序列分块</span>
        <span class="n">num_blocks</span> <span class="o">=</span> <span class="n">N</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
        <span class="n">query_blocks</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">):</span>
            <span class="c1"># 每个query块只attend到对应的key块</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
            <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

            <span class="n">q_block</span> <span class="o">=</span> <span class="n">query_blocks</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>  <span class="c1"># [B, block_size, D]</span>
            <span class="n">kv_block</span> <span class="o">=</span> <span class="n">key_value</span><span class="p">[:,</span> <span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>  <span class="c1"># [B, block_size, D]</span>

            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q_block</span><span class="p">,</span> <span class="n">kv_block</span><span class="p">,</span> <span class="n">kv_block</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>

<p><strong>门控交叉注意力</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">GatedCrossAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;使用门控机制的交叉注意力&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

        <span class="c1"># 门控网络</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gate_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">):</span>
        <span class="c1"># 计算注意力</span>
        <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">,</span> <span class="n">key_value</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 计算门控权重</span>
        <span class="n">gate_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">query</span><span class="p">,</span> <span class="n">attn_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">gate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gate_net</span><span class="p">(</span><span class="n">gate_input</span><span class="p">)</span>

        <span class="c1"># 门控输出</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">gate</span> <span class="o">*</span> <span class="n">attn_out</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gate</span><span class="p">)</span> <span class="o">*</span> <span class="n">query</span>
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>

<p><strong>层次化注意力池化</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">HierarchicalAttentionPooling</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;多粒度注意力池化&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">num_levels</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span> <span class="o">=</span> <span class="n">num_levels</span>

        <span class="c1"># 不同粒度的池化头</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool_heads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">//</span> <span class="n">num_levels</span><span class="p">)</span> 
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_levels</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># 粒度特定的注意力</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">level_attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span> <span class="o">//</span> <span class="n">num_levels</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_levels</span><span class="p">)</span>
        <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="c1"># features: [B, N, D]</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">pooled_features</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span><span class="p">):</span>
            <span class="c1"># 不同步长的池化</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">i</span>
            <span class="n">pooled</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:,</span> <span class="p">::</span><span class="n">stride</span><span class="p">]</span>  <span class="c1"># 降采样</span>

            <span class="c1"># 投影到子空间</span>
            <span class="n">pooled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_heads</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">pooled</span><span class="p">)</span>

            <span class="c1"># 层级内注意力</span>
            <span class="n">attended</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">level_attention</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">pooled</span><span class="p">,</span> <span class="n">pooled</span><span class="p">,</span> <span class="n">pooled</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">pooled_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attended</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># [B, D/num_levels]</span>

        <span class="c1"># 拼接多粒度特征</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pooled_features</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [B, D]</span>
</code></pre></div>

<h3 id="553-mome">5.5.3 模态专家混合（MoME）</h3>
<p>模态专家混合通过为不同模态分配专门的处理路径，提升模型的专业化能力：</p>
<p><strong>MoME 架构</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">ModalityMixtureOfExperts</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;模态感知的专家混合&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">num_experts</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_modalities</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span> <span class="o">=</span> <span class="n">num_experts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_modalities</span> <span class="o">=</span> <span class="n">num_modalities</span>

        <span class="c1"># 专家网络</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experts</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">FeedForward</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_experts</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># 模态特定的路由网络</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">routers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">({</span>
            <span class="s1">&#39;vision&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_experts</span><span class="p">),</span>
            <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_experts</span><span class="p">),</span>
            <span class="s1">&#39;audio&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_experts</span><span class="p">)</span>
        <span class="p">})</span>

        <span class="c1"># Top-k 选择</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">top_k</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">modality</span><span class="o">=</span><span class="s1">&#39;vision&#39;</span><span class="p">):</span>
        <span class="c1"># 计算路由权重</span>
        <span class="n">router</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">routers</span><span class="p">[</span><span class="n">modality</span><span class="p">]</span>
        <span class="n">routing_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">router</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [B, num_experts]</span>

        <span class="c1"># 选择 top-k 专家</span>
        <span class="n">top_k_weights</span><span class="p">,</span> <span class="n">top_k_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">routing_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">top_k</span><span class="p">)</span>
        <span class="n">top_k_weights</span> <span class="o">=</span> <span class="n">top_k_weights</span> <span class="o">/</span> <span class="n">top_k_weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># 应用专家</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">top_k</span><span class="p">):</span>
            <span class="n">expert_idx</span> <span class="o">=</span> <span class="n">top_k_indices</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">top_k_weights</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># 批量处理每个专家</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
                <span class="n">expert</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experts</span><span class="p">[</span><span class="n">expert_idx</span><span class="p">[</span><span class="n">b</span><span class="p">]]</span>
                <span class="n">output</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">*</span> <span class="n">expert</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>

<p><strong>动态专家分配</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DynamicExpertAllocation</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;基于输入内容动态分配专家&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">num_experts</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span> <span class="o">=</span> <span class="n">num_experts</span>

        <span class="c1"># 专家池</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experts</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_experts</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># 负载均衡损失权重</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_balance_weight</span> <span class="o">=</span> <span class="mf">0.01</span>

        <span class="c1"># 路由网络</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">router</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_experts</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># 计算每个token的路由</span>
        <span class="n">router_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">router</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [B, N, num_experts]</span>
        <span class="n">router_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">router_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Gumbel-Softmax 采样（训练时）</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">router_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gumbel_softmax</span><span class="p">(</span><span class="n">router_logits</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">hard</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># 负载均衡损失</span>
        <span class="n">expert_usage</span> <span class="o">=</span> <span class="n">router_probs</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span>
        <span class="n">load_balance_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_balance_weight</span> <span class="o">*</span> <span class="p">(</span>
            <span class="n">expert_usage</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span> <span class="o">-</span> <span class="n">expert_usage</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># 应用专家</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">expert</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experts</span><span class="p">):</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">router_probs</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># [B, N, 1]</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">expert</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">load_balance_loss</span>
</code></pre></div>

<p><strong>模态特定专家设计</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">ModalitySpecificExperts</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;为每个模态设计专门的专家&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># 视觉专家：擅长空间关系</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_expert</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">Conv2dAdapter</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>  <span class="c1"># 2D 卷积适配</span>
            <span class="n">SpatialAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>
            <span class="n">FeedForward</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># 文本专家：擅长序列建模</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_expert</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>
            <span class="n">CausalAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>  <span class="c1"># 因果注意力</span>
            <span class="n">FeedForward</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># 音频专家：擅长时频分析</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">audio_expert</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">SpectralGating</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>  <span class="c1"># 频域门控</span>
            <span class="n">TemporalConvNet</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>
            <span class="n">FeedForward</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># 通用专家：处理跨模态信息</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">general_expert</span> <span class="o">=</span> <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">modality_mask</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        modality_mask: [B, N] 指示每个token的模态</span>
<span class="sd">        0: vision, 1: text, 2: audio, 3: mixed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># 应用模态特定专家</span>
        <span class="k">for</span> <span class="n">modality</span><span class="p">,</span> <span class="n">expert</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vision_expert</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">text_expert</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">audio_expert</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">general_expert</span>
        <span class="p">]):</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">modality_mask</span> <span class="o">==</span> <span class="n">modality</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">expert</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>

<h3 id="554">5.5.4 计算效率优化</h3>
<p>跨模态注意力的计算开销巨大，优化策略至关重要：</p>
<p><strong>Flash Attention 集成</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">FlashCrossAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;使用 Flash Attention 的跨模态注意力&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="n">num_heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">q_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kv_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">key_value</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># 投影</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_proj</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
        <span class="n">kv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kv_proj</span><span class="p">(</span><span class="n">key_value</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
        <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">kv</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Flash Attention (需要特定硬件支持)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="kn">from</span> <span class="nn">flash_attn</span> <span class="kn">import</span> <span class="n">flash_attn_func</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">flash_attn_func</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Fallback to standard attention</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
            <span class="n">attn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div>

<p><strong>低秩分解优化</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">LowRankCrossAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;低秩分解的交叉注意力&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>

        <span class="c1"># 低秩投影</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_down</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">kv_down</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">rank</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kv_up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">rank</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># 标准注意力（低维）</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">):</span>
        <span class="c1"># 降维</span>
        <span class="n">q_low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_down</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>  <span class="c1"># [B, N, rank]</span>
        <span class="n">kv_low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kv_down</span><span class="p">(</span><span class="n">key_value</span><span class="p">)</span>  <span class="c1"># [B, M, rank*2]</span>
        <span class="n">k_low</span><span class="p">,</span> <span class="n">v_low</span> <span class="o">=</span> <span class="n">kv_low</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 低维注意力</span>
        <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q_low</span><span class="p">,</span> <span class="n">k_low</span><span class="p">,</span> <span class="n">v_low</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 升维</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_up</span><span class="p">(</span><span class="n">attn_out</span><span class="p">)</span>

        <span class="c1"># 残差连接</span>
        <span class="k">return</span> <span class="n">output</span> <span class="o">+</span> <span class="n">query</span>
</code></pre></div>

<p><strong>计算复用策略</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">ComputeReuseAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;复用计算结果的注意力&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">,</span> <span class="n">cache_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
            <span class="c1"># 复用缓存的key/value投影</span>
            <span class="n">k_cached</span><span class="p">,</span> <span class="n">v_cached</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
                <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
                <span class="n">key</span><span class="o">=</span><span class="n">k_cached</span><span class="p">,</span>
                <span class="n">value</span><span class="o">=</span><span class="n">v_cached</span><span class="p">,</span>
                <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 正常计算</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">,</span> <span class="n">key_value</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># 缓存中间结果</span>
            <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">in_proj_weight</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">@</span> <span class="n">key_value</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">in_proj_weight</span><span class="p">[</span><span class="n">dim</span><span class="p">:</span><span class="mi">2</span><span class="o">*</span><span class="n">dim</span><span class="p">]</span> <span class="o">@</span> <span class="n">key_value</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">v</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">clear_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</code></pre></div>

<p><strong>量化感知训练</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">QuantizedCrossAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;支持量化的交叉注意力&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">768</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qconfig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get_default_qconfig</span><span class="p">(</span><span class="s1">&#39;fbgemm&#39;</span><span class="p">)</span>

        <span class="c1"># 量化感知层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quant</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">QuantStub</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dequant</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">DeQuantStub</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">):</span>
        <span class="c1"># 量化输入</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">key_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant</span><span class="p">(</span><span class="n">key_value</span><span class="p">)</span>

        <span class="c1"># 执行注意力（量化）</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key_value</span><span class="p">,</span> <span class="n">key_value</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 反量化输出</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dequant</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">prepare_quantization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;准备量化&quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">prepare_qat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">convert_quantization</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;转换为量化模型&quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h2 id="_2">本章小结</h2>
<p>本章系统介绍了多模态任务的实验设计方法，涵盖了从基础的视觉-语言对齐到复杂的跨模态注意力机制设计。核心要点包括：</p>
<p><strong>📌 关键概念回顾</strong>：</p>
<ol>
<li><strong>视觉-语言对齐</strong>：CLIP 的对比学习范式奠定基础，关键在于大批量训练和温度参数调优</li>
<li><strong>统一建模架构</strong>：Perceiver Resampler 等连接层设计实现了高效的模态桥接</li>
<li><strong>音频集成策略</strong>：时频域特征融合与层次化编码处理多样化音频信号</li>
<li><strong>视频时序建模</strong>：帧采样策略与时空注意力分解平衡效率与效果</li>
<li><strong>跨模态注意力</strong>：早期vs晚期融合、MoME专家混合、计算效率优化</li>
</ol>
<p><strong>💡 实用公式总结</strong>：</p>
<ul>
<li>InfoNCE 损失：$\mathcal{L} = -\log \frac{\exp(s_{ii}/\tau)}{\sum_j \exp(s_{ij}/\tau)}$</li>
<li>时空复杂度优化：$O(T^2S^2) \rightarrow O(T^2 + S^2)$</li>
<li>负载均衡约束：$\mathcal{L}_{balance} = \text{Var}(usage) + ||\frac{1}{K} - usage||_1$</li>
</ul>
<p><strong>🔬 进阶探索方向</strong>：</p>
<ul>
<li>3D 视觉理解的多视角融合</li>
<li>实时多模态流处理优化</li>
<li>神经架构搜索（NAS）用于跨模态设计</li>
<li>模态缺失情况下的鲁棒推理</li>
</ul>
<h2 id="_3">练习题</h2>
<h3 id="_4">基础题</h3>
<p><strong>练习 5.1</strong>：实现一个简化版的 CLIP 模型，包括图像编码器、文本编码器和对比损失。</p>
<ul>
<li><em>Hint</em>：使用预训练的 ResNet50 和 BERT-base，关注投影层设计</li>
</ul>
<details>
<summary>参考答案</summary>
<p>关键实现要点：</p>
<ol>
<li>图像编码器输出需要全局池化得到 [B, D] 特征</li>
<li>文本编码器使用 [CLS] token 或平均池化</li>
<li>投影到相同维度空间（如 512）</li>
<li>对比损失需要计算 batch 内所有配对的相似度</li>
<li>温度参数初始化为 0.07，可学习</li>
</ol>
</details>
<p><strong>练习 5.2</strong>：设计一个帧采样策略，从 10 分钟的视频中采样 32 帧用于动作识别。</p>
<ul>
<li><em>Hint</em>：考虑 TSN 的分段采样思想</li>
</ul>
<details>
<summary>参考答案</summary>
<p>建议策略：</p>
<ol>
<li>将视频分为 32 个等长片段</li>
<li>每个片段随机采样 1 帧（训练时）或中间帧（测试时）</li>
<li>对于动作密集区域，可使用光流幅度加权采样</li>
<li>保持最小 0.5 秒间隔避免冗余</li>
</ol>
</details>
<p><strong>练习 5.3</strong>：计算 ViT-L/14 处理 224×224 图像时产生的 token 数量。</p>
<ul>
<li><em>Hint</em>：patch size = 14</li>
</ul>
<details>
<summary>参考答案</summary>
<p>计算过程：</p>
<ul>
<li>图像尺寸：224 × 224</li>
<li>Patch 尺寸：14 × 14</li>
<li>每个维度的 patch 数：224 / 14 = 16</li>
<li>总 patch 数：16 × 16 = 256</li>
<li>加上 [CLS] token：256 + 1 = 257 tokens</li>
</ul>
</details>
<p><strong>练习 5.4</strong>：比较早期融合和晚期融合在参数量和计算量上的差异。</p>
<ul>
<li><em>Hint</em>：假设视觉和文本序列长度分别为 Nv 和 Nt</li>
</ul>
<details>
<summary>参考答案</summary>
<p>分析：</p>
<ul>
<li>早期融合：</li>
<li>序列长度：Nv + Nt</li>
<li>自注意力复杂度：O((Nv + Nt)²)</li>
<li>
<p>参数共享，总参数量较少</p>
</li>
<li>
<p>晚期融合：</p>
</li>
<li>独立处理复杂度：O(Nv²) + O(Nt²)</li>
<li>参数量约为早期融合的 2 倍</li>
<li>当 Nv ≈ Nt 时，计算量约为早期融合的 50%</li>
</ul>
</details>
<h3 id="_5">挑战题</h3>
<p><strong>练习 5.5</strong>：设计一个自适应的模态专家分配策略，根据输入动态决定使用哪些专家。</p>
<ul>
<li><em>Hint</em>：考虑稀疏激活和负载均衡</li>
</ul>
<details>
<summary>参考答案</summary>
<p>设计要点：</p>
<ol>
<li>使用可学习的路由网络，输出每个专家的分数</li>
<li>Top-k 选择（k=2），保持稀疏性</li>
<li>添加负载均衡损失：鼓励均匀使用所有专家</li>
<li>引入容量限制：每个专家处理的 token 数上限</li>
<li>使用 Gumbel-Softmax 实现可微分的离散选择</li>
<li>辅助损失：最小化未使用专家的比例</li>
</ol>
</details>
<p><strong>练习 5.6</strong>：如何处理视频中的音画不同步问题？设计一个对齐机制。</p>
<ul>
<li><em>Hint</em>：考虑学习时间偏移</li>
</ul>
<details>
<summary>参考答案</summary>
<p>解决方案：</p>
<ol>
<li>可学习的时间偏移预测器，输出音频相对视频的偏移量</li>
<li>使用互相关计算音视频特征的最佳对齐点</li>
<li>循环一致性约束：视频→音频→视频应该回到原点</li>
<li>对比学习：同步的音视频对作为正样本</li>
<li>滑动窗口注意力，允许 ±2 秒的偏移搜索</li>
<li>数据增强：训练时人为引入时间偏移</li>
</ol>
</details>
<p><strong>练习 5.7</strong>：设计一个 token 压缩策略，将 1024 个视觉 tokens 压缩到 64 个。</p>
<ul>
<li><em>Hint</em>：考虑语义聚类和重要性评分</li>
</ul>
<details>
<summary>参考答案</summary>
<p>方案设计：</p>
<ol>
<li>学习 64 个可学习的聚类中心</li>
<li>计算每个 token 到聚类中心的相似度</li>
<li>Soft assignment：每个 token 软分配到多个中心</li>
<li>加权聚合：根据分配权重聚合 tokens</li>
<li>保留部分原始重要 tokens（如 [CLS]）</li>
<li>渐进压缩：1024→256→64，避免信息损失过快</li>
<li>辅助重建损失：压缩后应能重建原始特征</li>
</ol>
</details>
<p><strong>练习 5.8</strong>：如何在保持性能的前提下，将跨模态注意力的内存占用降低 75%？</p>
<ul>
<li><em>Hint</em>：结合多种优化技术</li>
</ul>
<details>
<summary>参考答案</summary>
<p>综合优化策略：</p>
<ol>
<li><strong>Flash Attention</strong>：融合计算，减少中间结果存储（-50%）</li>
<li><strong>低秩分解</strong>：将 768 维降到 128 维计算（-70%）</li>
<li><strong>块稀疏模式</strong>：只计算局部和全局注意力（-60%）</li>
<li><strong>梯度检查点</strong>：用计算换内存（-40%）</li>
<li><strong>混合精度</strong>：FP16 计算，FP32 累加（-50%）</li>
<li><strong>KV 缓存复用</strong>：跨层共享 key-value（-30%）</li>
</ol>
<p>组合使用可达到 75% 以上的内存节省，性能损失 &lt;2%。</p>
</details>
<h2 id="_6">常见陷阱与错误</h2>
<p>⚠️ <strong>常见错误与调试技巧</strong>：</p>
<ol>
<li>
<p><strong>模态不平衡问题</strong>
   - 错误：一个模态主导，其他模态被忽略
   - 解决：分别计算每个模态的梯度范数，动态调整学习率</p>
</li>
<li>
<p><strong>视觉 Token 数量爆炸</strong>
   - 错误：高分辨率图像产生过多 tokens
   - 解决：使用 Perceiver 降维或分层处理</p>
</li>
<li>
<p><strong>音视频不同步</strong>
   - 错误：假设音视频完全对齐
   - 解决：允许可学习的时间偏移，使用 DTW 对齐</p>
</li>
<li>
<p><strong>负样本采样偏差</strong>
   - 错误：负样本过于简单或过于困难
   - 解决：维护难度分布，curriculum 采样</p>
</li>
<li>
<p><strong>跨模态梯度不稳定</strong>
   - 错误：不同模态梯度尺度差异大
   - 解决：分模态的 gradient clipping 和归一化</p>
</li>
<li>
<p><strong>推理速度瓶颈</strong>
   - 错误：直接使用训练架构部署
   - 解决：知识蒸馏到轻量级学生模型</p>
</li>
<li>
<p><strong>数据泄露风险</strong>
   - 错误：测试集的音视频对出现在训练集
   - 解决：基于视频 ID 而非帧级别划分数据集</p>
</li>
<li>
<p><strong>计算图内存泄露</strong>
   - 错误：保存了过多的中间激活值
   - 解决：及时 detach()，使用 gradient checkpointing</p>
</li>
</ol>
            </article>
            
            <nav class="page-nav"><a href="chapter4.html" class="nav-link prev">← 第四章：纯语言任务实验设计</a><a href="chapter6.html" class="nav-link next">第六章：强化学习与人类反馈 →</a></nav>
        </main>
    </div>
</body>
</html>