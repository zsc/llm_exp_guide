<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第七章：训练循环与迭代优化</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">LLM 后训练实验设计指南</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第一章：后训练基础理论</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第二章：实验代码基础设施</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第三章：数据工程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第四章：纯语言任务实验设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第五章：多模态任务实验设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第六章：强化学习与人类反馈</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第七章：训练循环与迭代优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第八章：评估与基准测试</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第九章：生产部署与监控</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十章：案例研究与最佳实践</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="_1">第七章：训练循环与迭代优化</h1>
<p>本章深入探讨 LLM 后训练的端到端训练流程设计，重点关注如何构建高效的迭代优化系统。我们将从数据-标注-训练-评估的完整循环开始，逐步深入到主动学习、模型合并、超参数优化以及分布式训练的工程实践。通过本章学习，您将掌握构建可扩展、高效率训练系统的核心方法论。</p>
<h2 id="71-">7.1 数据-标注-训练-评估循环设计</h2>
<p>后训练的成功很大程度上取决于能否建立高效的迭代循环。与预训练的单次大规模训练不同，后训练需要持续的数据收集、标注、训练和评估，形成一个不断改进的闭环系统。</p>
<h3 id="711">7.1.1 循环架构的基本原理</h3>
<p>数据-标注-训练-评估（DLTE）循环是后训练的核心架构模式。其基本流程如下：</p>
<div class="codehilite"><pre><span></span><code>    ┌─────────────┐
    │   数据收集   │ ← 用户反馈/合成生成
    └──────┬──────┘
           │
    ┌──────▼──────┐
    │   数据标注   │ ← 人工/模型辅助
    └──────┬──────┘
           │
    ┌──────▼──────┐
    │   模型训练   │ ← SFT/RLHF/DPO
    └──────┬──────┘
           │
    ┌──────▼──────┐
    │   模型评估   │ → 指标监控
    └──────┬──────┘
           │
    ┌──────▼──────┐
    │  部署/迭代   │
    └─────────────┘
</code></pre></div>

<p><strong>关键设计原则</strong>：</p>
<ol>
<li><strong>增量式更新</strong>：每次循环不必处理全量数据，而是关注新增和高价值数据</li>
<li><strong>快速迭代</strong>：缩短循环周期，加快反馈速度（目标：日级别迭代）</li>
<li><strong>质量门控</strong>：每个环节设置质量检查点，防止低质量数据污染</li>
<li><strong>可追溯性</strong>：数据来源、标注历史、训练配置完全可追溯</li>
</ol>
<h3 id="712">7.1.2 数据流管道设计</h3>
<p>高效的数据流管道需要解决数据收集、预处理、存储和版本管理等挑战：</p>
<p><strong>数据收集策略</strong>：</p>
<ul>
<li><strong>用户交互数据</strong>：收集真实用户查询和反馈</li>
<li><strong>合成数据生成</strong>：使用更强模型生成训练数据</li>
<li><strong>困难案例挖掘</strong>：主动收集模型表现不佳的案例</li>
<li><strong>领域数据爬取</strong>：针对特定领域的数据收集</li>
</ul>
<p><strong>管道架构设计</strong>：</p>
<div class="codehilite"><pre><span></span><code>输入源 → 数据验证 → 去重清洗 → 格式标准化 → 数据池
  ↓         ↓          ↓           ↓          ↓
监控      质量报告   清洗日志    schema检查  版本控制
</code></pre></div>

<p><strong>数据版本管理</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 数据版本配置示例</span>
<span class="n">data_version</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;version&quot;</span><span class="p">:</span> <span class="s2">&quot;v2.3.1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;base_dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;v2.3.0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;incremental&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;user_feedback&quot;</span><span class="p">:</span> <span class="mi">50000</span><span class="p">,</span>
        <span class="s2">&quot;synthetic&quot;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>
        <span class="s2">&quot;hard_negatives&quot;</span><span class="p">:</span> <span class="mi">20000</span>
    <span class="p">},</span>
    <span class="s2">&quot;filters_applied&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;deduplication&quot;</span><span class="p">,</span>
        <span class="s2">&quot;quality_threshold_0.8&quot;</span><span class="p">,</span>
        <span class="s2">&quot;safety_filter&quot;</span>
    <span class="p">],</span>
    <span class="s2">&quot;split_ratio&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="s2">&quot;val&quot;</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span>
        <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="mf">0.05</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="713">7.1.3 标注系统集成</h3>
<p>标注是后训练数据质量的关键环节。现代标注系统需要平衡效率、质量和成本：</p>
<p><strong>标注模式选择</strong>：</p>
<ol>
<li>
<p><strong>纯人工标注</strong>：
   - 优点：质量高，可处理复杂任务
   - 缺点：成本高，速度慢，一致性难保证
   - 适用：安全相关、高价值任务</p>
</li>
<li>
<p><strong>模型辅助标注</strong>：
   - 优点：效率高，成本低
   - 缺点：可能传播模型偏见
   - 适用：大规模初筛、简单分类任务</p>
</li>
<li>
<p><strong>混合标注策略</strong>：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code>原始数据 → 模型预标注 → 人工审核/修正 → 质量采样检查 → 最终标注
             ↓              ↓                ↓
         置信度评分    标注者一致性    随机质检(5-10%)
</code></pre></div>

<p><strong>标注规范设计要点</strong>：</p>
<ul>
<li><strong>清晰的任务定义</strong>：避免歧义，提供充分示例</li>
<li><strong>层次化标注</strong>：将复杂任务分解为简单子任务</li>
<li><strong>动态规范更新</strong>：根据标注过程中的问题持续优化规范</li>
<li><strong>标注者培训</strong>：系统化培训和认证机制</li>
</ul>
<h3 id="714">7.1.4 训练触发机制</h3>
<p>确定何时触发新一轮训练是循环设计的关键决策点：</p>
<p><strong>触发策略类型</strong>：</p>
<ol>
<li>
<p><strong>定时触发</strong>：
   - 固定周期（如每日、每周）
   - 优点：可预测，便于资源规划
   - 缺点：可能浪费计算资源</p>
</li>
<li>
<p><strong>数据量触发</strong>：
   - 累积足够新数据后触发（如10万条）
   - 优点：确保每次训练有足够增量
   - 缺点：时间不可控</p>
</li>
<li>
<p><strong>性能触发</strong>：
   - 监控指标下降到阈值时触发
   - 优点：按需训练，针对性强
   - 缺点：需要可靠的在线监控</p>
</li>
<li>
<p><strong>混合触发策略</strong>：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">should_trigger_training</span><span class="p">():</span>
    <span class="n">conditions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">data_accumulated</span> <span class="o">&gt;</span> <span class="n">min_data_threshold</span><span class="p">,</span>
        <span class="n">days_since_last_training</span> <span class="o">&gt;</span> <span class="n">max_wait_days</span><span class="p">,</span>
        <span class="n">performance_degradation</span> <span class="o">&gt;</span> <span class="n">alert_threshold</span><span class="p">,</span>
        <span class="n">critical_bug_fixes_pending</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">conditions</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">all</span><span class="p">(</span><span class="n">conditions</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
</code></pre></div>

<h3 id="715">7.1.5 评估反馈路径</h3>
<p>评估结果需要有效反馈到循环的各个环节：</p>
<p><strong>反馈机制设计</strong>：</p>
<div class="codehilite"><pre><span></span><code>评估结果 ──┬── 数据收集：指导困难样本收集
          ├── 标注优化：调整标注规范
          ├── 训练策略：调整损失权重
          └── 模型选择：决定部署版本
</code></pre></div>

<p><strong>关键指标监控</strong>：</p>
<ol>
<li><strong>任务指标</strong>：准确率、BLEU、ROUGE等</li>
<li><strong>质量指标</strong>：响应相关性、事实准确性</li>
<li><strong>安全指标</strong>：有害内容率、偏见程度</li>
<li><strong>效率指标</strong>：推理延迟、吞吐量</li>
</ol>
<p><strong>自动化决策规则</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_and_decide</span><span class="p">(</span><span class="n">model_metrics</span><span class="p">):</span>
    <span class="n">decisions</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;deploy&quot;</span><span class="p">:</span> <span class="nb">all</span><span class="p">([</span>
            <span class="n">model_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">baseline</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.02</span><span class="p">,</span>
            <span class="n">model_metrics</span><span class="p">[</span><span class="s2">&quot;safety_score&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.95</span><span class="p">,</span>
            <span class="n">model_metrics</span><span class="p">[</span><span class="s2">&quot;latency_p99&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">baseline</span><span class="p">[</span><span class="s2">&quot;latency_p99&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.1</span>
        <span class="p">]),</span>
        <span class="s2">&quot;collect_more_data&quot;</span><span class="p">:</span> <span class="n">model_metrics</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">target_accuracy</span><span class="p">,</span>
        <span class="s2">&quot;adjust_training&quot;</span><span class="p">:</span> <span class="n">model_metrics</span><span class="p">[</span><span class="s2">&quot;loss_variance&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">,</span>
        <span class="s2">&quot;rollback&quot;</span><span class="p">:</span> <span class="n">model_metrics</span><span class="p">[</span><span class="s2">&quot;safety_score&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.9</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">decisions</span>
</code></pre></div>

<p><strong>持续改进机制</strong>：</p>
<ul>
<li><strong>A/B测试</strong>：新模型与基线模型对比</li>
<li><strong>渐进式发布</strong>：逐步扩大新模型的流量比例</li>
<li><strong>回滚机制</strong>：性能下降时快速恢复</li>
<li><strong>案例分析</strong>：定期分析失败案例，优化数据收集</li>
</ul>
<h2 id="72">7.2 主动学习与数据选择策略</h2>
<p>在后训练中，并非所有数据都具有同等价值。主动学习（Active Learning）帮助我们识别和优先处理最有价值的数据，从而以最小的标注成本获得最大的模型改进。</p>
<h3 id="721">7.2.1 不确定性采样</h3>
<p>不确定性采样是主动学习的核心策略，通过选择模型最不确定的样本进行标注：</p>
<p><strong>不确定性度量方法</strong>：</p>
<ol>
<li>
<p><strong>预测熵（Entropy）</strong>：
   $$H(x) = -\sum_{i=1}^{K} p(y_i|x) \log p(y_i|x)$$
其中 $K$ 是类别数，$p(y_i|x)$ 是模型对类别 $i$ 的预测概率</p>
</li>
<li>
<p><strong>最小置信度（Least Confidence）</strong>：
$$LC(x) = 1 - \max_i p(y_i|x)$$</p>
</li>
<li>
<p><strong>边际采样（Margin Sampling）</strong>：
$$MS(x) = p(y_1|x) - p(y_2|x)$$
其中 $y_1, y_2$ 是概率最高的两个类别</p>
</li>
</ol>
<p><strong>LLM 特定的不确定性估计</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_llm_uncertainty</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;通过多次采样估计 LLM 的不确定性&quot;&quot;&quot;</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">response</span><span class="p">,</span> <span class="n">lp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span> 
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">return_log_probs</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="n">responses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">log_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lp</span><span class="p">)</span>

    <span class="c1"># 计算响应多样性</span>
    <span class="n">unique_responses</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">responses</span><span class="p">))</span>
    <span class="n">diversity_score</span> <span class="o">=</span> <span class="n">unique_responses</span> <span class="o">/</span> <span class="n">num_samples</span>

    <span class="c1"># 计算平均对数概率方差</span>
    <span class="n">avg_log_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">lp</span><span class="p">)</span> <span class="k">for</span> <span class="n">lp</span> <span class="ow">in</span> <span class="n">log_probs</span><span class="p">])</span>
    <span class="n">log_prob_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">lp</span><span class="p">)</span> <span class="k">for</span> <span class="n">lp</span> <span class="ow">in</span> <span class="n">log_probs</span><span class="p">])</span>

    <span class="n">uncertainty</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;diversity&quot;</span><span class="p">:</span> <span class="n">diversity_score</span><span class="p">,</span>
        <span class="s2">&quot;avg_confidence&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">avg_log_prob</span><span class="p">),</span>
        <span class="s2">&quot;confidence_variance&quot;</span><span class="p">:</span> <span class="n">log_prob_variance</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">uncertainty</span>
</code></pre></div>

<p><strong>实践技巧</strong>：</p>
<ul>
<li><strong>温度调节</strong>：使用不同温度多次采样，高不确定性样本的输出差异更大</li>
<li><strong>注意力分析</strong>：分析注意力权重的分散程度，识别模型"犹豫"的位置</li>
<li><strong>早期层特征</strong>：利用中间层表示的变化评估不确定性</li>
</ul>
<h3 id="722">7.2.2 多样性选择</h3>
<p>仅选择不确定样本可能导致数据冗余。多样性选择确保覆盖不同的数据分布：</p>
<p><strong>多样性策略</strong>：</p>
<ol>
<li><strong>聚类采样</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">diversity_sampling</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1"># 先聚类</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">)</span>
    <span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

    <span class="n">selected_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">samples_per_cluster</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="n">n_clusters</span>

    <span class="k">for</span> <span class="n">cluster_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="n">cluster_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cluster_labels</span> <span class="o">==</span> <span class="n">cluster_id</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># 从每个簇中选择最接近中心的样本</span>
        <span class="n">cluster_center</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="n">cluster_id</span><span class="p">]</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
            <span class="n">embeddings</span><span class="p">[</span><span class="n">cluster_indices</span><span class="p">]</span> <span class="o">-</span> <span class="n">cluster_center</span><span class="p">,</span> 
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">selected</span> <span class="o">=</span> <span class="n">cluster_indices</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">distances</span><span class="p">)[:</span><span class="n">samples_per_cluster</span><span class="p">]]</span>
        <span class="n">selected_indices</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">selected_indices</span>
</code></pre></div>

<ol start="2">
<li>
<p><strong>最大边际相关性（MMR）</strong>：
$$MMR = \arg\max_{d_i \in R \setminus S} [\lambda \cdot Sim_1(d_i, q) - (1-\lambda) \cdot \max_{d_j \in S} Sim_2(d_i, d_j)]$$
平衡与查询的相关性和与已选样本的差异性</p>
</li>
<li>
<p><strong>子模函数优化</strong>：
   利用子模函数的递减边际效用特性，贪心选择提供最大信息增益的样本</p>
</li>
</ol>
<p><strong>实现考虑</strong>：</p>
<ul>
<li><strong>嵌入空间选择</strong>：使用任务相关的嵌入（如最后一层 vs 中间层）</li>
<li><strong>增量更新</strong>：维护已选样本的摘要统计，避免重复计算</li>
<li><strong>批量选择</strong>：一次选择多个样本，考虑样本间的相互影响</li>
</ul>
<h3 id="723">7.2.3 困难样本挖掘</h3>
<p>困难样本（Hard Examples）是模型容易出错的案例，对改进模型性能至关重要：</p>
<p><strong>困难样本识别方法</strong>：</p>
<ol>
<li><strong>损失排序</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">find_hard_examples</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">percentile</span><span class="o">=</span><span class="mi">95</span><span class="p">):</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

    <span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">percentile</span><span class="p">)</span>
    <span class="n">hard_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">losses</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">hard_indices</span>
</code></pre></div>

<ol start="2">
<li><strong>对抗样本生成</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">generate_adversarial_prompts</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">base_prompt</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;生成对抗性提示&quot;&quot;&quot;</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">base_prompt</span><span class="p">)</span>
    <span class="n">embedding</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_target_loss</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># 对嵌入添加扰动</span>
    <span class="n">perturbation</span> <span class="o">=</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">embedding</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span>
    <span class="n">adversarial_embedding</span> <span class="o">=</span> <span class="n">embedding</span> <span class="o">+</span> <span class="n">perturbation</span>

    <span class="c1"># 解码回文本（近似）</span>
    <span class="n">adversarial_prompt</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">adversarial_embedding</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">adversarial_prompt</span>
</code></pre></div>

<ol start="3">
<li><strong>模型分歧挖掘</strong>：
   比较不同模型或同一模型不同版本的预测差异</li>
</ol>
<p><strong>困难样本的类型</strong>：</p>
<ul>
<li><strong>边界案例</strong>：接近决策边界的样本</li>
<li><strong>长尾样本</strong>：罕见但重要的案例</li>
<li><strong>组合复杂性</strong>：需要多步推理的样本</li>
<li><strong>领域偏移</strong>：与训练分布差异较大的样本</li>
</ul>
<h3 id="724">7.2.4 课程学习设计</h3>
<p>课程学习（Curriculum Learning）通过控制样本的学习顺序来提高训练效率：</p>
<p><strong>课程设计策略</strong>：</p>
<ol>
<li><strong>难度递增课程</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">CurriculumScheduler</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">difficulty_scores</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">difficulty_scores</span> <span class="o">=</span> <span class="n">difficulty_scores</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_difficulty</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">max_epoch</span><span class="p">):</span>
        <span class="c1"># 线性增加难度阈值</span>
        <span class="n">difficulty_threshold</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">/</span> <span class="n">max_epoch</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span>

        <span class="c1"># 选择难度低于阈值的样本</span>
        <span class="n">valid_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">difficulty_scores</span> <span class="o">&lt;=</span> <span class="n">difficulty_threshold</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 加权采样，优先选择接近阈值的样本</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">difficulty_scores</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">]</span> <span class="o">-</span> <span class="n">difficulty_threshold</span> <span class="o">*</span> <span class="mf">0.8</span>
        <span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">/</span> <span class="n">weights</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="n">valid_indices</span><span class="p">,</span> 
            <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
            <span class="n">p</span><span class="o">=</span><span class="n">weights</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">]</span>
</code></pre></div>

<ol start="2">
<li><strong>自适应课程</strong>：
   根据模型当前性能动态调整课程：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">adaptive_curriculum</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">performance_history</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">performance_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="c1"># 如果性能停滞，增加难度</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">performance_history</span><span class="p">)</span> <span class="o">==</span> <span class="n">window_size</span><span class="p">:</span>
            <span class="n">recent_improvement</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">performance_history</span><span class="p">)[:</span><span class="mi">500</span><span class="p">])</span> <span class="o">-</span> 
                <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">performance_history</span><span class="p">)[</span><span class="mi">500</span><span class="p">:])</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">recent_improvement</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="c1"># 引入更难的样本</span>
                <span class="n">increase_difficulty_level</span><span class="p">()</span>
</code></pre></div>

<ol start="3">
<li><strong>反课程学习</strong>：
   某些任务中，先学习困难样本可能更有效</li>
</ol>
<p><strong>课程学习的关键考虑</strong>：</p>
<ul>
<li><strong>难度评估</strong>：准确评估样本难度是关键</li>
<li><strong>过渡平滑</strong>：避免难度跳跃过大</li>
<li><strong>遗忘问题</strong>：定期回顾简单样本，防止灾难性遗忘</li>
</ul>
<h3 id="725">7.2.5 数据价值评估</h3>
<p>量化每个数据点对模型改进的贡献，优化数据投资回报：</p>
<p><strong>数据价值度量方法</strong>：</p>
<ol>
<li>
<p><strong>留一法影响函数（Leave-One-Out Influence）</strong>：
$$\mathcal{I}(z) = \nabla_\theta \mathcal{L}(z)^T H^{-1} \nabla_\theta \mathcal{L}(z_{test})$$
其中 $H$ 是 Hessian 矩阵，$z$ 是训练样本，$z_{test}$ 是测试样本</p>
</li>
<li>
<p><strong>数据 Shapley 值</strong>：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_data_shapley</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">shapley_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="c1"># 随机排列</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

        <span class="n">prev_score</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_set</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">perm</span><span class="p">):</span>
            <span class="c1"># 增量训练</span>
            <span class="n">model</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            <span class="n">new_score</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_set</span><span class="p">)</span>

            <span class="c1"># 边际贡献</span>
            <span class="n">shapley_values</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">new_score</span> <span class="o">-</span> <span class="n">prev_score</span><span class="p">)</span>
            <span class="n">prev_score</span> <span class="o">=</span> <span class="n">new_score</span>

    <span class="k">return</span> <span class="n">shapley_values</span> <span class="o">/</span> <span class="n">n_iterations</span>
</code></pre></div>

<ol start="3">
<li><strong>梯度相似性</strong>：
   衡量训练样本梯度与验证集梯度的一致性</li>
</ol>
<p><strong>数据价值的应用</strong>：</p>
<ul>
<li><strong>数据购买决策</strong>：确定哪些数据值得购买/标注</li>
<li><strong>数据清理优先级</strong>：优先清理高价值数据</li>
<li><strong>样本权重调整</strong>：根据价值调整训练权重</li>
<li><strong>数据归因</strong>：追踪模型能力来源</li>
</ul>
<p><strong>实践建议</strong>：</p>
<ol>
<li><strong>组合策略</strong>：结合不确定性、多样性和困难度</li>
<li><strong>动态调整</strong>：随训练进展调整选择策略</li>
<li><strong>成本考虑</strong>：平衡数据价值和获取成本</li>
<li><strong>在线更新</strong>：实时更新数据价值估计</li>
</ol>
<h2 id="73">7.3 模型合并与集成学习</h2>
<p>模型合并和集成学习技术允许我们组合多个模型的优势，在不增加推理成本的情况下提升性能。这在后训练中特别有价值，因为我们经常需要整合不同任务或领域的专门化模型。</p>
<h3 id="731">7.3.1 参数空间合并技术</h3>
<p>直接在参数空间合并模型是最直接的方法，但需要仔细处理以保持模型质量：</p>
<p><strong>基础合并方法</strong>：</p>
<ol>
<li>
<p><strong>线性插值（LERP）</strong>：
$$\theta_{merged} = \alpha \cdot \theta_A + (1-\alpha) \cdot \theta_B$$
其中 $\alpha \in [0,1]$ 是插值系数</p>
</li>
<li>
<p><strong>球面线性插值（SLERP）</strong>：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">slerp</span><span class="p">(</span><span class="n">theta_A</span><span class="p">,</span> <span class="n">theta_B</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;球面线性插值，保持参数向量的范数&quot;&quot;&quot;</span>
    <span class="c1"># 归一化参数向量</span>
    <span class="n">theta_A_norm</span> <span class="o">=</span> <span class="n">theta_A</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">theta_A</span><span class="p">)</span>
    <span class="n">theta_B_norm</span> <span class="o">=</span> <span class="n">theta_B</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">theta_B</span><span class="p">)</span>

    <span class="c1"># 计算夹角</span>
    <span class="n">dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta_A_norm</span><span class="p">,</span> <span class="n">theta_B_norm</span><span class="p">)</span>
    <span class="n">omega</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">dot_product</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># 球面插值</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">omega</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">theta_A</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta_B</span>

    <span class="n">sin_omega</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">omega</span><span class="p">)</span>
    <span class="n">theta_merged</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">omega</span><span class="p">)</span> <span class="o">/</span> <span class="n">sin_omega</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta_A</span> <span class="o">+</span> \
                  <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">omega</span><span class="p">)</span> <span class="o">/</span> <span class="n">sin_omega</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta_B</span>

    <span class="k">return</span> <span class="n">theta_merged</span>
</code></pre></div>

<ol start="3">
<li>
<p><strong>加权平均</strong>：
$$\theta_{merged} = \frac{\sum_{i=1}^{N} w_i \cdot \theta_i}{\sum_{i=1}^{N} w_i}$$
<strong>高级合并技术</strong>：</p>
</li>
<li>
<p><strong>Fisher 加权合并</strong>：
   使用 Fisher 信息矩阵作为重要性权重：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fisher_weighted_merge</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;基于 Fisher 信息的参数合并&quot;&quot;&quot;</span>
    <span class="n">fisher_matrices</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
        <span class="c1"># 计算 Fisher 信息矩阵（对角近似）</span>
        <span class="n">fisher</span> <span class="o">=</span> <span class="n">compute_fisher_diagonal</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
        <span class="n">fisher_matrices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fisher</span><span class="p">)</span>

    <span class="c1"># 归一化 Fisher 权重</span>
    <span class="n">total_fisher</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">fisher_matrices</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="o">/</span> <span class="n">total_fisher</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">fisher_matrices</span><span class="p">]</span>

    <span class="c1"># 加权合并</span>
    <span class="n">merged_params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
        <span class="n">merged_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">w</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">param_name</span><span class="p">]</span> 
            <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">models</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">merged_params</span>
</code></pre></div>

<ol start="2">
<li><strong>RegMean（正则化均值）</strong>：
   通过添加正则化项防止合并后的参数偏离过远：
$$\theta_{merged} = \arg\min_\theta \sum_{i=1}^{N} |\theta - \theta_i|^2 + \lambda R(\theta)$$</li>
</ol>
<h3 id="732">7.3.2 任务向量与模型算术</h3>
<p>任务向量（Task Vectors）将模型能力表示为参数空间中的向量，实现模型能力的算术运算：</p>
<p><strong>任务向量定义</strong>：
$$\tau = \theta_{finetuned} - \theta_{pretrained}$$</p>
<p><strong>模型算术运算</strong>：</p>
<ol>
<li><strong>能力添加</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_capabilities</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">task_vectors</span><span class="p">,</span> <span class="n">scaling_factors</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;向基础模型添加多个任务能力&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">scaling_factors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scaling_factors</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_vectors</span><span class="p">)</span>

    <span class="n">merged_params</span> <span class="o">=</span> <span class="n">base_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">merged_params</span><span class="p">:</span>
        <span class="c1"># 累加任务向量</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="n">scale</span> <span class="o">*</span> <span class="n">tv</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> 
            <span class="k">for</span> <span class="n">scale</span><span class="p">,</span> <span class="n">tv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">scaling_factors</span><span class="p">,</span> <span class="n">task_vectors</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">merged_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">+=</span> <span class="n">delta</span>

    <span class="k">return</span> <span class="n">merged_params</span>
</code></pre></div>

<ol start="2">
<li><strong>能力删除</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">remove_capability</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">task_vector</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;从模型中移除特定能力&quot;&quot;&quot;</span>
    <span class="n">updated_params</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">updated_params</span><span class="p">:</span>
        <span class="n">updated_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">-=</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">task_vector</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">updated_params</span>
</code></pre></div>

<ol start="3">
<li><strong>能力组合的冲突检测</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">detect_task_conflicts</span><span class="p">(</span><span class="n">task_vectors</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;检测任务向量之间的冲突&quot;&quot;&quot;</span>
    <span class="n">conflicts</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tv1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">task_vectors</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">tv2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">task_vectors</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:],</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="c1"># 计算余弦相似度</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span>
                <span class="n">flatten</span><span class="p">(</span><span class="n">tv1</span><span class="p">),</span> <span class="n">flatten</span><span class="p">(</span><span class="n">tv2</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># 负相关表示潜在冲突</span>
            <span class="k">if</span> <span class="n">similarity</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">:</span>
                <span class="n">conflicts</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">=</span> <span class="n">similarity</span>

    <span class="k">return</span> <span class="n">conflicts</span>
</code></pre></div>

<p><strong>实践考虑</strong>：</p>
<ul>
<li><strong>缩放因子优化</strong>：通过验证集搜索最优缩放系数</li>
<li><strong>正交化</strong>：确保任务向量相互正交，减少干扰</li>
<li><strong>稀疏化</strong>：只保留重要的参数变化</li>
</ul>
<h3 id="733">7.3.3 层级合并策略</h3>
<p>不同层可能需要不同的合并策略，基于层的功能和重要性：</p>
<p><strong>层级重要性分析</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_layer_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">layer_names</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;计算各层对任务的重要性&quot;&quot;&quot;</span>
    <span class="n">importances</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="n">layer_names</span><span class="p">:</span>
        <span class="c1"># 临时移除层</span>
        <span class="n">original_layer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">())</span>

        <span class="c1"># 评估性能下降</span>
        <span class="n">degraded_performance</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>

        <span class="c1"># 恢复层</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">original_layer</span><span class="p">)</span>
        <span class="n">baseline_performance</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>

        <span class="n">importance</span> <span class="o">=</span> <span class="n">baseline_performance</span> <span class="o">-</span> <span class="n">degraded_performance</span>
        <span class="n">importances</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">importance</span>

    <span class="k">return</span> <span class="n">importances</span>
</code></pre></div>

<p><strong>分层合并策略</strong>：</p>
<ol>
<li><strong>底层共享，高层特化</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">hierarchical_merge</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">split_layer</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;低层参数平均，高层保持特化&quot;&quot;&quot;</span>
    <span class="n">merged_model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">merged_model</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">layer_idx</span> <span class="o">&lt;</span> <span class="n">split_layer</span><span class="p">:</span>
            <span class="c1"># 低层：平均合并</span>
            <span class="n">merged_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">average_layers</span><span class="p">(</span>
                <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 高层：选择最佳或保持独立</span>
            <span class="n">best_model_idx</span> <span class="o">=</span> <span class="n">select_best_for_layer</span><span class="p">(</span>
                <span class="n">models</span><span class="p">,</span> <span class="n">layer_idx</span>
            <span class="p">)</span>
            <span class="n">merged_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">models</span><span class="p">[</span><span class="n">best_model_idx</span><span class="p">]</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">merged_model</span>
</code></pre></div>

<ol start="2">
<li><strong>注意力头选择性合并</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">merge_attention_heads</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">importance_threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;根据重要性选择性合并注意力头&quot;&quot;&quot;</span>
    <span class="n">merged_attention</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">n_heads</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">n_heads</span>
    <span class="k">for</span> <span class="n">head_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_heads</span><span class="p">):</span>
        <span class="n">head_candidates</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">m</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">heads</span><span class="p">[</span><span class="n">head_idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span>
        <span class="p">]</span>

        <span class="c1"># 评估每个头的重要性</span>
        <span class="n">importances</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">evaluate_head_importance</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">head_candidates</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">importances</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">importance_threshold</span><span class="p">:</span>
            <span class="c1"># 选择最重要的头</span>
            <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">importances</span><span class="p">)</span>
            <span class="n">merged_attention</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">head_candidates</span><span class="p">[</span><span class="n">best_idx</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 低重要性头可以平均</span>
            <span class="n">merged_attention</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">average_heads</span><span class="p">(</span><span class="n">head_candidates</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">merged_attention</span>
</code></pre></div>

<h3 id="734">7.3.4 集成学习方法</h3>
<p>当无法直接合并参数时，集成多个模型的预测：</p>
<p><strong>集成策略</strong>：</p>
<ol>
<li><strong>加权投票</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">WeightedEnsemble</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">models</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="ow">or</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_data</span><span class="p">):</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
            <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span> <span class="o">*</span> <span class="n">pred</span><span class="p">)</span>

        <span class="c1"># 加权平均</span>
        <span class="n">ensemble_pred</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

        <span class="c1"># 对于分类任务，可能需要重新归一化</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s1">&#39;classification&#39;</span><span class="p">:</span>
            <span class="n">ensemble_pred</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">ensemble_pred</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ensemble_pred</span>
</code></pre></div>

<ol start="2">
<li><strong>混合专家（MoE）风格</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MixtureOfExperts</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experts</span><span class="p">,</span> <span class="n">gating_network</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experts</span> <span class="o">=</span> <span class="n">experts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gating</span> <span class="o">=</span> <span class="n">gating_network</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 计算门控权重</span>
        <span class="n">gate_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gating</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [batch_size, n_experts]</span>

        <span class="c1"># 获取每个专家的输出</span>
        <span class="n">expert_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
            <span class="n">expert</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">expert</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">experts</span>
        <span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, n_experts, output_dim]</span>

        <span class="c1"># 加权组合</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">gate_weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">expert_outputs</span><span class="p">,</span> 
            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>

<ol start="3">
<li><strong>级联集成</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">cascade_ensemble</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">confidence_threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;按置信度级联使用模型&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
        <span class="n">prediction</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_with_confidence</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">confidence</span> <span class="o">&gt;</span> <span class="n">confidence_threshold</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">prediction</span>

    <span class="c1"># 如果所有模型置信度都低，可以组合预测</span>
    <span class="k">return</span> <span class="n">weighted_ensemble</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
</code></pre></div>

<h3 id="735">7.3.5 合并冲突解决</h3>
<p>处理模型合并中的冲突是确保质量的关键：</p>
<p><strong>冲突类型与解决策略</strong>：</p>
<ol>
<li><strong>参数符号冲突</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">resolve_sign_conflicts</span><span class="p">(</span><span class="n">param_A</span><span class="p">,</span> <span class="n">param_B</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;magnitude&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;解决参数符号相反的冲突&quot;&quot;&quot;</span>
    <span class="n">sign_conflict</span> <span class="o">=</span> <span class="p">(</span><span class="n">param_A</span> <span class="o">*</span> <span class="n">param_B</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;magnitude&#39;</span><span class="p">:</span>
        <span class="c1"># 选择绝对值较大的</span>
        <span class="n">merged</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">param_A</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">param_B</span><span class="p">),</span>
            <span class="n">param_A</span><span class="p">,</span> <span class="n">param_B</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;zero&#39;</span><span class="p">:</span>
        <span class="c1"># 冲突位置置零</span>
        <span class="n">merged</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">sign_conflict</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">param_A</span> <span class="o">+</span> <span class="n">param_B</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;interpolate&#39;</span><span class="p">:</span>
        <span class="c1"># 根据重要性插值</span>
        <span class="n">importance_A</span> <span class="o">=</span> <span class="n">compute_param_importance</span><span class="p">(</span><span class="n">param_A</span><span class="p">)</span>
        <span class="n">importance_B</span> <span class="o">=</span> <span class="n">compute_param_importance</span><span class="p">(</span><span class="n">param_B</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">importance_A</span> <span class="o">/</span> <span class="p">(</span><span class="n">importance_A</span> <span class="o">+</span> <span class="n">importance_B</span><span class="p">)</span>
        <span class="n">merged</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">param_A</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">param_B</span>

    <span class="k">return</span> <span class="n">merged</span>
</code></pre></div>

<ol start="2">
<li><strong>梯度冲突检测与缓解</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">gradient_surgery</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;梯度手术：投影冲突梯度到正交空间&quot;&quot;&quot;</span>
    <span class="n">modified_grads</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">g_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gradients</span><span class="p">):</span>
        <span class="n">g_modified</span> <span class="o">=</span> <span class="n">g_i</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">g_j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gradients</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
                <span class="c1"># 计算余弦相似度</span>
                <span class="n">cos_sim</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">g_i</span><span class="p">,</span> <span class="n">g_j</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">cos_sim</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>  <span class="c1"># 负相关，存在冲突</span>
                    <span class="c1"># 投影到正交空间</span>
                    <span class="n">projection</span> <span class="o">=</span> <span class="p">(</span><span class="n">g_i</span> <span class="o">@</span> <span class="n">g_j</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">g_j</span> <span class="o">@</span> <span class="n">g_j</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">*</span> <span class="n">g_j</span>
                    <span class="n">g_modified</span> <span class="o">=</span> <span class="n">g_modified</span> <span class="o">-</span> <span class="n">projection</span>

        <span class="n">modified_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g_modified</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">modified_grads</span>
</code></pre></div>

<p><strong>合并质量验证</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">validate_merge_quality</span><span class="p">(</span><span class="n">original_models</span><span class="p">,</span> <span class="n">merged_model</span><span class="p">,</span> <span class="n">test_sets</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;验证合并后模型的质量&quot;&quot;&quot;</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;performance_retention&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;capability_preservation&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;emergence_score&#39;</span><span class="p">:</span> <span class="mi">0</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">original</span><span class="p">,</span> <span class="n">test_set</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">original_models</span><span class="p">,</span> <span class="n">test_sets</span><span class="p">):</span>
        <span class="c1"># 性能保持率</span>
        <span class="n">original_score</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">test_set</span><span class="p">)</span>
        <span class="n">merged_score</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">merged_model</span><span class="p">,</span> <span class="n">test_set</span><span class="p">)</span>
        <span class="n">retention</span> <span class="o">=</span> <span class="n">merged_score</span> <span class="o">/</span> <span class="n">original_score</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;performance_retention&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">retention</span><span class="p">)</span>

        <span class="c1"># 能力保留检查</span>
        <span class="n">capability_tests</span> <span class="o">=</span> <span class="n">generate_capability_tests</span><span class="p">(</span><span class="n">original</span><span class="p">)</span>
        <span class="n">preservation</span> <span class="o">=</span> <span class="n">evaluate_capabilities</span><span class="p">(</span><span class="n">merged_model</span><span class="p">,</span> <span class="n">capability_tests</span><span class="p">)</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;capability_preservation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">preservation</span><span class="p">)</span>

    <span class="c1"># 涌现能力（合并后出现的新能力）</span>
    <span class="n">combined_test</span> <span class="o">=</span> <span class="n">combine_test_sets</span><span class="p">(</span><span class="n">test_sets</span><span class="p">)</span>
    <span class="n">emergence</span> <span class="o">=</span> <span class="n">evaluate_emergence</span><span class="p">(</span><span class="n">merged_model</span><span class="p">,</span> <span class="n">combined_test</span><span class="p">,</span> <span class="n">original_models</span><span class="p">)</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;emergence_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">emergence</span>

    <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div>

<h2 id="74">7.4 超参数搜索的实用技巧</h2>
<p>超参数优化是后训练成功的关键因素之一。与预训练相比，后训练的超参数空间更复杂，需要更精细的搜索策略。</p>
<h3 id="741">7.4.1 搜索空间设计</h3>
<p>合理的搜索空间设计可以大幅提高搜索效率：</p>
<p><strong>关键超参数及其范围</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">hyperparameter_space</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># 学习率相关</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;log_uniform&quot;</span><span class="p">,</span>
        <span class="s2">&quot;low&quot;</span><span class="p">:</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="s2">&quot;high&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;峰值学习率&quot;</span>
    <span class="p">},</span>
    <span class="s2">&quot;warmup_ratio&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
        <span class="s2">&quot;low&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;high&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;预热步数比例&quot;</span>
    <span class="p">},</span>

    <span class="c1"># 训练配置</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;choice&quot;</span><span class="p">,</span>
        <span class="s2">&quot;values&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;有效批次大小&quot;</span>
    <span class="p">},</span>
    <span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;choice&quot;</span><span class="p">,</span>
        <span class="s2">&quot;values&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;梯度累积步数&quot;</span>
    <span class="p">},</span>

    <span class="c1"># 正则化</span>
    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;log_uniform&quot;</span><span class="p">,</span>
        <span class="s2">&quot;low&quot;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="s2">&quot;high&quot;</span><span class="p">:</span> <span class="mf">1e-1</span>
    <span class="p">},</span>
    <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
        <span class="s2">&quot;low&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s2">&quot;high&quot;</span><span class="p">:</span> <span class="mf">0.3</span>
    <span class="p">},</span>

    <span class="c1"># RLHF 特定参数</span>
    <span class="s2">&quot;kl_coefficient&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;log_uniform&quot;</span><span class="p">,</span>
        <span class="s2">&quot;low&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
        <span class="s2">&quot;high&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;KL 散度惩罚系数&quot;</span>
    <span class="p">},</span>
    <span class="s2">&quot;clip_range&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
        <span class="s2">&quot;low&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s2">&quot;high&quot;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;PPO 裁剪范围&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>条件依赖关系</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">conditional_hyperparameters</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;处理超参数间的条件依赖&quot;&quot;&quot;</span>
    <span class="c1"># 如果使用 LoRA，添加相关参数</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_lora&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lora_rank&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_from</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lora_alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lora_rank&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="n">config</span><span class="p">[</span><span class="s2">&quot;lora_dropout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_from</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="c1"># 学习率与批次大小的关系</span>
    <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">:</span>
        <span class="n">config</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1"># 梯度累积与实际批次大小</span>
    <span class="n">config</span><span class="p">[</span><span class="s2">&quot;effective_batch_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">config</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">config</span>
</code></pre></div>

<p><strong>搜索空间约简技巧</strong>：</p>
<ol>
<li><strong>分阶段搜索</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">staged_search</span><span class="p">():</span>
    <span class="c1"># 第一阶段：粗粒度搜索</span>
    <span class="n">stage1_space</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">],</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>
    <span class="p">}</span>
    <span class="n">best_config_stage1</span> <span class="o">=</span> <span class="n">grid_search</span><span class="p">(</span><span class="n">stage1_space</span><span class="p">)</span>

    <span class="c1"># 第二阶段：细粒度搜索</span>
    <span class="n">stage2_space</span> <span class="o">=</span> <span class="n">create_refined_space</span><span class="p">(</span><span class="n">best_config_stage1</span><span class="p">)</span>
    <span class="n">best_config</span> <span class="o">=</span> <span class="n">bayesian_optimization</span><span class="p">(</span><span class="n">stage2_space</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">best_config</span>
</code></pre></div>

<ol start="2">
<li><strong>重要性采样</strong>：
   基于参数重要性分配搜索预算</li>
</ol>
<h3 id="742">7.4.2 贝叶斯优化</h3>
<p>贝叶斯优化通过建立代理模型高效探索超参数空间：</p>
<p><strong>高斯过程实现</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">BayesianOptimizer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">space</span><span class="p">,</span> <span class="n">acquisition_func</span><span class="o">=</span><span class="s2">&quot;ei&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">space</span> <span class="o">=</span> <span class="n">space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_func</span> <span class="o">=</span> <span class="n">acquisition_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observations</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">suggest_next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observations</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
            <span class="c1"># 初始随机探索</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_sample</span><span class="p">()</span>

        <span class="c1"># 训练高斯过程</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">observations</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">observations</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># 优化获取函数</span>
        <span class="n">next_point</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimize_acquisition</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">next_point</span>

    <span class="k">def</span> <span class="nf">optimize_acquisition</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;优化获取函数找到下一个采样点&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_func</span> <span class="o">==</span> <span class="s2">&quot;ei&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected_improvement</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_func</span> <span class="o">==</span> <span class="s2">&quot;ucb&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">upper_confidence_bound</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_func</span> <span class="o">==</span> <span class="s2">&quot;pi&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">probability_improvement</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">expected_improvement</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;期望改进获取函数&quot;&quot;&quot;</span>
        <span class="n">best_y</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="n">obs</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">observations</span><span class="p">])</span>

        <span class="k">def</span> <span class="nf">ei</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean</span> <span class="o">-</span> <span class="n">best_y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span> <span class="o">+</span> <span class="mf">1e-9</span><span class="p">)</span>
            <span class="n">ei_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean</span> <span class="o">-</span> <span class="n">best_y</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">+</span> <span class="n">std</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">ei_value</span>  <span class="c1"># 负值用于最小化</span>

        <span class="c1"># 多起点优化</span>
        <span class="n">best_x</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">best_ei</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
            <span class="n">x0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_sample</span><span class="p">()</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">ei</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">space</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>
            <span class="k">if</span> <span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">fun</span> <span class="o">&gt;</span> <span class="n">best_ei</span><span class="p">:</span>
                <span class="n">best_ei</span> <span class="o">=</span> <span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">fun</span>
                <span class="n">best_x</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

        <span class="k">return</span> <span class="n">best_x</span>
</code></pre></div>

<p><strong>多保真度优化（Multi-fidelity）</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">successive_halving</span><span class="p">(</span><span class="n">configs</span><span class="p">,</span> <span class="n">budget</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Successive Halving 算法&quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">budget</span> <span class="o">/</span> <span class="n">n</span>  <span class="c1"># 初始资源分配</span>

    <span class="k">while</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># 训练所有配置 r 个 epoch</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">configs</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
            <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

        <span class="c1"># 保留前 1/eta</span>
        <span class="n">k</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">//</span> <span class="n">eta</span><span class="p">)</span>
        <span class="n">top_k_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">)[</span><span class="o">-</span><span class="n">k</span><span class="p">:]</span>
        <span class="n">configs</span> <span class="o">=</span> <span class="p">[</span><span class="n">configs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_k_indices</span><span class="p">]</span>

        <span class="c1"># 增加资源</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">eta</span>

    <span class="k">return</span> <span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>

<h3 id="743">7.4.3 群体训练策略</h3>
<p>同时训练多个模型变体，利用群体智慧：</p>
<p><strong>Population Based Training (PBT)</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">PopulationBasedTraining</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">population_size</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">population_size</span> <span class="o">=</span> <span class="n">population_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">population</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialize_population</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">initialize_population</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;初始化种群&quot;&quot;&quot;</span>
        <span class="n">population</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">population_size</span><span class="p">):</span>
            <span class="n">member</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_hyperparameters</span><span class="p">(),</span>
                <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s2">&quot;age&quot;</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">}</span>
            <span class="n">population</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">member</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">population</span>

    <span class="k">def</span> <span class="nf">evolve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;进化过程&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="c1"># 并行训练一段时间</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_population</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

            <span class="c1"># 评估性能</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_population</span><span class="p">()</span>

            <span class="c1"># 执行进化操作</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">exploit_and_explore</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">exploit_and_explore</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;利用和探索&quot;&quot;&quot;</span>
        <span class="c1"># 排序种群</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">population</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># 底部 25% 被顶部 25% 替换</span>
        <span class="n">bottom_quartile</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">population_size</span> <span class="o">//</span> <span class="mi">4</span>
        <span class="n">top_quartile</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">population_size</span> <span class="o">//</span> <span class="mi">4</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bottom_quartile</span><span class="p">):</span>
            <span class="c1"># 复制高性能成员</span>
            <span class="n">source_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">top_quartile</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">population</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_member</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">population</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="c1"># 扰动超参数（探索）</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">perturb_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">population</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">perturb_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">member</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;扰动超参数进行探索&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">member</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.2</span><span class="p">:</span>  <span class="c1"># 20% 概率扰动</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                    <span class="c1"># 乘性扰动</span>
                    <span class="n">factor</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">])</span>
                    <span class="n">config</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span> <span class="o">*</span> <span class="n">factor</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="c1"># 加性扰动</span>
                    <span class="n">delta</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
                    <span class="n">config</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span>
</code></pre></div>

<h3 id="744">7.4.4 早停与预算分配</h3>
<p>智能分配计算资源，避免在差配置上浪费时间：</p>
<p><strong>自适应早停策略</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">AdaptiveEarlyStopping</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="n">min_delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">current_score</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="c1"># 相对改进</span>
        <span class="n">relative_improvement</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">current_score</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_score</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">relative_improvement</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">current_score</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># 动态调整 patience</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">adjusted_patience</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># 早期更宽容</span>
        <span class="k">elif</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">50</span><span class="p">:</span>
            <span class="n">adjusted_patience</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">//</span> <span class="mi">2</span>  <span class="c1"># 后期更严格</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">adjusted_patience</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="n">adjusted_patience</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span>
</code></pre></div>

<p><strong>预算分配算法</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">hyperband</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">81</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Hyperband 算法&quot;&quot;&quot;</span>
    <span class="n">logeta</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
    <span class="n">s_max</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">logeta</span><span class="p">(</span><span class="n">max_iter</span><span class="p">))</span>
    <span class="n">B</span> <span class="o">=</span> <span class="p">(</span><span class="n">s_max</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_iter</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">s_max</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">B</span> <span class="o">/</span> <span class="n">max_iter</span> <span class="o">/</span> <span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">eta</span> <span class="o">**</span> <span class="n">s</span><span class="p">))</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">max_iter</span> <span class="o">*</span> <span class="n">eta</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="n">s</span><span class="p">)</span>

        <span class="c1"># Successive halving</span>
        <span class="n">configs</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample_configuration</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">n_configs</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">eta</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="n">i</span><span class="p">)</span>
            <span class="n">n_iterations</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">eta</span> <span class="o">**</span> <span class="n">i</span>

            <span class="c1"># 训练和评估</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">configs</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">n_configs</span><span class="p">)]:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span>
                    <span class="n">config</span><span class="p">,</span> 
                    <span class="n">iterations</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">score</span><span class="p">,</span> <span class="n">config</span><span class="p">))</span>

            <span class="c1"># 选择最佳配置继续</span>
            <span class="n">scores</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">configs</span> <span class="o">=</span> <span class="p">[</span><span class="n">config</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">n_configs</span> <span class="o">/</span> <span class="n">eta</span><span class="p">)]]</span>

        <span class="n">results</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scores</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># 保存最佳结果</span>

    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>

<h3 id="745">7.4.5 超参数迁移学习</h3>
<p>利用历史任务的超参数知识加速新任务的搜索：</p>
<p><strong>元学习超参数</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">HyperparameterMetaLearner</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_embeddings</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meta_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_meta_model</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">build_meta_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;构建元学习模型&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">learn_from_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_features</span><span class="p">,</span> <span class="n">best_hyperparams</span><span class="p">,</span> <span class="n">performance</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;从任务中学习&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;task_features&quot;</span><span class="p">:</span> <span class="n">task_features</span><span class="p">,</span>
            <span class="s2">&quot;hyperparams&quot;</span><span class="p">:</span> <span class="n">best_hyperparams</span><span class="p">,</span>
            <span class="s2">&quot;performance&quot;</span><span class="p">:</span> <span class="n">performance</span>
        <span class="p">})</span>

        <span class="c1"># 更新元模型</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_history</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="p">[</span><span class="s2">&quot;task_features&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="s2">&quot;hyperparams&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> 
                 <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_history</span><span class="p">]</span>
            <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">h</span><span class="p">[</span><span class="s2">&quot;performance&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_history</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">meta_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">suggest_initial_hyperparams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_task_features</span><span class="p">,</span> <span class="n">n_suggestions</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;为新任务建议初始超参数&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_history</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="c1"># 历史数据不足，返回随机配置</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">sample_random_config</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_suggestions</span><span class="p">)]</span>

        <span class="c1"># 找到相似任务</span>
        <span class="n">similar_tasks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_similar_tasks</span><span class="p">(</span><span class="n">new_task_features</span><span class="p">)</span>

        <span class="n">suggestions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">similar_tasks</span><span class="p">[:</span><span class="n">n_suggestions</span><span class="p">]:</span>
            <span class="c1"># 基于相似任务的超参数，添加小扰动</span>
            <span class="n">base_config</span> <span class="o">=</span> <span class="n">task</span><span class="p">[</span><span class="s2">&quot;hyperparams&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">perturbed_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturb_config</span><span class="p">(</span><span class="n">base_config</span><span class="p">)</span>
            <span class="n">suggestions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">perturbed_config</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">suggestions</span>

    <span class="k">def</span> <span class="nf">find_similar_tasks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_features</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;找到最相似的历史任务&quot;&quot;&quot;</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hist</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_history</span><span class="p">:</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">task_features</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hist</span><span class="p">[</span><span class="s2">&quot;task_features&quot;</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="n">distances</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dist</span><span class="p">,</span> <span class="n">hist</span><span class="p">))</span>

        <span class="n">distances</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">hist</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">hist</span> <span class="ow">in</span> <span class="n">distances</span><span class="p">[:</span><span class="n">k</span><span class="p">]]</span>
</code></pre></div>

<h2 id="75">7.5 分布式训练的工程优化</h2>
<p>大规模 LLM 后训练必须依赖分布式系统。合理的分布式策略和工程优化可以显著提升训练效率和稳定性。</p>
<h3 id="751">7.5.1 并行策略选择</h3>
<p>根据模型规模和硬件资源选择合适的并行策略：</p>
<p><strong>并行策略对比</strong>：</p>
<p>| 策略 | 通信开销 | 内存效率 | 适用场景 |</p>
<table>
<thead>
<tr>
<th>策略</th>
<th>通信开销</th>
<th>内存效率</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据并行(DP)</td>
<td>O(模型大小)</td>
<td>低</td>
<td>小模型，大批次</td>
</tr>
<tr>
<td>张量并行(TP)</td>
<td>O(激活大小)</td>
<td>高</td>
<td>单层参数超过GPU内存</td>
</tr>
<tr>
<td>流水线并行(PP)</td>
<td>O(批次大小)</td>
<td>中</td>
<td>深层网络</td>
</tr>
<tr>
<td>3D并行</td>
<td>混合</td>
<td>最高</td>
<td>超大规模模型</td>
</tr>
</tbody>
</table>
<p><strong>混合并行策略实现</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">HybridParallelConfig</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">model_config</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="n">world_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">model_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">determine_strategy</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">determine_strategy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;根据模型和硬件自动确定并行策略&quot;&quot;&quot;</span>
        <span class="n">model_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_parameters</span>
        <span class="n">gpu_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span>

        <span class="c1"># 估算单GPU能否容纳模型</span>
        <span class="n">bytes_per_param</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># FP32</span>
        <span class="n">model_memory</span> <span class="o">=</span> <span class="n">model_params</span> <span class="o">*</span> <span class="n">bytes_per_param</span>
        <span class="n">activation_memory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_activation_memory</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">model_memory</span> <span class="o">+</span> <span class="n">activation_memory</span> <span class="o">&lt;</span> <span class="n">gpu_memory</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">:</span>
            <span class="c1"># 纯数据并行</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;dp&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="s2">&quot;tp&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;pp&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>

        <span class="c1"># 需要模型并行</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">&gt;</span> <span class="mi">24</span><span class="p">:</span>
            <span class="c1"># 深层网络，使用流水线并行</span>
            <span class="n">pp_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">//</span> <span class="mi">12</span><span class="p">)</span>
            <span class="n">remaining</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">//</span> <span class="n">pp_size</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">&gt;</span> <span class="mi">8192</span><span class="p">:</span>
                <span class="c1"># 宽模型，添加张量并行</span>
                <span class="n">tp_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">remaining</span><span class="p">)</span>
                <span class="n">dp_size</span> <span class="o">=</span> <span class="n">remaining</span> <span class="o">//</span> <span class="n">tp_size</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tp_size</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">dp_size</span> <span class="o">=</span> <span class="n">remaining</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 浅层宽模型，主要使用张量并行</span>
            <span class="n">tp_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>
            <span class="n">dp_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">//</span> <span class="n">tp_size</span>
            <span class="n">pp_size</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;dp&quot;</span><span class="p">:</span> <span class="n">dp_size</span><span class="p">,</span> <span class="s2">&quot;tp&quot;</span><span class="p">:</span> <span class="n">tp_size</span><span class="p">,</span> <span class="s2">&quot;pp&quot;</span><span class="p">:</span> <span class="n">pp_size</span><span class="p">}</span>
</code></pre></div>

<p><strong>ZeRO 优化策略</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">configure_zero_optimization</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;配置 ZeRO 优化&quot;&quot;&quot;</span>
    <span class="n">zero_config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;stage&quot;</span><span class="p">:</span> <span class="n">stage</span><span class="p">,</span>
        <span class="s2">&quot;allgather_partitions&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;allgather_bucket_size&quot;</span><span class="p">:</span> <span class="mf">2e8</span><span class="p">,</span>
        <span class="s2">&quot;overlap_comm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;reduce_scatter&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;reduce_bucket_size&quot;</span><span class="p">:</span> <span class="mf">2e8</span><span class="p">,</span>
        <span class="s2">&quot;contiguous_gradients&quot;</span><span class="p">:</span> <span class="kc">True</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">stage</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># ZeRO-2: 优化器状态分片</span>
        <span class="n">zero_config</span><span class="p">[</span><span class="s2">&quot;offload_optimizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">}</span>

    <span class="k">if</span> <span class="n">stage</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="c1"># ZeRO-3: 参数分片</span>
        <span class="n">zero_config</span><span class="p">[</span><span class="s2">&quot;offload_param&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">}</span>
        <span class="n">zero_config</span><span class="p">[</span><span class="s2">&quot;param_persistence_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e5</span>

    <span class="k">return</span> <span class="n">zero_config</span>
</code></pre></div>

<h3 id="752">7.5.2 通信优化</h3>
<p>减少通信开销是分布式训练的关键优化点：</p>
<p><strong>梯度压缩</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">GradientCompressor</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">compression_ratio</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compression_ratio</span> <span class="o">=</span> <span class="n">compression_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residuals</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">compress</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Top-k 稀疏化压缩&quot;&quot;&quot;</span>
        <span class="c1"># 添加残差</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">residuals</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">residuals</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="c1"># 选择 top-k 元素</span>
        <span class="n">numel</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="n">k</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">numel</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">compression_ratio</span><span class="p">))</span>

        <span class="n">values</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">mask</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">compressed</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask</span>

        <span class="c1"># 保存残差</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residuals</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">compressed</span>

        <span class="c1"># 返回稀疏表示</span>
        <span class="k">return</span> <span class="n">indices</span><span class="p">,</span> <span class="n">compressed</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">decompress</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;解压缩&quot;&quot;&quot;</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">tensor</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>

<p><strong>通信调度优化</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">CommunicationScheduler</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">comm_groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_comm_groups</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">schedule_allreduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;优化 AllReduce 调度&quot;&quot;&quot;</span>
        <span class="c1"># 按大小分组</span>
        <span class="n">small_grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">large_grads</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">grad</span> <span class="ow">in</span> <span class="n">gradients</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">grad</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">1e6</span><span class="p">:</span>
                <span class="n">small_grads</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">grad</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">large_grads</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">grad</span><span class="p">))</span>

        <span class="c1"># 小梯度合并通信</span>
        <span class="k">if</span> <span class="n">small_grads</span><span class="p">:</span>
            <span class="n">merged</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">g</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">small_grads</span><span class="p">])</span>
            <span class="n">handle</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">merged</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># 大梯度流水线通信</span>
        <span class="n">handles</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">grad</span> <span class="ow">in</span> <span class="n">large_grads</span><span class="p">:</span>
            <span class="n">handle</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">handles</span>
</code></pre></div>

<h3 id="753">7.5.3 内存管理</h3>
<p>精细的内存管理对大模型训练至关重要：</p>
<p><strong>激活检查点（Activation Checkpointing）</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">SelectiveCheckpointing</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;选择性激活检查点&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">checkpoint_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_ratio</span> <span class="o">=</span> <span class="n">checkpoint_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_checkpointing</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">setup_checkpointing</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;配置哪些层使用检查点&quot;&quot;&quot;</span>
        <span class="n">total_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
        <span class="n">checkpoint_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_layers</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_ratio</span><span class="p">)</span>

        <span class="c1"># 选择内存占用大的层</span>
        <span class="n">layer_memories</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">memory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_layer_memory</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="n">layer_memories</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">memory</span><span class="p">))</span>

        <span class="c1"># 优先检查点内存占用大的层</span>
        <span class="n">layer_memories</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">layer_memories</span><span class="p">[:</span><span class="n">checkpoint_layers</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">use_checkpoint</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">estimate_layer_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;估算层的激活内存&quot;&quot;&quot;</span>
        <span class="c1"># 简化估算</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</code></pre></div>

<p><strong>内存池管理</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MemoryPool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;预分配内存池减少碎片&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">):</span>  <span class="c1"># 1GB</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ByteTensor</span><span class="p">(</span><span class="n">pool_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allocated</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allocations</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">allocate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;从池中分配内存&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">allocated</span> <span class="o">+</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Memory pool exhausted&quot;</span><span class="p">)</span>

        <span class="n">start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">allocated</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allocated</span> <span class="o">+=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allocations</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">start</span><span class="o">+</span><span class="n">size</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">free</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;释放内存（逻辑释放）&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">allocations</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">allocations</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="c1"># 实际实现中需要内存整理</span>
</code></pre></div>

<h3 id="754">7.5.4 故障恢复机制</h3>
<p>构建健壮的故障恢复机制确保训练稳定性：</p>
<p><strong>检查点管理</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">RobustCheckpointing</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="p">,</span> <span class="n">keep_last_n</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">checkpoint_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_n</span> <span class="o">=</span> <span class="n">keep_last_n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;保存检查点with原子操作&quot;&quot;&quot;</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model_state_dict&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="n">metrics</span><span class="p">,</span>
            <span class="s2">&quot;timestamp&quot;</span><span class="p">:</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="p">}</span>

        <span class="c1"># 临时文件</span>
        <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">/temp_ckpt_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.pt&quot;</span>
        <span class="n">final_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">/checkpoint_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.pt&quot;</span>

        <span class="c1"># 原子写入</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">temp_path</span><span class="p">)</span>

        <span class="c1"># 验证检查点</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verify_checkpoint</span><span class="p">(</span><span class="n">temp_path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">temp_path</span><span class="p">,</span> <span class="n">final_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_path</span><span class="p">)</span>

            <span class="c1"># 清理旧检查点</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_history</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_n</span><span class="p">:</span>
                <span class="n">old_ckpt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_history</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">old_ckpt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">temp_path</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Checkpoint verification failed&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">verify_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;验证检查点完整性&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="n">required_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;model_state_dict&quot;</span><span class="p">,</span> <span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">,</span> <span class="s2">&quot;epoch&quot;</span><span class="p">]</span>
            <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">k</span> <span class="ow">in</span> <span class="n">checkpoint</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">required_keys</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
</code></pre></div>

<p><strong>弹性训练</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">ElasticTrainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;支持动态节点增减的弹性训练&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_nodes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_nodes</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_nodes</span> <span class="o">=</span> <span class="n">min_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_nodes</span> <span class="o">=</span> <span class="n">max_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detect_available_nodes</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">handle_node_failure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">failed_node</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;处理节点故障&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_nodes</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">failed_node</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_nodes</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_nodes</span><span class="p">:</span>
            <span class="c1"># 等待新节点或终止</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wait_for_nodes</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 重新配置并继续</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reconfigure_training</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reconfigure_training</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;重新配置训练&quot;&quot;&quot;</span>
        <span class="c1"># 重新初始化进程组</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
            <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span>
            <span class="n">world_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_nodes</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># 调整批次大小保持全局批次不变</span>
        <span class="n">global_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">global_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">local_batch_size</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">global_batch_size</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_nodes</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># 重新分配数据</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">redistribute_data</span><span class="p">()</span>
</code></pre></div>

<h3 id="755">7.5.5 性能调优实践</h3>
<p>系统级优化提升训练效率：</p>
<p><strong>性能分析工具集成</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">PerformanceMonitor</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">profile_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;分析单次迭代&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span>
            <span class="n">activities</span><span class="o">=</span><span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CPU</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">profile_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
            <span class="c1"># 执行训练步骤</span>
            <span class="k">yield</span>

        <span class="c1"># 分析结果</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">analyze_profile</span><span class="p">(</span><span class="n">prof</span><span class="p">,</span> <span class="n">iteration</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">analyze_profile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prof</span><span class="p">,</span> <span class="n">iteration</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;分析性能瓶颈&quot;&quot;&quot;</span>
        <span class="c1"># GPU利用率</span>
        <span class="n">cuda_time</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
            <span class="n">item</span><span class="o">.</span><span class="n">cuda_time_total</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span>
        <span class="p">])</span>

        <span class="c1"># 通信时间</span>
        <span class="n">comm_time</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
            <span class="n">item</span><span class="o">.</span><span class="n">cuda_time_total</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;nccl&quot;</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">key</span> <span class="ow">or</span> <span class="s2">&quot;allreduce&quot;</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">key</span>
        <span class="p">])</span>

        <span class="c1"># 内存峰值</span>
        <span class="n">memory_peak</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;gpu_utilization&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cuda_time</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;comm_overhead&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">comm_time</span> <span class="o">/</span> <span class="n">cuda_time</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;memory_peak&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">memory_peak</span><span class="p">)</span>

        <span class="c1"># 识别瓶颈</span>
        <span class="k">if</span> <span class="n">comm_time</span> <span class="o">/</span> <span class="n">cuda_time</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: High communication overhead (</span><span class="si">{</span><span class="n">comm_time</span><span class="o">/</span><span class="n">cuda_time</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>自动性能调优</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">AutoTuner</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;自动调优训练配置&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">initial_config</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">initial_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">performance_history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">auto_tune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_trials</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;自动调优&quot;&quot;&quot;</span>
        <span class="n">best_throughput</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">best_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_trials</span><span class="p">):</span>
            <span class="c1"># 生成新配置</span>
            <span class="n">trial_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_config_variant</span><span class="p">()</span>

            <span class="c1"># 测试性能</span>
            <span class="n">throughput</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">benchmark_config</span><span class="p">(</span><span class="n">trial_config</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">throughput</span> <span class="o">&gt;</span> <span class="n">best_throughput</span><span class="p">:</span>
                <span class="n">best_throughput</span> <span class="o">=</span> <span class="n">throughput</span>
                <span class="n">best_config</span> <span class="o">=</span> <span class="n">trial_config</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">performance_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="n">trial_config</span><span class="p">,</span>
                <span class="s2">&quot;throughput&quot;</span><span class="p">:</span> <span class="n">throughput</span>
            <span class="p">})</span>

        <span class="k">return</span> <span class="n">best_config</span>

    <span class="k">def</span> <span class="nf">generate_config_variant</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;生成配置变体&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># 调整关键参数</span>
        <span class="n">params_to_tune</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;micro_batch_size&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]),</span>
            <span class="p">(</span><span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">]),</span>
            <span class="p">(</span><span class="s2">&quot;num_workers&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]),</span>
            <span class="p">(</span><span class="s2">&quot;pin_memory&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]),</span>
            <span class="p">(</span><span class="s2">&quot;prefetch_factor&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
        <span class="p">]</span>

        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">params_to_tune</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.3</span><span class="p">:</span>  <span class="c1"># 30% 概率修改</span>
                <span class="n">config</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">config</span>
</code></pre></div>

<h2 id="_2">本章小结</h2>
<p>本章系统介绍了 LLM 后训练中的训练循环与迭代优化方法：</p>
<p><strong>核心要点</strong>：</p>
<ol>
<li>
<p><strong>数据-标注-训练-评估循环</strong>：
   - 建立高效的闭环系统是后训练成功的基础
   - 每个环节的质量控制和反馈机制至关重要
   - 自动化和智能化决策提升迭代效率</p>
</li>
<li>
<p><strong>主动学习与数据选择</strong>：
   - 不确定性采样、多样性选择、困难样本挖掘相结合
   - 课程学习优化训练顺序，提高收敛速度
   - 数据价值评估指导资源分配</p>
</li>
<li>
<p><strong>模型合并与集成</strong>：
   - 参数空间合并技术实现零成本集成
   - 任务向量支持模型能力的算术运算
   - 层级策略和冲突解决确保合并质量</p>
</li>
<li>
<p><strong>超参数优化</strong>：
   - 贝叶斯优化和群体训练提高搜索效率
   - 多保真度方法优化计算资源使用
   - 超参数迁移学习加速新任务适配</p>
</li>
<li>
<p><strong>分布式训练优化</strong>：
   - 混合并行策略适应不同规模模型
   - 通信和内存优化降低训练成本
   - 故障恢复机制保证训练稳定性</p>
</li>
</ol>
<p><strong>关键公式回顾</strong>：</p>
<ul>
<li>不确定性度量：$H(x) = -\sum_{i=1}^{K} p(y_i|x) \log p(y_i|x)$</li>
<li>任务向量：$\tau = \theta_{finetuned} - \theta_{pretrained}$</li>
<li>期望改进：$EI(x) = (\mu(x) - f^*) \Phi(Z) + \sigma(x) \phi(Z)$</li>
</ul>
<h2 id="_3">练习题</h2>
<h3 id="_4">基础题</h3>
<ol>
<li><strong>循环设计理解</strong>
   设计一个数据-标注-训练-评估循环，要求日产出 1000 个高质量标注样本，描述各环节的关键指标和质量控制点。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑标注效率、质量检查、自动化程度、反馈延迟等因素。
   </details>
<details markdown="block">
   <summary markdown="off">参考答案</summary>

   循环设计方案：

   - 数据收集：从用户交互日志筛选（2000样本/日），预过滤规则去除明显低质量
   - 标注：混合模式，模型预标注(5000/日) → 人工审核(1500/日) → 质检(100%覆盖)
   - 训练：累积5000样本触发，增量训练2小时
   - 评估：自动评估(准确率&gt;95%) + 人工抽检(5%)
   - 关键指标：标注一致性&gt;0.85，模型改进&gt;2%，端到端延迟&lt;24小时
   </details>
<ol start="2">
<li><strong>不确定性计算</strong>
   给定模型对三个类别的预测概率为 [0.4, 0.35, 0.25]，计算预测熵、最小置信度和边际采样分数。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   直接应用本章介绍的三个公式。
   </details>
<details markdown="block">
   <summary markdown="off">参考答案</summary>

   - 预测熵：H = -0.4×log(0.4) - 0.35×log(0.35) - 0.25×log(0.25) ≈ 1.08
   - 最小置信度：LC = 1 - 0.4 = 0.6
   - 边际采样：MS = 0.4 - 0.35 = 0.05
   - 结论：高不确定性样本，适合主动学习
   </details>
<ol start="3">
<li><strong>模型合并权重</strong>
   两个模型在验证集上的性能分别为 0.85 和 0.90，Fisher 信息矩阵范数比为 2:3，计算最优合并权重。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   结合性能和 Fisher 信息确定权重。
   </details>
<details markdown="block">
   <summary markdown="off">参考答案</summary>

   综合权重计算：

   - 性能权重：0.85:0.90 = 0.486:0.514
   - Fisher 权重：2:3 = 0.4:0.6
   - 综合权重（平均）：(0.486+0.4)/2 : (0.514+0.6)/2 = 0.443:0.557
   - 归一化：0.443:0.557
   </details>
<ol start="4">
<li><strong>并行策略选择</strong>
   模型参数 70B，32 个 A100 GPU（80GB），批次大小 512，如何设计 3D 并行策略？</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   计算模型内存需求，考虑激活内存。
   </details>
<details markdown="block">
   <summary markdown="off">参考答案</summary>

   策略设计：

   - 模型内存：70B × 4 bytes = 280GB（FP32）
   - 单GPU无法容纳，需要模型并行
   - 建议配置：TP=4, PP=2, DP=4
   - 每个GPU负责：70B/(4×2) = 8.75B 参数
   - 内存占用：35GB模型 + 20GB激活 &lt; 80GB
   </details>
<h3 id="_5">挑战题</h3>
<ol start="5">
<li><strong>主动学习策略设计</strong>
   设计一个结合不确定性、多样性和困难度的综合主动学习策略，给出具体的评分函数和选择算法。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑三个维度的权重平衡和归一化。
   </details>
<details markdown="block">
   <summary markdown="off">参考答案</summary>

   综合评分函数：
   Score(x) = α·Uncertainty(x) + β·Diversity(x) + γ·Difficulty(x)

   其中：

   - Uncertainty(x) = H(x) / log(K)  # 归一化熵
   - Diversity(x) = min_distance(x, selected_set) / max_distance
   - Difficulty(x) = loss(x) / percentile_95_loss
   - α=0.4, β=0.3, γ=0.3（可调）

   选择算法：

   1. 计算所有候选样本的综合分数
   2. 贪心选择：每次选最高分，更新已选集合
   3. 动态调整权重：早期重视多样性，后期重视困难度
   </details>
<ol start="6">
<li><strong>超参数迁移方案</strong>
   设计一个跨任务的超参数迁移学习系统，包括任务相似度计算、历史知识存储和初始化策略。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑任务特征提取、相似度度量、知识蒸馏。
   </details>
<details markdown="block">
   <summary markdown="off">参考答案</summary>

   系统设计：

   1. 任务特征提取：
      - 数据统计：样本数、类别数、文本长度分布
      - 模型特征：架构、参数量、预训练来源
      - 领域特征：任务类型、评估指标

   2. 相似度计算：
      - 特征向量余弦相似度
      - 任务嵌入（通过元学习获得）
      - 历史性能相关性

   3. 知识迁移：
      - Top-3相似任务的超参数加权平均
      - 添加探索噪声（±20%）
      - 保留任务特定调整空间
   </details>
<ol start="7">
<li><strong>分布式训练故障恢复</strong>
   设计一个能处理节点故障、网络分区和数据损坏的完整故障恢复系统。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑检测、隔离、恢复、验证四个阶段。
   </details>
<details markdown="block">
   <summary markdown="off">参考答案</summary>

   故障恢复系统：

   1. 故障检测：
      - 心跳监控（5秒超时）
      - 梯度范数异常检测
      - 通信错误率监控

   2. 故障隔离：
      - 标记故障节点
      - 重组通信拓扑
      - 数据重分配

   3. 状态恢复：
      - 从最近检查点恢复
      - 重放日志恢复中间状态
      - 验证模型参数一致性

   4. 弹性调整：
      - 动态调整并行度
      - 重新计算批次大小
      - 更新学习率（根据有效批次）
   </details>
<ol start="8">
<li><strong>模型合并冲突解决</strong>
   两个模型在相同任务上训练但使用不同数据集，合并时发现30%的参数符号相反，设计解决方案。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   分析冲突原因，设计多级解决策略。
   </details>
<details markdown="block">
   <summary markdown="off">参考答案</summary>

   冲突解决方案：

   1. 冲突分析：
      - 按层统计冲突比例
      - 识别系统性 vs 随机性冲突
      - 评估参数重要性（梯度、Fisher信息）

   2. 分级处理：
      - 关键层（注意力）：基于验证集性能选择
      - 中间层：重要性加权插值
      - 顶层：任务相关性决定

   3. 后处理：
      - 微调合并模型（小学习率）
      - 知识蒸馏对齐
      - 验证关键能力保持

   4. 预防措施：
      - 训练时添加一致性正则化
      - 使用相同初始化
      - 定期交换梯度信息
   </details>
<h2 id="_6">常见陷阱与错误</h2>
<h3 id="_7">数据循环相关</h3>
<p>⚠️ <strong>陷阱1：数据泄露</strong></p>
<ul>
<li>错误：验证集数据进入训练循环</li>
<li>后果：过高估计模型性能</li>
<li>解决：严格的数据隔离，版本控制</li>
</ul>
<p>⚠️ <strong>陷阱2：标注漂移</strong></p>
<ul>
<li>错误：标注规范随时间变化但未更新历史数据</li>
<li>后果：数据不一致，模型学习冲突信号</li>
<li>解决：定期审查规范，必要时重新标注</li>
</ul>
<h3 id="_8">主动学习相关</h3>
<p>⚠️ <strong>陷阱3：采样偏差</strong></p>
<ul>
<li>错误：过度关注不确定样本，忽略代表性</li>
<li>后果：模型在常见案例上性能下降</li>
<li>解决：平衡不确定性和多样性</li>
</ul>
<p>⚠️ <strong>陷阱4：冷启动问题</strong></p>
<ul>
<li>错误：初始模型太差，不确定性估计不可靠</li>
<li>后果：选择低价值样本</li>
<li>解决：初始随机采样建立基线</li>
</ul>
<h3 id="_9">模型合并相关</h3>
<p>⚠️ <strong>陷阱5：盲目平均</strong></p>
<ul>
<li>错误：直接平均所有参数</li>
<li>后果：破坏学习的特征表示</li>
<li>解决：考虑参数重要性和任务相关性</li>
</ul>
<p>⚠️ <strong>陷阱6：忽视初始化</strong></p>
<ul>
<li>错误：合并不同初始化的模型</li>
<li>后果：参数空间不对齐</li>
<li>解决：使用相同预训练模型作为基础</li>
</ul>
<h3 id="_10">分布式训练相关</h3>
<p>⚠️ <strong>陷阱7：通信瓶颈</strong></p>
<ul>
<li>错误：忽视网络带宽限制</li>
<li>后果：GPU利用率低</li>
<li>解决：梯度压缩，通信优化</li>
</ul>
<p>⚠️ <strong>陷阱8：检查点损坏</strong></p>
<ul>
<li>错误：检查点保存不完整或损坏</li>
<li>后果：无法恢复训练</li>
<li>解决：原子操作，多副本，验证机制</li>
</ul>
<h3 id="_11">超参数优化相关</h3>
<p>⚠️ <strong>陷阱9：过早停止</strong></p>
<ul>
<li>错误：在学习率预热阶段就停止</li>
<li>后果：错过潜在好配置</li>
<li>解决：设置最小训练步数</li>
</ul>
<p>⚠️ <strong>陷阱10：搜索空间过大</strong></p>
<ul>
<li>错误：同时搜索所有超参数</li>
<li>后果：搜索效率低</li>
<li>解决：分阶段搜索，固定次要参数</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="chapter6.html" class="nav-link prev">← 第六章：强化学习与人类反馈</a><a href="chapter8.html" class="nav-link next">第八章：评估与基准测试 →</a></nav>
        </main>
    </div>
</body>
</html>