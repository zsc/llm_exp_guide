# ç¬¬ä¸‰ç« ï¼šæ•°æ®å·¥ç¨‹

## æœ¬ç« æ¦‚è§ˆ

æ•°æ®æ˜¯åè®­ç»ƒçš„åŸºçŸ³ã€‚ä¸é¢„è®­ç»ƒé˜¶æ®µè¿½æ±‚è§„æ¨¡å’Œå¤šæ ·æ€§ä¸åŒï¼Œåè®­ç»ƒæ•°æ®å·¥ç¨‹èšç„¦äºè´¨é‡ã€å¯¹é½å’Œä»»åŠ¡è¦†ç›–ã€‚æœ¬ç« æ·±å…¥æ¢è®¨åè®­ç»ƒæ•°æ®çš„å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼šä»é«˜è´¨é‡æŒ‡ä»¤æ•°æ®çš„æ„é€ ï¼Œåˆ°æ ‡æ³¨ä½“ç³»çš„è®¾è®¡ï¼Œå†åˆ°æ•°æ®é£è½®çš„æ­å»ºã€‚æˆ‘ä»¬å°†ç»“åˆå®é™…æ¡ˆä¾‹ï¼Œé˜è¿°å¦‚ä½•æ„å»ºä¸€ä¸ªå¯æŒç»­ã€å¯æ‰©å±•çš„æ•°æ®å·¥ç¨‹ä½“ç³»ï¼Œæ”¯æ’‘æ¨¡å‹èƒ½åŠ›çš„æŒç»­è¿­ä»£ã€‚

**å­¦ä¹ ç›®æ ‡**ï¼š
- æŒæ¡é«˜è´¨é‡æŒ‡ä»¤æ•°æ®çš„è®¾è®¡åŸåˆ™å’Œæ„é€ æ–¹æ³•
- ç†è§£æ ‡æ³¨è§„èŒƒçš„åˆ¶å®šæµç¨‹å’Œè´¨é‡æ§åˆ¶æœºåˆ¶
- å­¦ä¼šæ­å»ºæ•°æ®é£è½®ï¼Œå®ç°æ•°æ®çš„è‡ªåŠ¨åŒ–è¿­ä»£
- æŒæ¡åˆæˆæ•°æ®ç”Ÿæˆçš„å„ç±»æŠ€æœ¯å’Œè¯„ä¼°æ–¹æ³•
- ç†è§£æ•°æ®é…æ¯”å’Œè¯¾ç¨‹å­¦ä¹ åœ¨åè®­ç»ƒä¸­çš„åº”ç”¨

## 3.1 é«˜è´¨é‡æŒ‡ä»¤æ•°æ®çš„æ„é€ æ–¹æ³•

### 3.1.1 æŒ‡ä»¤æ•°æ®çš„æ ¸å¿ƒè¦ç´ 

é«˜è´¨é‡çš„æŒ‡ä»¤æ•°æ®åº”åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒè¦ç´ ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         æŒ‡ä»¤æ•°æ®ä¸‰è¦ç´                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. æŒ‡ä»¤(Instruction)               â”‚
â”‚     - æ¸…æ™°çš„ä»»åŠ¡æè¿°                 â”‚
â”‚     - æ˜ç¡®çš„çº¦æŸæ¡ä»¶                 â”‚
â”‚     - æœŸæœ›çš„è¾“å‡ºæ ¼å¼                 â”‚
â”‚                                     â”‚
â”‚  2. è¾“å…¥(Input)                     â”‚
â”‚     - ä»»åŠ¡ç›¸å…³çš„ä¸Šä¸‹æ–‡               â”‚
â”‚     - å¿…è¦çš„èƒŒæ™¯ä¿¡æ¯                 â”‚
â”‚     - å¤šæ¨¡æ€å†…å®¹(å¯é€‰)               â”‚
â”‚                                     â”‚
â”‚  3. è¾“å‡º(Output)                    â”‚
â”‚     - é«˜è´¨é‡çš„æ ‡å‡†ç­”æ¡ˆ               â”‚
â”‚     - æ€ç»´è¿‡ç¨‹(å¯¹äºæ¨ç†ä»»åŠ¡)         â”‚
â”‚     - å¤šæ ·åŒ–çš„è¡¨è¾¾æ–¹å¼               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.1.2 æ•°æ®æºçš„é€‰æ‹©ç­–ç•¥

**1. äººå·¥æ„é€ æ•°æ®**

ä¼˜åŠ¿ï¼šè´¨é‡å¯æ§ã€ä»»åŠ¡é’ˆå¯¹æ€§å¼º
åŠ£åŠ¿ï¼šæˆæœ¬é«˜ã€è§„æ¨¡å—é™

æ„é€ åŸåˆ™ï¼š
- **ä»»åŠ¡è¦†ç›–å®Œæ•´æ€§**ï¼šç³»ç»Ÿæ€§åœ°è¦†ç›–ç›®æ ‡èƒ½åŠ›çŸ©é˜µ
- **éš¾åº¦æ¢¯åº¦è®¾è®¡**ï¼šä»ç®€å•åˆ°å¤æ‚çš„æ¸è¿›å¼åˆ†å¸ƒ
- **è¾¹ç•Œæ¡ˆä¾‹åŒ…å«**ï¼šåˆ»æ„åŒ…å«å¼‚å¸¸å’Œè¾¹ç•Œæƒ…å†µ

**2. ç°æœ‰æ•°æ®æ”¹é€ **

ä»é«˜è´¨é‡çš„æ–‡æœ¬è¯­æ–™ï¼ˆå¦‚æ•™ç§‘ä¹¦ã€æŠ€æœ¯æ–‡æ¡£ï¼‰ä¸­æå–å’Œæ”¹é€ ï¼š

```
åŸå§‹æ–‡æœ¬ â†’ é—®ç­”å¯¹æå– â†’ æŒ‡ä»¤æ ¼å¼åŒ– â†’ è´¨é‡ç­›é€‰
         â†“
    ä¿¡æ¯æŠ½å–è§„åˆ™
    (NER, å…³ç³»æŠ½å–ç­‰)
```

**3. æ¨¡å‹ç”Ÿæˆæ•°æ®**

åˆ©ç”¨å¼ºå¤§çš„åŸºç¡€æ¨¡å‹ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼š

```
ç§å­ä»»åŠ¡ â†’ LLMç”Ÿæˆ â†’ äººå·¥éªŒè¯ â†’ è‡ªåŠ¨æ‰©å±•
         â†“            â†“
    Self-Instruct  è´¨é‡è¯„åˆ†æ¨¡å‹
```

### 3.1.3 æ•°æ®å¤šæ ·æ€§è®¾è®¡

ğŸ“Œ **å¤šæ ·æ€§ç»´åº¦**ï¼š

1. **ä»»åŠ¡ç±»å‹å¤šæ ·æ€§**
   - ç”Ÿæˆç±»ï¼šåˆ›ä½œã€ç¿»è¯‘ã€æ€»ç»“
   - ç†è§£ç±»ï¼šåˆ†ç±»ã€æŠ½å–ã€é—®ç­”
   - æ¨ç†ç±»ï¼šæ•°å­¦ã€é€»è¾‘ã€ä»£ç 

2. **é¢†åŸŸå¤šæ ·æ€§**
   - é€šç”¨çŸ¥è¯† vs ä¸“ä¸šé¢†åŸŸ
   - æ­£å¼è¯­å¢ƒ vs æ—¥å¸¸å¯¹è¯
   - ä¸åŒæ–‡åŒ–èƒŒæ™¯

3. **å¤æ‚åº¦å¤šæ ·æ€§**
   - å•è½® vs å¤šè½®
   - ç®€å•æŒ‡ä»¤ vs å¤åˆä»»åŠ¡
   - çŸ­æ–‡æœ¬ vs é•¿æ–‡æœ¬

### 3.1.4 æ•°æ®è´¨é‡è¯„ä¼°æ¡†æ¶

å»ºç«‹å¤šç»´åº¦çš„è´¨é‡è¯„ä¼°ä½“ç³»ï¼š

$$Q_{data} = \alpha \cdot Q_{correctness} + \beta \cdot Q_{helpfulness} + \gamma \cdot Q_{harmlessness} + \delta \cdot Q_{diversity}$$

å…¶ä¸­ï¼š
- $Q_{correctness}$ï¼šäº‹å®å‡†ç¡®æ€§å¾—åˆ†
- $Q_{helpfulness}$ï¼šæœ‰ç”¨æ€§å¾—åˆ†  
- $Q_{harmlessness}$ï¼šå®‰å…¨æ€§å¾—åˆ†
- $Q_{diversity}$ï¼šå¤šæ ·æ€§å¾—åˆ†
- $\alpha, \beta, \gamma, \delta$ï¼šæƒé‡ç³»æ•°ï¼Œæ»¡è¶³ $\sum = 1$

## 3.2 æ ‡æ³¨è§„èŒƒè®¾è®¡ä¸è´¨é‡æ§åˆ¶

### 3.2.1 æ ‡æ³¨è§„èŒƒçš„å±‚æ¬¡åŒ–è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          æ ‡æ³¨è§„èŒƒå±‚æ¬¡ç»“æ„             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 1: åŸºç¡€è§„èŒƒ                   â”‚
â”‚  - æ ¼å¼è¦æ±‚                          â”‚
â”‚  - é•¿åº¦é™åˆ¶                          â”‚
â”‚  - è¯­è¨€é£æ ¼                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 2: ä»»åŠ¡è§„èŒƒ                   â”‚
â”‚  - ä»»åŠ¡ç‰¹å®šè¦æ±‚                      â”‚
â”‚  - è¯„åˆ†æ ‡å‡†                          â”‚
â”‚  - ç¤ºä¾‹æ¡ˆä¾‹                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 3: è´¨é‡è§„èŒƒ                   â”‚
â”‚  - å‡†ç¡®æ€§æ ‡å‡†                        â”‚
â”‚  - å®Œæ•´æ€§è¦æ±‚                        â”‚
â”‚  - ä¸€è‡´æ€§æ£€æŸ¥                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Level 4: å®‰å…¨è§„èŒƒ                   â”‚
â”‚  - æœ‰å®³å†…å®¹è¿‡æ»¤                      â”‚
â”‚  - åè§æ£€æµ‹                          â”‚
â”‚  - éšç§ä¿æŠ¤                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2.2 æ ‡æ³¨è€…ç®¡ç†ä½“ç³»

**1. æ ‡æ³¨è€…é€‰æ‹©ä¸åŸ¹è®­**

- **èƒŒæ™¯ç­›é€‰**ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚èƒŒæ™¯çš„æ ‡æ³¨è€…
- **åŸ¹è®­æµç¨‹**ï¼š
  ```
  ç†è®ºå­¦ä¹  â†’ æ¡ˆä¾‹ç»ƒä¹  â†’ æµ‹è¯•è€ƒæ ¸ â†’ æ­£å¼æ ‡æ³¨ â†’ æŒç»­åé¦ˆ
  ```
- **èƒ½åŠ›åˆ†çº§**ï¼šåˆçº§ã€ä¸­çº§ã€é«˜çº§æ ‡æ³¨è€…çš„ä»»åŠ¡åˆ†é…

**2. æ ‡æ³¨ä¸€è‡´æ€§ä¿è¯**

Inter-Annotator Agreement (IAA) è®¡ç®—ï¼š

$$\kappa = \frac{P_o - P_e}{1 - P_e}$$

å…¶ä¸­ï¼š
- $P_o$ï¼šè§‚å¯Ÿåˆ°çš„ä¸€è‡´æ€§æ¯”ä¾‹
- $P_e$ï¼šéšæœºä¸€è‡´æ€§çš„æœŸæœ›æ¯”ä¾‹

ç›®æ ‡ï¼š$\kappa > 0.8$ è¡¨ç¤ºé«˜åº¦ä¸€è‡´

### 3.2.3 è´¨é‡æ§åˆ¶æœºåˆ¶

**1. å¤šé‡æ ‡æ³¨ç­–ç•¥**

```
ä»»åŠ¡ â†’ æ ‡æ³¨è€…A â†’ ç»“æœA â†˜
     â†’ æ ‡æ³¨è€…B â†’ ç»“æœB â†’ ä»²è£/æŠ•ç¥¨ â†’ æœ€ç»ˆç»“æœ
     â†’ æ ‡æ³¨è€…C â†’ ç»“æœC â†—
```

**2. è´¨é‡æŠ½æ£€æµç¨‹**

- **éšæœºæŠ½æ£€**ï¼šæŒ‰æ¯”ä¾‹éšæœºæŠ½å–æ ·æœ¬å¤æ ¸
- **å®šå‘æŠ½æ£€**ï¼šé’ˆå¯¹ç‰¹å®šæ ‡æ³¨è€…æˆ–ä»»åŠ¡ç±»å‹
- **äº¤å‰éªŒè¯**ï¼šæ ‡æ³¨è€…äº’ç›¸æ£€æŸ¥

**3. åŠ¨æ€è´¨é‡è¯„åˆ†**

æ ‡æ³¨è€…è´¨é‡å¾—åˆ†æ›´æ–°ï¼š

$$Q_t = \lambda \cdot Q_{t-1} + (1-\lambda) \cdot q_t$$

å…¶ä¸­ï¼š
- $Q_t$ï¼šæ—¶åˆ» $t$ çš„è´¨é‡å¾—åˆ†
- $q_t$ï¼šå½“å‰æ‰¹æ¬¡çš„è´¨é‡è¯„åˆ†
- $\lambda$ï¼šå†å²æƒé‡å› å­ï¼ˆå…¸å‹å€¼ 0.7-0.9ï¼‰

### 3.2.4 æ ‡æ³¨å·¥å…·ä¸å¹³å°

**å…³é”®åŠŸèƒ½éœ€æ±‚**ï¼š

1. **ä»»åŠ¡åˆ†å‘**ï¼šæ™ºèƒ½åˆ†é…ã€è´Ÿè½½å‡è¡¡
2. **è¿›åº¦è¿½è¸ª**ï¼šå®æ—¶ç›‘æ§ã€ç“¶é¢ˆè¯†åˆ«
3. **ç‰ˆæœ¬ç®¡ç†**ï¼šæ ‡æ³¨å†å²ã€å˜æ›´è¿½è¸ª
4. **åä½œåŠŸèƒ½**ï¼šè®¨è®ºã€äº‰è®®è§£å†³
5. **è‡ªåŠ¨åŒ–è¾…åŠ©**ï¼šé¢„æ ‡æ³¨ã€æ™ºèƒ½æç¤º

âš ï¸ **å¸¸è§é™·é˜±**ï¼š
- è¿‡åº¦ä¾èµ–å•ä¸€æ ‡æ³¨æº
- å¿½è§†æ ‡æ³¨è€…ç–²åŠ³å¯¼è‡´çš„è´¨é‡ä¸‹é™
- æ ‡æ³¨è§„èŒƒè¿‡äºå¤æ‚å¯¼è‡´ç†è§£åå·®
- ç¼ºä¹åŠæ—¶çš„åé¦ˆå¾ªç¯

## 3.3 æ•°æ®é£è½®ï¼ˆData Flywheelï¼‰æ­å»º

### 3.3.1 æ•°æ®é£è½®çš„æ ¸å¿ƒç†å¿µ

æ•°æ®é£è½®æ˜¯ä¸€ä¸ªè‡ªæˆ‘å¼ºåŒ–çš„å¾ªç¯ç³»ç»Ÿï¼Œé€šè¿‡æ¨¡å‹éƒ¨ç½²æ”¶é›†æ–°æ•°æ®ï¼Œä¸æ–­æ”¹è¿›æ¨¡å‹æ€§èƒ½ï¼š

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   1. æ¨¡å‹éƒ¨ç½²     â”‚
     â”‚   æ”¶é›†ç”¨æˆ·äº¤äº’    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   2. æ•°æ®ç­›é€‰     â”‚
     â”‚   è¯†åˆ«é«˜ä»·å€¼æ ·æœ¬  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   3. æ•°æ®æ ‡æ³¨     â”‚
     â”‚   äººå·¥/è‡ªåŠ¨æ ‡æ³¨   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   4. æ¨¡å‹è®­ç»ƒ     â”‚
     â”‚   å¢é‡/å…¨é‡è®­ç»ƒ   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   5. è¯„ä¼°éªŒè¯     â”‚
     â”‚   A/Bæµ‹è¯•         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
         å¾ªç¯ç»§ç»­ â†â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3.2 æ•°æ®æ”¶é›†ç­–ç•¥

**1. ä¸»åŠ¨æ”¶é›†**

- **ç”¨æˆ·åé¦ˆæŒ‰é’®**ï¼šğŸ‘/ğŸ‘ å¿«é€Ÿåé¦ˆ
- **è¯¦ç»†è¯„ä»·è¡¨å•**ï¼šç»“æ„åŒ–çš„è´¨é‡è¯„ä¼°
- **å¯¹æ¯”è¯„æµ‹**ï¼šA/B æ¨¡å‹è¾“å‡ºå¯¹æ¯”

**2. è¢«åŠ¨æ”¶é›†**

- **äº¤äº’æ—¥å¿—**ï¼šç”¨æˆ·è¡Œä¸ºåºåˆ—åˆ†æ
- **ä¿®æ”¹ç—•è¿¹**ï¼šç”¨æˆ·å¯¹è¾“å‡ºçš„ç¼–è¾‘
- **ä½¿ç”¨æ¨¡å¼**ï¼šé«˜é¢‘æŸ¥è¯¢ã€é‡è¯•è¡Œä¸º

**3. éšå¼ä¿¡å·æå–**

```python
# ä¼ªä»£ç ç¤ºä¾‹
value_score = Î± * dwell_time + 
              Î² * copy_rate + 
              Î³ * share_rate - 
              Î´ * regeneration_rate
```

### 3.3.3 é«˜ä»·å€¼æ•°æ®è¯†åˆ«

**ä»·å€¼è¯„åˆ†æ¨¡å‹**ï¼š

$$V(x) = w_1 \cdot \text{Uncertainty}(x) + w_2 \cdot \text{Diversity}(x) + w_3 \cdot \text{Difficulty}(x) + w_4 \cdot \text{Frequency}(x)$$

å…¶ä¸­ï¼š
- **Uncertainty**ï¼šæ¨¡å‹é¢„æµ‹çš„ä¸ç¡®å®šæ€§ï¼ˆç†µï¼‰
- **Diversity**ï¼šä¸ç°æœ‰æ•°æ®çš„å·®å¼‚åº¦
- **Difficulty**ï¼šä»»åŠ¡å¤æ‚åº¦è¯„åˆ†
- **Frequency**ï¼šæŸ¥è¯¢é¢‘ç‡æˆ–é‡è¦æ€§

**ç­›é€‰ç­–ç•¥**ï¼š

1. **ä¸ç¡®å®šæ€§é‡‡æ ·**ï¼šé€‰æ‹©æ¨¡å‹æœ€ä¸ç¡®å®šçš„æ ·æœ¬
2. **å¤šæ ·æ€§é‡‡æ ·**ï¼šæœ€å¤§åŒ–æ•°æ®é›†çš„è¦†ç›–åº¦
3. **å¯¹æŠ—æ ·æœ¬æŒ–æ˜**ï¼šæ‰¾å‡ºæ¨¡å‹å¤±è´¥çš„æ¡ˆä¾‹
4. **è¾¹ç•Œæ¢ç´¢**ï¼šæ¥è¿‘å†³ç­–è¾¹ç•Œçš„æ ·æœ¬

### 3.3.4 è‡ªåŠ¨åŒ–æ ‡æ³¨æµæ°´çº¿

**æ··åˆæ ‡æ³¨ç­–ç•¥**ï¼š

```
          é«˜ç½®ä¿¡åº¦
æ–°æ•°æ® â†’ æ¨¡å‹é¢„æ ‡æ³¨ â†’ è‡ªåŠ¨é‡‡çº³
                   â†˜
                    ä¸­ç½®ä¿¡åº¦ â†’ äººå·¥å¤æ ¸ â†’ æ ‡æ³¨ç»“æœ
                   â†—
         ä½ç½®ä¿¡åº¦ â†’ äººå·¥æ ‡æ³¨
```

**ç½®ä¿¡åº¦æ ¡å‡†**ï¼š

ä½¿ç”¨æ¸©åº¦ç¼©æ”¾ï¼ˆTemperature Scalingï¼‰æ ¡å‡†æ¨¡å‹ç½®ä¿¡åº¦ï¼š

$$p_i^{calibrated} = \frac{\exp(z_i/T)}{\sum_j \exp(z_j/T)}$$

å…¶ä¸­ $T$ æ˜¯é€šè¿‡éªŒè¯é›†ä¼˜åŒ–çš„æ¸©åº¦å‚æ•°ã€‚

### 3.3.5 å¢é‡è®­ç»ƒä¸ç‰ˆæœ¬ç®¡ç†

**å¢é‡è®­ç»ƒç­–ç•¥**ï¼š

1. **æŒç»­å¾®è°ƒ**ï¼šåœ¨æ–°æ•°æ®ä¸Šç»§ç»­è®­ç»ƒ
   ```
   Loss = Î» * L_new + (1-Î») * L_replay
   ```
   
2. **ç»éªŒå›æ”¾**ï¼šæ··åˆå†å²æ•°æ®é˜²æ­¢é—å¿˜
3. **å¼¹æ€§æƒé‡å·©å›ºï¼ˆEWCï¼‰**ï¼šä¿æŠ¤é‡è¦å‚æ•°

**æ•°æ®ç‰ˆæœ¬ç®¡ç†**ï¼š

```
data_v1.0/
â”œâ”€â”€ raw/           # åŸå§‹æ•°æ®
â”œâ”€â”€ processed/     # å¤„ç†åæ•°æ®
â”œâ”€â”€ splits/        # è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ’åˆ†
â”œâ”€â”€ metadata.json  # æ•°æ®é›†å…ƒä¿¡æ¯
â””â”€â”€ changelog.md   # å˜æ›´è®°å½•

data_v1.1/
â”œâ”€â”€ incremental/   # å¢é‡æ•°æ®
â”œâ”€â”€ merged/        # åˆå¹¶åå®Œæ•´æ•°æ®
â””â”€â”€ diff_report/   # å˜æ›´åˆ†æ
```

ğŸ’¡ **å®ç”¨æŠ€å·§**ï¼š
- ä¿æŒ 10-20% çš„éªŒè¯é›†ç¨³å®šï¼Œç”¨äºé•¿æœŸæ€§èƒ½è¿½è¸ª
- ä½¿ç”¨æ•°æ®å“ˆå¸Œå€¼è¿½è¸ªæ•°æ®è¡€ç¼˜
- å®šæœŸè¿›è¡Œå…¨é‡é‡è®­ï¼Œé‡ç½®æ¨¡å‹çŠ¶æ€

## 3.4 åˆæˆæ•°æ®ç”Ÿæˆç­–ç•¥

### 3.4.1 åˆæˆæ•°æ®çš„ä»·å€¼ä¸æŒ‘æˆ˜

**ä»·å€¼**ï¼š
- è§„æ¨¡åŒ–ï¼šä½æˆæœ¬å¤§è§„æ¨¡ç”Ÿæˆ
- å¯æ§æ€§ï¼šç²¾ç¡®æ§åˆ¶æ•°æ®ç‰¹å¾
- éšç§æ€§ï¼šé¿å…çœŸå®æ•°æ®éšç§é—®é¢˜
- å¹³è¡¡æ€§ï¼šè¡¥å……ç¨€æœ‰ç±»åˆ«æ•°æ®

**æŒ‘æˆ˜**ï¼š
- è´¨é‡ä¿è¯ï¼šé¿å…é”™è¯¯ä¼ æ’­
- å¤šæ ·æ€§ï¼šé˜²æ­¢æ¨¡å¼åç¼©
- çœŸå®æ€§ï¼šä¿æŒä¸çœŸå®åˆ†å¸ƒä¸€è‡´

### 3.4.2 ç”Ÿæˆæ–¹æ³•åˆ†ç±»

**1. æ¨¡æ¿åŸºç¡€ç”Ÿæˆ**

```python
template = "å°†ä¸‹åˆ—{è¯­è¨€A}ç¿»è¯‘æˆ{è¯­è¨€B}ï¼š{æ–‡æœ¬}"
instances = [
    {"è¯­è¨€A": "è‹±æ–‡", "è¯­è¨€B": "ä¸­æ–‡", "æ–‡æœ¬": text}
    for text in source_texts
]
```

**2. æ‰°åŠ¨åŸºç¡€ç”Ÿæˆ**

åŸå§‹æ ·æœ¬é€šè¿‡ç³»ç»Ÿæ€§æ‰°åŠ¨ç”Ÿæˆå˜ä½“ï¼š

- **è¯çº§æ‰°åŠ¨**ï¼šåŒä¹‰è¯æ›¿æ¢ã€æ’å…¥ã€åˆ é™¤
- **å¥çº§æ‰°åŠ¨**ï¼šæ”¹å†™ã€å€’è£…ã€æ‹†åˆ†åˆå¹¶
- **è¯­ä¹‰æ‰°åŠ¨**ï¼šå¦å®šã€æ¡ä»¶å˜æ¢ã€è§†è§’è½¬æ¢

**3. æ¨¡å‹åŸºç¡€ç”Ÿæˆ**

åˆ©ç”¨å¤§æ¨¡å‹ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Self-Instruct Pipeline     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. ç§å­ä»»åŠ¡ (175ä¸ª)             â”‚
â”‚    â†“                           â”‚
â”‚ 2. æŒ‡ä»¤ç”Ÿæˆ (GPTç”Ÿæˆæ–°æŒ‡ä»¤)     â”‚
â”‚    â†“                           â”‚
â”‚ 3. æŒ‡ä»¤è¿‡æ»¤ (å»é‡ã€è´¨é‡ç­›é€‰)    â”‚
â”‚    â†“                           â”‚
â”‚ 4. å®ä¾‹ç”Ÿæˆ (è¾“å…¥è¾“å‡ºå¯¹)        â”‚
â”‚    â†“                           â”‚
â”‚ 5. è´¨é‡éªŒè¯                    â”‚
â”‚    â†“                           â”‚
â”‚ 6. åŠ å…¥ç§å­æ±  (è¿­ä»£)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4.3 çŸ¥è¯†è’¸é¦ä¸æ•°æ®å¢å¼º

**çŸ¥è¯†è’¸é¦æµç¨‹**ï¼š

$$\mathcal{L}_{distill} = \alpha \cdot \mathcal{L}_{CE}(y, \hat{y}) + (1-\alpha) \cdot \mathcal{L}_{KL}(p_{teacher}, p_{student})$$

å…¶ä¸­ï¼š
- $\mathcal{L}_{CE}$ï¼šäº¤å‰ç†µæŸå¤±ï¼ˆhard labelï¼‰
- $\mathcal{L}_{KL}$ï¼šKLæ•£åº¦ï¼ˆsoft labelï¼‰
- $\alpha$ï¼šç¡¬æ ‡ç­¾æƒé‡

**æ•°æ®å¢å¼ºæŠ€æœ¯**ï¼š

1. **å›è¯‘å¢å¼º**ï¼ˆBack-translationï¼‰
   ```
   åŸæ–‡ â†’ ç¿»è¯‘åˆ°è¯­è¨€B â†’ ç¿»è¯‘å›è¯­è¨€A â†’ å¢å¼ºæ ·æœ¬
   ```

2. **é“¾å¼æ€ç»´å¢å¼º**ï¼ˆCoT Augmentationï¼‰
   ```
   é—®é¢˜ â†’ ç”Ÿæˆæ¨ç†æ­¥éª¤ â†’ éªŒè¯ç­”æ¡ˆ â†’ ç­›é€‰é«˜è´¨é‡CoT
   ```

3. **å¯¹æ¯”å­¦ä¹ å¢å¼º**
   ç”Ÿæˆæ­£ä¾‹å’Œè´Ÿä¾‹å¯¹ï¼š
   ```
   åŸå§‹æ ·æœ¬ â†’ æ­£ä¾‹ï¼ˆç›¸ä¼¼ä½†ä¸åŒï¼‰
           â†’ è´Ÿä¾‹ï¼ˆè¡¨é¢ç›¸ä¼¼ä½†è¯­ä¹‰ä¸åŒï¼‰
   ```

### 3.4.4 åˆæˆæ•°æ®è´¨é‡è¯„ä¼°

**è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡**ï¼š

1. **å›°æƒ‘åº¦è¿‡æ»¤**ï¼š
   $$PPL_{threshold} = \mu_{PPL} + k \cdot \sigma_{PPL}$$

2. **å¤šæ ·æ€§åº¦é‡**ï¼š
   - N-gramå¤šæ ·æ€§
   - è¯­ä¹‰åµŒå…¥å¤šæ ·æ€§
   - å¥æ³•ç»“æ„å¤šæ ·æ€§

3. **ä¸€è‡´æ€§æ£€éªŒ**ï¼š
   - è‡ªæ´½æ€§ï¼šå¤šæ¬¡ç”Ÿæˆçš„ä¸€è‡´æ€§
   - äº‹å®ä¸€è‡´æ€§ï¼šä¸çŸ¥è¯†åº“å¯¹æ¯”
   - é€»è¾‘ä¸€è‡´æ€§ï¼šæ¨ç†é“¾éªŒè¯

**äººå·¥è¯„ä¼°é‡‡æ ·**ï¼š

é‡‡ç”¨åˆ†å±‚é‡‡æ ·ç¡®ä¿è¦†ç›–ï¼š
```
æ€»ä½“ â†’ æŒ‰éš¾åº¦åˆ†å±‚ â†’ æŒ‰ç±»å‹åˆ†å±‚ â†’ éšæœºé‡‡æ · â†’ äººå·¥è¯„ä¼°
```

âš ï¸ **å¸¸è§é™·é˜±**ï¼š
- è¿‡åº¦ä¾èµ–å•ä¸€ç”Ÿæˆæ¨¡å‹
- å¿½è§†ç”Ÿæˆæ•°æ®çš„åˆ†å¸ƒåç§»
- ç¼ºä¹ç³»ç»Ÿæ€§çš„è´¨é‡æ§åˆ¶
- åˆæˆæ•°æ®æ¯”ä¾‹è¿‡é«˜å¯¼è‡´æ€§èƒ½é€€åŒ–

## 3.5 æ•°æ®é…æ¯”ä¸è¯¾ç¨‹å­¦ä¹ 

### 3.5.1 æ•°æ®é…æ¯”çš„ç†è®ºåŸºç¡€

**æœ€ä¼˜é…æ¯”é—®é¢˜**ï¼š

ç»™å®š $K$ ç±»ä»»åŠ¡æ•°æ® $\{D_1, D_2, ..., D_K\}$ï¼Œå¯»æ‰¾æœ€ä¼˜æ··åˆæ¯”ä¾‹ $\{\alpha_1, \alpha_2, ..., \alpha_K\}$ï¼š

$$\min_{\alpha} \sum_{i=1}^{K} w_i \cdot \mathcal{L}_i(\theta; \alpha_i \cdot D_i)$$

çº¦æŸæ¡ä»¶ï¼š$\sum_{i=1}^{K} \alpha_i = 1, \alpha_i \geq 0$

**é…æ¯”ç­–ç•¥**ï¼š

1. **å‡åŒ€é…æ¯”**ï¼š$\alpha_i = 1/K$
2. **æŒ‰é‡é…æ¯”**ï¼š$\alpha_i \propto |D_i|$
3. **æŒ‰æ€§èƒ½é…æ¯”**ï¼š$\alpha_i \propto 1/\mathcal{L}_i$
4. **åŠ¨æ€é…æ¯”**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´

### 3.5.2 è¯¾ç¨‹å­¦ä¹ è®¾è®¡

**éš¾åº¦è¯„ä¼°**ï¼š

```
éš¾åº¦æŒ‡æ ‡ = f(é•¿åº¦, å¤æ‚åº¦, ç¨€æœ‰åº¦, æ­§ä¹‰åº¦)
```

**è¯¾ç¨‹ç­–ç•¥**ï¼š

1. **å•è°ƒé€’å¢è¯¾ç¨‹**ï¼š
   ```
   ç®€å•æ ·æœ¬ â†’ ä¸­ç­‰æ ·æœ¬ â†’ å›°éš¾æ ·æœ¬
   ```

2. **å¾ªç¯è¯¾ç¨‹**ï¼š
   ```
   ç¬¬1è½®: ç®€å•(100%)
   ç¬¬2è½®: ç®€å•(50%) + ä¸­ç­‰(50%)
   ç¬¬3è½®: ç®€å•(25%) + ä¸­ç­‰(50%) + å›°éš¾(25%)
   ```

3. **è‡ªé€‚åº”è¯¾ç¨‹**ï¼š
   æ ¹æ®æ¨¡å‹å½“å‰æ€§èƒ½åŠ¨æ€è°ƒæ•´ï¼š
   $$p(x) \propto \exp(-\lambda \cdot |difficulty(x) - competence(model)|)$$

### 3.5.3 å¤šä»»åŠ¡æ•°æ®æ··åˆ

**æ··åˆç²’åº¦é€‰æ‹©**ï¼š

1. **æ ·æœ¬çº§æ··åˆ**ï¼šæ¯ä¸ªbatchåŒ…å«å¤šç§ä»»åŠ¡
   - ä¼˜ç‚¹ï¼šæ¢¯åº¦æ›´æ–°å¹³æ»‘
   - ç¼ºç‚¹ï¼šå¯èƒ½ç›¸äº’å¹²æ‰°

2. **æ‰¹æ¬¡çº§æ··åˆ**ï¼šä¸åŒbatchæ¥è‡ªä¸åŒä»»åŠ¡
   - ä¼˜ç‚¹ï¼šä»»åŠ¡ç‹¬ç«‹æ€§å¥½
   - ç¼ºç‚¹ï¼šå¯èƒ½å¯¼è‡´éœ‡è¡

3. **é˜¶æ®µçº§æ··åˆ**ï¼šåˆ†é˜¶æ®µè®­ç»ƒä¸åŒä»»åŠ¡
   - ä¼˜ç‚¹ï¼šä¸“æ³¨åº¦é«˜
   - ç¼ºç‚¹ï¼šæ˜“é—å¿˜æ—©æœŸä»»åŠ¡

**é‡‡æ ·ç®—æ³•**ï¼š

```python
# æ¸©åº¦é‡‡æ ·
def temperature_sampling(task_sizes, temperature=1.0):
    probs = np.array(task_sizes) ** (1/temperature)
    probs = probs / probs.sum()
    return probs

# temperature > 1: æ›´å‡åŒ€
# temperature < 1: æ›´åå‘å¤§ä»»åŠ¡
# temperature = 1: æŒ‰æ¯”ä¾‹é‡‡æ ·
```

### 3.5.4 æ•°æ®é…æ¯”çš„å®éªŒéªŒè¯

**ç½‘æ ¼æœç´¢æ³•**ï¼š

```
é…æ¯”å®éªŒçŸ©é˜µï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Task A â”‚ Task B â”‚ Task C â”‚ Score â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  0.33  â”‚  0.33  â”‚  0.34  â”‚  0.85 â”‚
â”‚  0.50  â”‚  0.25  â”‚  0.25  â”‚  0.87 â”‚
â”‚  0.25  â”‚  0.50  â”‚  0.25  â”‚  0.86 â”‚
â”‚  0.60  â”‚  0.20  â”‚  0.20  â”‚  0.88 â”‚ â† æœ€ä¼˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è´å¶æ–¯ä¼˜åŒ–**ï¼š

ä½¿ç”¨é«˜æ–¯è¿‡ç¨‹å»ºæ¨¡é…æ¯”ä¸æ€§èƒ½çš„å…³ç³»ï¼š

$$f(\alpha) \sim \mathcal{GP}(\mu(\alpha), k(\alpha, \alpha'))$$

é€šè¿‡æœ€å¤§åŒ–é‡‡é›†å‡½æ•°é€‰æ‹©ä¸‹ä¸€ä¸ªå®éªŒç‚¹ã€‚

ğŸ’¡ **å®ç”¨æŠ€å·§**ï¼š
- å…ˆç”¨å°è§„æ¨¡å®éªŒå¿«é€Ÿæ¢ç´¢é…æ¯”ç©ºé—´
- å…³æ³¨ä»»åŠ¡é—´çš„ååŒæ•ˆåº”å’Œè´Ÿè¿ç§»
- ä¿ç•™ä¸€å®šæ¯”ä¾‹çš„"ä¿æŠ¤æ•°æ®"é˜²æ­¢èƒ½åŠ›é€€åŒ–
- ä½¿ç”¨æ—©åœé¿å…è¿‡æ‹ŸåˆæŸç±»ä»»åŠ¡

## æœ¬ç« å°ç»“

æœ¬ç« ç³»ç»Ÿä»‹ç»äº†åè®­ç»ƒæ•°æ®å·¥ç¨‹çš„å®Œæ•´æµç¨‹ã€‚æ ¸å¿ƒè¦ç‚¹åŒ…æ‹¬ï¼š

1. **æ•°æ®è´¨é‡ä¼˜äºæ•°é‡**ï¼šç²¾å¿ƒè®¾è®¡çš„å°è§„æ¨¡é«˜è´¨é‡æ•°æ®å¾€å¾€ä¼˜äºå¤§è§„æ¨¡ä½è´¨é‡æ•°æ®

2. **æ ‡æ³¨ä½“ç³»æ˜¯åŸºçŸ³**ï¼šå®Œå–„çš„æ ‡æ³¨è§„èŒƒã€è´¨é‡æ§åˆ¶å’Œæ ‡æ³¨è€…ç®¡ç†å†³å®šæ•°æ®è´¨é‡ä¸Šé™

3. **æ•°æ®é£è½®é©±åŠ¨è¿­ä»£**ï¼šé€šè¿‡éƒ¨ç½²-æ”¶é›†-æ ‡æ³¨-è®­ç»ƒçš„å¾ªç¯å®ç°æŒç»­æ”¹è¿›

4. **åˆæˆæ•°æ®ä½œä¸ºè¡¥å……**ï¼šåˆç†ä½¿ç”¨åˆæˆæ•°æ®å¯ä»¥æå‡æ•ˆç‡ï¼Œä½†éœ€è¦ä¸¥æ ¼çš„è´¨é‡æ§åˆ¶

5. **é…æ¯”ä¸è¯¾ç¨‹å½±å“æ”¶æ•›**ï¼šæ•°æ®é…æ¯”å’Œè¯¾ç¨‹è®¾è®¡ç›´æ¥å½±å“è®­ç»ƒæ•ˆç‡å’Œæœ€ç»ˆæ€§èƒ½

**å…³é”®å…¬å¼å›é¡¾**ï¼š

- æ•°æ®è´¨é‡è¯„åˆ†ï¼š$Q_{data} = \sum \omega_i \cdot Q_i$
- æ ‡æ³¨ä¸€è‡´æ€§ï¼š$\kappa = \frac{P_o - P_e}{1 - P_e}$
- çŸ¥è¯†è’¸é¦æŸå¤±ï¼š$\mathcal{L} = \alpha \cdot \mathcal{L}_{CE} + (1-\alpha) \cdot \mathcal{L}_{KL}$
- æœ€ä¼˜é…æ¯”ï¼š$\min_{\alpha} \sum w_i \cdot \mathcal{L}_i(\theta; \alpha_i \cdot D_i)$

## ç»ƒä¹ é¢˜

### åŸºç¡€é¢˜

**ç»ƒä¹  3.1**ï¼šè®¾è®¡ä¸€ä¸ªå¤šè½®å¯¹è¯ä»»åŠ¡çš„æ ‡æ³¨è§„èŒƒï¼ŒåŒ…æ‹¬æ ¼å¼è¦æ±‚ã€è´¨é‡æ ‡å‡†å’Œè¯„åˆ†ç»†åˆ™ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>

è€ƒè™‘ä»¥ä¸‹è¦ç´ ï¼š
- å¯¹è¯çš„è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡ä¾èµ–
- è§’è‰²ä¸€è‡´æ€§
- ä¿¡æ¯çš„ç´¯ç§¯æ€§
- é”™è¯¯ä¼ æ’­çš„å¤„ç†

</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

æ ‡æ³¨è§„èŒƒåº”åŒ…æ‹¬ï¼š

1. **æ ¼å¼è§„èŒƒ**ï¼š
   - æ˜ç¡®çš„è½®æ¬¡æ ‡è®°
   - è§’è‰²æ ‡è¯†ï¼ˆç”¨æˆ·/åŠ©æ‰‹ï¼‰
   - ä¸Šä¸‹æ–‡çª—å£å®šä¹‰

2. **è´¨é‡ç»´åº¦**ï¼š
   - ç›¸å…³æ€§ï¼šå›å¤æ˜¯å¦é’ˆå¯¹å½“å‰é—®é¢˜
   - è¿è´¯æ€§ï¼šæ˜¯å¦ä¸å†å²å¯¹è¯ä¸€è‡´
   - ä¿¡æ¯æ€§ï¼šæ˜¯å¦æä¾›æœ‰ä»·å€¼ä¿¡æ¯
   - è‡ªç„¶åº¦ï¼šè¯­è¨€æ˜¯å¦æµç•…è‡ªç„¶

3. **è¯„åˆ†æ ‡å‡†**ï¼š
   - 5åˆ†åˆ¶ï¼Œæ¯ä¸ªç»´åº¦ç‹¬ç«‹è¯„åˆ†
   - æ€»åˆ†åŠ æƒå¹³å‡
   - ä½äº3åˆ†éœ€è¦é‡æ–°æ ‡æ³¨

4. **ç‰¹æ®Šæƒ…å†µå¤„ç†**ï¼š
   - è¯é¢˜è½¬æ¢çš„åˆç†æ€§åˆ¤æ–­
   - æŒ‡ä»£æ¶ˆè§£çš„å‡†ç¡®æ€§
   - å¤šè½®ä¾èµ–çš„å®Œæ•´æ€§æ£€æŸ¥

</details>

**ç»ƒä¹  3.2**ï¼šè®¡ç®—ä¸¤ä¸ªæ ‡æ³¨è€…çš„ Cohen's Kappa ç³»æ•°ã€‚æ ‡æ³¨è€…Aå’ŒBå¯¹100ä¸ªæ ·æœ¬è¿›è¡ŒäºŒåˆ†ç±»æ ‡æ³¨ï¼Œå…¶ä¸­ï¼š
- ä¸¤è€…éƒ½æ ‡æ³¨ä¸ºæ­£ä¾‹ï¼š40ä¸ª
- ä¸¤è€…éƒ½æ ‡æ³¨ä¸ºè´Ÿä¾‹ï¼š35ä¸ª  
- Aæ­£Bè´Ÿï¼š15ä¸ª
- Aè´ŸBæ­£ï¼š10ä¸ª

<details>
<summary>ğŸ’¡ æç¤º</summary>

Kappa å…¬å¼ï¼š$\kappa = \frac{P_o - P_e}{1 - P_e}$

å…¶ä¸­ï¼š
- $P_o$ = è§‚å¯Ÿä¸€è‡´æ€§
- $P_e$ = æœŸæœ›ä¸€è‡´æ€§

</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

è®¡ç®—æ­¥éª¤ï¼š

1. **è§‚å¯Ÿä¸€è‡´æ€§**ï¼š
   $P_o = \frac{40 + 35}{100} = 0.75$

2. **è¾¹é™…æ¦‚ç‡**ï¼š
   - Aæ ‡æ­£ä¾‹ï¼š$\frac{40 + 15}{100} = 0.55$
   - Bæ ‡æ­£ä¾‹ï¼š$\frac{40 + 10}{100} = 0.50$
   - Aæ ‡è´Ÿä¾‹ï¼š$\frac{35 + 10}{100} = 0.45$
   - Bæ ‡è´Ÿä¾‹ï¼š$\frac{35 + 15}{100} = 0.50$

3. **æœŸæœ›ä¸€è‡´æ€§**ï¼š
   $P_e = 0.55 \times 0.50 + 0.45 \times 0.50 = 0.275 + 0.225 = 0.50$

4. **Kappaç³»æ•°**ï¼š
   $\kappa = \frac{0.75 - 0.50}{1 - 0.50} = \frac{0.25}{0.50} = 0.50$

ç»“æœï¼šÎº = 0.50ï¼Œè¡¨ç¤ºä¸­ç­‰ç¨‹åº¦çš„ä¸€è‡´æ€§ã€‚

</details>

**ç»ƒä¹  3.3**ï¼šè®¾è®¡ä¸€ä¸ªæ•°æ®é£è½®çš„æœ€å°å¯è¡Œç‰ˆæœ¬ï¼ˆMVPï¼‰ï¼ŒåŒ…æ‹¬æ•°æ®æ”¶é›†ã€ç­›é€‰ã€æ ‡æ³¨å’Œè®­ç»ƒçš„å®Œæ•´æµç¨‹ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>

è€ƒè™‘ï¼š
- æœ€ç®€å•çš„åé¦ˆæœºåˆ¶
- è‡ªåŠ¨åŒ–vsäººå·¥çš„å¹³è¡¡
- è¿­ä»£å‘¨æœŸçš„è®¾å®š
- è¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©

</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

MVP æ•°æ®é£è½®è®¾è®¡ï¼š

1. **æ•°æ®æ”¶é›†ï¼ˆæ¯æ—¥ï¼‰**ï¼š
   - ç”¨æˆ·æŸ¥è¯¢æ—¥å¿—
   - ç®€å•çš„ğŸ‘/ğŸ‘åé¦ˆ
   - å“åº”æ—¶é—´å’Œé‡è¯•æ¬¡æ•°

2. **æ•°æ®ç­›é€‰ï¼ˆæ¯å‘¨ï¼‰**ï¼š
   - ç­›é€‰æ ‡å‡†ï¼š
     * æ‰€æœ‰ğŸ‘çš„æ ·æœ¬
     * å“åº”æ—¶é—´>5ç§’çš„æ ·æœ¬
     * é‡è¯•>2æ¬¡çš„æ ·æœ¬
   - æ¯å‘¨é€‰æ‹©Top 100æ ·æœ¬

3. **æ ‡æ³¨æµç¨‹ï¼ˆæ¯å‘¨ï¼‰**ï¼š
   - 2åæ ‡æ³¨è€…ç‹¬ç«‹æ ‡æ³¨
   - ä¸ä¸€è‡´çš„ç”±ç¬¬3äººä»²è£
   - ç”Ÿæˆæ”¹è¿›çš„å›å¤

4. **æ¨¡å‹æ›´æ–°ï¼ˆæ¯ä¸¤å‘¨ï¼‰**ï¼š
   - ç´¯ç§¯200ä¸ªæ–°æ ·æœ¬
   - æ··åˆ10%å†å²æ•°æ®
   - å¢é‡è®­ç»ƒ2ä¸ªepoch

5. **è¯„ä¼°éªŒè¯**ï¼š
   - ä¿æŒå›ºå®šæµ‹è¯•é›†
   - A/Bæµ‹è¯•ï¼ˆ5%æµé‡ï¼‰
   - å…³é”®æŒ‡æ ‡ï¼šæ»¡æ„åº¦æå‡>2%åˆ™å…¨é‡

</details>

### æŒ‘æˆ˜é¢˜

**ç»ƒä¹  3.4**ï¼šè®¾è®¡ä¸€ä¸ªè‡ªé€‚åº”çš„æ•°æ®é…æ¯”ç®—æ³•ï¼Œèƒ½å¤Ÿæ ¹æ®æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°åŠ¨æ€è°ƒæ•´è®­ç»ƒæ•°æ®çš„é‡‡æ ·æ¯”ä¾‹ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>

è€ƒè™‘ï¼š
- å¦‚ä½•åº¦é‡å„ä»»åŠ¡çš„å­¦ä¹ è¿›åº¦
- å¦‚ä½•å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨
- å¦‚ä½•é¿å…æŸäº›ä»»åŠ¡è¢«"é¥¿æ­»"
- å¦‚ä½•å¤„ç†ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»

</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

è‡ªé€‚åº”é…æ¯”ç®—æ³•è®¾è®¡ï¼š

1. **æ€§èƒ½è¿½è¸ª**ï¼š
   ```python
   performance[task] = exponential_moving_average(
       current_loss, 
       historical_performance,
       alpha=0.1
   )
   ```

2. **å­¦ä¹ è¿›åº¦è¯„ä¼°**ï¼š
   ```python
   progress[task] = 1 - (current_loss / initial_loss)
   learning_rate[task] = d(progress) / d(steps)
   ```

3. **é…æ¯”æ›´æ–°è§„åˆ™**ï¼š
   ```python
   # åŸºç¡€é…æ¯”
   base_ratio = 1 / num_tasks
   
   # æ€§èƒ½è°ƒæ•´é¡¹
   perf_adjust = softmax(-performance / temperature)
   
   # è¿›åº¦è°ƒæ•´é¡¹
   progress_adjust = softmax(-learning_rate / temperature)
   
   # æœ€ç»ˆé…æ¯”
   ratio[task] = base_ratio + 
                 Î± * perf_adjust + 
                 Î² * progress_adjust
   
   # å½’ä¸€åŒ–
   ratio = ratio / ratio.sum()
   
   # ä¿åº•æœºåˆ¶
   ratio = max(ratio, min_ratio)
   ```

4. **æ¢ç´¢æœºåˆ¶**ï¼š
   - æ¯Nä¸ªepochéšæœºæå‡æŸä¸ªä»»åŠ¡æ¯”ä¾‹
   - ä½¿ç”¨Îµ-greedyç­–ç•¥
   - è®°å½•æ¢ç´¢ç»“æœç”¨äºæœªæ¥å†³ç­–

5. **çº¦æŸæ¡ä»¶**ï¼š
   - æœ€å°æ¯”ä¾‹ï¼šmin_ratio = 0.05
   - æœ€å¤§æ¯”ä¾‹ï¼šmax_ratio = 0.5
   - å¹³æ»‘æ›´æ–°ï¼šé™åˆ¶ç›¸é‚»epochçš„å˜åŒ–ç‡

</details>

**ç»ƒä¹  3.5**ï¼šè®¾è®¡ä¸€ä¸ªåˆæˆæ•°æ®è´¨é‡è¯„ä¼°ç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«å’Œè¿‡æ»¤ä½è´¨é‡çš„ç”Ÿæˆæ•°æ®ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>

ä»å¤šä¸ªç»´åº¦è¯„ä¼°ï¼š
- è¯­è¨€è´¨é‡
- äº‹å®å‡†ç¡®æ€§
- ä»»åŠ¡ç›¸å…³æ€§
- ä¸çœŸå®æ•°æ®çš„åˆ†å¸ƒå·®å¼‚

</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

è´¨é‡è¯„ä¼°ç³»ç»Ÿè®¾è®¡ï¼š

1. **å¤šç»´åº¦è¯„åˆ†å™¨**ï¼š

   a) **æµç•…åº¦è¯„åˆ†**ï¼š
   ```python
   fluency = 1 / (1 + perplexity / baseline_ppl)
   ```

   b) **å¤šæ ·æ€§è¯„åˆ†**ï¼š
   ```python
   diversity = (unique_ngrams / total_ngrams) * 
              (1 - self_bleu_score)
   ```

   c) **ä¸€è‡´æ€§è¯„åˆ†**ï¼š
   ```python
   # å¤šæ¬¡ç”Ÿæˆçš„ä¸€è‡´æ€§
   consistency = mean_pairwise_similarity(
       multiple_generations
   )
   ```

   d) **ç›¸å…³æ€§è¯„åˆ†**ï¼š
   ```python
   relevance = cosine_similarity(
       task_embedding, 
       response_embedding
   )
   ```

2. **å¼‚å¸¸æ£€æµ‹**ï¼š
   ```python
   # ä½¿ç”¨å­¤ç«‹æ£®æ—æ£€æµ‹å¼‚å¸¸
   from sklearn.ensemble import IsolationForest
   
   features = extract_features(synthetic_data)
   detector = IsolationForest(contamination=0.1)
   outliers = detector.fit_predict(features)
   ```

3. **åˆ†å¸ƒåŒ¹é…**ï¼š
   ```python
   # KLæ•£åº¦æ£€æµ‹åˆ†å¸ƒåç§»
   kl_div = kl_divergence(
       real_data_distribution,
       synthetic_data_distribution
   )
   
   if kl_div > threshold:
       flag_as_distribution_shift()
   ```

4. **é›†æˆå†³ç­–**ï¼š
   ```python
   quality_score = weighted_sum([
       fluency * 0.2,
       diversity * 0.2,
       consistency * 0.3,
       relevance * 0.3
   ])
   
   if quality_score < 0.6 or is_outlier:
       filter_out()
   ```

5. **äººå·¥éªŒè¯é‡‡æ ·**ï¼š
   - é«˜ç½®ä¿¡åº¦é€šè¿‡ï¼šç›´æ¥ä½¿ç”¨
   - ä¸­ç½®ä¿¡åº¦ï¼šæŒ‰æ¯”ä¾‹é‡‡æ ·éªŒè¯
   - ä½ç½®ä¿¡åº¦ï¼šå…¨éƒ¨äººå·¥å®¡æ ¸

</details>

**ç»ƒä¹  3.6**ï¼šç»™å®šä¸€ä¸ªåŒ…å«10ä¸ªä¸åŒéš¾åº¦ç­‰çº§ä»»åŠ¡çš„æ•°æ®é›†ï¼Œè®¾è®¡ä¸€ä¸ªè¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œä½¿æ¨¡å‹è®­ç»ƒæ•ˆç‡æœ€å¤§åŒ–ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>

è€ƒè™‘ï¼š
- éš¾åº¦è¯„ä¼°çš„å®¢è§‚æŒ‡æ ‡
- è¯¾ç¨‹çš„å¹³æ»‘è¿‡æ¸¡
- é˜²æ­¢ç¾éš¾æ€§é—å¿˜
- æ”¶æ•›é€Ÿåº¦vsæœ€ç»ˆæ€§èƒ½çš„æƒè¡¡

</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

è¯¾ç¨‹å­¦ä¹ ç­–ç•¥è®¾è®¡ï¼š

1. **éš¾åº¦é‡åŒ–**ï¼š
   ```python
   difficulty = 0.3 * length_score + 
                0.2 * vocabulary_score +
                0.3 * reasoning_steps +
                0.2 * ambiguity_score
   ```

2. **åˆ†æ¡¶ç­–ç•¥**ï¼š
   - Level 1-3: åŸºç¡€ä»»åŠ¡ï¼ˆ30%ï¼‰
   - Level 4-6: ä¸­çº§ä»»åŠ¡ï¼ˆ40%ï¼‰
   - Level 7-10: é«˜çº§ä»»åŠ¡ï¼ˆ30%ï¼‰

3. **æ¸è¿›å¼è¯¾ç¨‹**ï¼š

   **é˜¶æ®µ1ï¼ˆEpoch 1-5ï¼‰**ï¼š
   ```
   Level 1-3: 70%
   Level 4-6: 25%
   Level 7-10: 5%
   ```

   **é˜¶æ®µ2ï¼ˆEpoch 6-10ï¼‰**ï¼š
   ```
   Level 1-3: 40%
   Level 4-6: 40%
   Level 7-10: 20%
   ```

   **é˜¶æ®µ3ï¼ˆEpoch 11-15ï¼‰**ï¼š
   ```
   Level 1-3: 20%
   Level 4-6: 40%
   Level 7-10: 40%
   ```

   **é˜¶æ®µ4ï¼ˆEpoch 16+ï¼‰**ï¼š
   ```
   å‡åŒ€åˆ†å¸ƒæˆ–åŸºäºæ€§èƒ½çš„è‡ªé€‚åº”é‡‡æ ·
   ```

4. **åé—å¿˜æœºåˆ¶**ï¼š
   - æ¯ä¸ªé˜¶æ®µä¿ç•™20%çš„å‰æœŸæ•°æ®
   - ä½¿ç”¨ç»éªŒå›æ”¾ç¼“å†²åŒº
   - å®šæœŸåœ¨æ—©æœŸä»»åŠ¡ä¸Šè¯„ä¼°

5. **æ—©åœæ¡ä»¶**ï¼š
   ```python
   if (val_loss_increase_count > patience and
       all_levels_coverage > 0.8):
       stop_training()
   ```

6. **åŠ¨æ€è°ƒæ•´**ï¼š
   ```python
   # åŸºäºå­¦ä¹ æ›²çº¿è°ƒæ•´è¿›åº¦
   if learning_plateaued(level_k):
       increase_difficulty_ratio(level_k+1)
   ```

</details>

**ç»ƒä¹  3.7**ï¼šè®¾è®¡ä¸€ä¸ªæ•°æ®è¡€ç¼˜è¿½è¸ªç³»ç»Ÿï¼Œèƒ½å¤Ÿè¿½è¸ªæ¯ä¸ªè®­ç»ƒæ ·æœ¬ä»åŸå§‹æ•°æ®åˆ°æœ€ç»ˆä½¿ç”¨çš„å®Œæ•´å†å²ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>

è€ƒè™‘ï¼š
- æ•°æ®çš„ç‰ˆæœ¬æ§åˆ¶
- å˜æ¢æ“ä½œçš„è®°å½•
- æ€§èƒ½å½’å› åˆ†æ
- å­˜å‚¨å’ŒæŸ¥è¯¢æ•ˆç‡

</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

æ•°æ®è¡€ç¼˜ç³»ç»Ÿè®¾è®¡ï¼š

1. **æ•°æ®æ¨¡å‹**ï¼š
   ```python
   class DataLineage:
       sample_id: str  # å”¯ä¸€æ ‡è¯†
       source_id: str  # åŸå§‹æ•°æ®ID
       version: str    # æ•°æ®ç‰ˆæœ¬
       
       transformations: List[{
           'operation': str,
           'timestamp': datetime,
           'parameters': dict,
           'operator': str  # äºº/æ¨¡å‹
       }]
       
       quality_scores: List[{
           'metric': str,
           'score': float,
           'timestamp': datetime
       }]
       
       usage_history: List[{
           'model_version': str,
           'training_run': str,
           'epoch': int,
           'loss_contribution': float
       }]
   ```

2. **æ“ä½œè¿½è¸ª**ï¼š
   ```python
   @track_lineage
   def transform_data(data, operation):
       result = operation(data)
       lineage.add_transformation({
           'input_hash': hash(data),
           'output_hash': hash(result),
           'operation': operation.__name__,
           'timestamp': now()
       })
       return result
   ```

3. **ç‰ˆæœ¬ç®¡ç†**ï¼š
   ```python
   # Git-like ç‰ˆæœ¬æ§åˆ¶
   data_version = hashlib.sha256(
       data_content + parent_version
   ).hexdigest()[:8]
   ```

4. **æŸ¥è¯¢æ¥å£**ï¼š
   ```python
   # æ­£å‘è¿½è¸ª
   def trace_forward(sample_id):
       return lineage_db.query(
           source_id=sample_id
       )
   
   # åå‘è¿½è¸ª
   def trace_backward(model_issue):
       problematic_samples = identify_issues()
       return [
           get_lineage(s) for s in problematic_samples
       ]
   ```

5. **æ€§èƒ½å½’å› **ï¼š
   ```python
   def attribute_performance(model_degradation):
       # æ‰¾å‡ºæ€§èƒ½ä¸‹é™ç›¸å…³çš„æ•°æ®å˜åŒ–
       recent_changes = get_recent_data_changes()
       correlation = calculate_correlation(
           recent_changes,
           model_degradation
       )
       return rank_by_impact(correlation)
   ```

6. **å­˜å‚¨ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨å›¾æ•°æ®åº“å­˜å‚¨è¡€ç¼˜å…³ç³»
   - å®šæœŸå‹ç¼©å†å²è®°å½•
   - åªä¿ç•™å…³é”®èŠ‚ç‚¹çš„å®Œæ•´æ•°æ®

</details>

**ç»ƒä¹  3.8**ï¼šè®¾è®¡ä¸€ä¸ªä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰ç­–ç•¥ï¼Œåœ¨æ ‡æ³¨é¢„ç®—æœ‰é™çš„æƒ…å†µä¸‹é€‰æ‹©æœ€æœ‰ä»·å€¼çš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>

ç»“åˆå¤šç§é€‰æ‹©ç­–ç•¥ï¼š
- ä¸ç¡®å®šæ€§
- å¤šæ ·æ€§  
- ä»£è¡¨æ€§
- é¢„æœŸæ¨¡å‹æ”¹è¿›

</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

ä¸»åŠ¨å­¦ä¹ ç­–ç•¥è®¾è®¡ï¼š

1. **ä¸ç¡®å®šæ€§é‡‡æ ·**ï¼š
   ```python
   def uncertainty_sampling(model, unlabeled_data):
       predictions = model.predict_proba(unlabeled_data)
       
       # ç†µå€¼è®¡ç®—
       entropy = -sum(p * log(p) for p in predictions)
       
       # æœ€å°ç½®ä¿¡åº¦
       least_confidence = 1 - max(predictions)
       
       # è¾¹ç•Œé‡‡æ ·
       margin = abs(top1_prob - top2_prob)
       
       uncertainty = Î±*entropy + Î²*least_confidence + Î³/margin
       return uncertainty
   ```

2. **å¤šæ ·æ€§é‡‡æ ·**ï¼š
   ```python
   def diversity_sampling(selected_samples, candidate):
       # åŸºäºåµŒå…¥çš„å¤šæ ·æ€§
       min_distance = min([
           cosine_distance(candidate_emb, selected_emb)
           for selected_emb in selected_samples
       ])
       
       # åŸºäºèšç±»çš„å¤šæ ·æ€§
       cluster_coverage = len(unique_clusters) / total_clusters
       
       return min_distance * cluster_coverage
   ```

3. **ä»£è¡¨æ€§é‡‡æ ·**ï¼š
   ```python
   def representativeness(sample, unlabeled_pool):
       # å¯†åº¦ä¼°è®¡
       density = mean([
           similarity(sample, other)
           for other in unlabeled_pool
       ])
       
       # ä¸­å¿ƒæ€§
       centrality = 1 / mean_distance_to_others
       
       return density * centrality
   ```

4. **é¢„æœŸæ¨¡å‹æ”¹è¿›**ï¼š
   ```python
   def expected_model_change(model, sample):
       # é¢„æœŸæ¢¯åº¦é•¿åº¦
       gradient = compute_gradient(model, sample)
       egl = norm(gradient)
       
       # é¢„æœŸè¯¯å·®å‡å°‘
       eer = estimate_error_reduction(model, sample)
       
       return egl + eer
   ```

5. **æ··åˆç­–ç•¥**ï¼š
   ```python
   def hybrid_active_learning(
       model, 
       unlabeled_data, 
       budget,
       selected=[]
   ):
       scores = []
       for sample in unlabeled_data:
           u_score = uncertainty_sampling(model, sample)
           d_score = diversity_sampling(selected, sample)
           r_score = representativeness(sample, unlabeled_data)
           e_score = expected_model_change(model, sample)
           
           # åŠ¨æ€æƒé‡
           w1 = 0.4 if len(selected) < budget*0.3 else 0.2
           w2 = 0.2 if len(selected) < budget*0.3 else 0.4
           w3 = 0.2
           w4 = 0.2
           
           total = w1*u_score + w2*d_score + w3*r_score + w4*e_score
           scores.append(total)
       
       # é€‰æ‹©top-k
       top_indices = argsort(scores)[-budget:]
       return unlabeled_data[top_indices]
   ```

6. **æ‰¹é‡é€‰æ‹©ä¼˜åŒ–**ï¼š
   ```python
   # é¿å…æ‰¹æ¬¡å†…å†—ä½™
   def batch_selection(candidates, batch_size):
       selected = []
       for _ in range(batch_size):
           best = argmax([
               score(c) - Î»*max_similarity(c, selected)
               for c in candidates
           ])
           selected.append(candidates[best])
           candidates.remove(best)
       return selected
   ```

</details>

## å¸¸è§é™·é˜±ä¸é”™è¯¯ (Gotchas)

### æ•°æ®ç›¸å…³é™·é˜±

1. **æ ‡æ³¨è§„èŒƒæ¼‚ç§»**
   - é—®é¢˜ï¼šéšæ—¶é—´æ¨ç§»ï¼Œæ ‡æ³¨æ ‡å‡†é€æ¸åç¦»
   - è§£å†³ï¼šå®šæœŸæ ¡å‡†ä¼šè®®ï¼Œç»´æŠ¤æ ‡æ³¨ç¤ºä¾‹åº“

2. **æ•°æ®æ³„éœ²**
   - é—®é¢˜ï¼šæµ‹è¯•é›†ä¿¡æ¯æ³„éœ²åˆ°è®­ç»ƒé›†
   - è§£å†³ï¼šä¸¥æ ¼çš„æ•°æ®éš”ç¦»ï¼Œä½¿ç”¨æ—¶é—´æˆ³åˆ†å‰²

3. **æ ‡æ³¨è€…åè§ç´¯ç§¯**
   - é—®é¢˜ï¼šç‰¹å®šæ ‡æ³¨è€…çš„åå¥½è¢«æ”¾å¤§
   - è§£å†³ï¼šæ ‡æ³¨è€…è½®æ¢ï¼Œäº¤å‰éªŒè¯

### åˆæˆæ•°æ®é™·é˜±

4. **æ¨¡å‹åç¼©**
   - é—®é¢˜ï¼šç”¨æ¨¡å‹ç”Ÿæˆçš„æ•°æ®è®­ç»ƒå¯¼è‡´å¤šæ ·æ€§é™ä½
   - è§£å†³ï¼šä¿æŒçœŸå®æ•°æ®æ¯”ä¾‹ï¼Œå®šæœŸæ³¨å…¥æ–°æ•°æ®

5. **é”™è¯¯æ”¾å¤§**
   - é—®é¢˜ï¼šç”Ÿæˆæ•°æ®ä¸­çš„é”™è¯¯è¢«å­¦ä¹ å’Œæ”¾å¤§
   - è§£å†³ï¼šä¸¥æ ¼çš„è´¨é‡è¿‡æ»¤ï¼Œäººå·¥éªŒè¯å…³é”®æ ·æœ¬

6. **åˆ†å¸ƒåç§»æœªå¯Ÿè§‰**
   - é—®é¢˜ï¼šåˆæˆæ•°æ®åˆ†å¸ƒé€æ¸åç¦»çœŸå®åˆ†å¸ƒ
   - è§£å†³ï¼šæŒç»­ç›‘æ§åˆ†å¸ƒæŒ‡æ ‡ï¼Œå®šæœŸæ ¡å‡†

### å·¥ç¨‹å®è·µé™·é˜±

7. **æ•°æ®ç‰ˆæœ¬æ··ä¹±**
   - é—®é¢˜ï¼šä¸åŒå®éªŒä½¿ç”¨äº†ä¸åŒç‰ˆæœ¬çš„æ•°æ®
   - è§£å†³ï¼šä¸¥æ ¼çš„ç‰ˆæœ¬ç®¡ç†ï¼Œå®éªŒé…ç½®è®°å½•

8. **å¢é‡è®­ç»ƒçš„é—å¿˜**
   - é—®é¢˜ï¼šæ–°æ•°æ®è®­ç»ƒåæ—§èƒ½åŠ›é€€åŒ–
   - è§£å†³ï¼šç»éªŒå›æ”¾ï¼Œå¼¹æ€§æƒé‡å·©å›º

9. **æ ‡æ³¨ç“¶é¢ˆ**
   - é—®é¢˜ï¼šæ ‡æ³¨é€Ÿåº¦è·Ÿä¸ä¸Šæ•°æ®äº§ç”Ÿé€Ÿåº¦
   - è§£å†³ï¼šåˆ†ä¼˜å…ˆçº§æ ‡æ³¨ï¼Œè‡ªåŠ¨æ ‡æ³¨è¾…åŠ©

10. **è¯„ä¼°é›†æ±¡æŸ“**
    - é—®é¢˜ï¼šè¯„ä¼°é›†è¢«ç”¨äºè®­ç»ƒå†³ç­–
    - è§£å†³ï¼šè®¾ç½®åªæœ‰å°‘æ•°äººçŸ¥é“çš„ä¿ç•™æµ‹è¯•é›†