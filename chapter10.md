# ç¬¬åç« ï¼šæ¡ˆä¾‹ç ”ç©¶ä¸æœ€ä½³å®è·µ

æœ¬ç« é€šè¿‡å››ä¸ªçœŸå®çš„ç«¯åˆ°ç«¯æ¡ˆä¾‹ï¼Œå±•ç¤º LLM åè®­ç»ƒçš„å®Œæ•´å®è·µæµç¨‹ã€‚æ¯ä¸ªæ¡ˆä¾‹éƒ½æ¶µç›–ä»éœ€æ±‚åˆ†æã€æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒåˆ°éƒ¨ç½²ç›‘æ§çš„å…¨é“¾è·¯ï¼Œå¹¶è¯¦ç»†å‰–æè¿‡ç¨‹ä¸­çš„å…³é”®å†³ç­–å’ŒæŠ€æœ¯ç»†èŠ‚ã€‚é€šè¿‡è¿™äº›æ¡ˆä¾‹ï¼Œæ‚¨å°†å­¦ä¼šå¦‚ä½•å°†å‰ä¹ç« çš„ç†è®ºçŸ¥è¯†æ•´åˆåº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­ï¼ŒæŒæ¡å¤„ç†å¤æ‚å·¥ç¨‹æŒ‘æˆ˜çš„ç³»ç»Ÿæ–¹æ³•ã€‚

## æœ¬ç« å¤§çº²

1. **ChatGPT ç±»å¯¹è¯ç³»ç»Ÿçš„å®Œæ•´å®ç°**
   - ç³»ç»Ÿæ¶æ„è®¾è®¡
   - æ•°æ®æ”¶é›†ä¸é¢„å¤„ç†
   - SFT åŸºçº¿è®­ç»ƒ
   - RLHF ä¼˜åŒ–æµç¨‹
   - å®‰å…¨æ€§ä¸å¯¹é½
   - éƒ¨ç½²ä¸ç›‘æ§

2. **å¤šæ¨¡æ€åŠ©æ‰‹çš„è®­ç»ƒæµç¨‹**
   - æ¨¡æ€èåˆæ¶æ„
   - æ•°æ®å¯¹é½ç­–ç•¥
   - æ¸è¿›å¼è®­ç»ƒ
   - è·¨æ¨¡æ€èƒ½åŠ›è¯„ä¼°
   - æ¨ç†ä¼˜åŒ–

3. **é¢†åŸŸä¸“å®¶æ¨¡å‹çš„æ„å»º**
   - é¢†åŸŸçŸ¥è¯†æ³¨å…¥
   - ä¸“ä¸šæ•°æ®é‡‡é›†
   - æŒç»­å­¦ä¹ æœºåˆ¶
   - æ€§èƒ½åŸºå‡†è®¾è®¡
   - çŸ¥è¯†æ›´æ–°ç­–ç•¥

4. **å¸¸è§å¤±è´¥æ¨¡å¼ä¸è°ƒè¯•æŠ€å·§**
   - è®­ç»ƒä¸ç¨³å®šè¯Šæ–­
   - è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ
   - ç¾éš¾æ€§é—å¿˜
   - åˆ†å¸ƒåç§»å¤„ç†
   - è°ƒè¯•å·¥å…·é“¾

## å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š

1. è®¾è®¡å¹¶å®ç°ç”Ÿäº§çº§çš„å¯¹è¯ç³»ç»Ÿï¼ŒåŒ…æ‹¬å¤šè½®å¯¹è¯ç®¡ç†å’Œä¸ªæ€§åŒ–ä¼˜åŒ–
2. æ„å»ºæ”¯æŒè§†è§‰ã€è¯­éŸ³ç­‰å¤šæ¨¡æ€è¾“å…¥çš„ç»Ÿä¸€åŠ©æ‰‹æ¨¡å‹
3. é’ˆå¯¹ç‰¹å®šé¢†åŸŸï¼ˆåŒ»ç–—ã€æ³•å¾‹ã€é‡‘èï¼‰å®šåˆ¶é«˜æ€§èƒ½ä¸“å®¶æ¨¡å‹
4. è¯†åˆ«å’Œè§£å†³åè®­ç»ƒè¿‡ç¨‹ä¸­çš„å¸¸è§é—®é¢˜ï¼Œå»ºç«‹ç³»ç»Ÿçš„è°ƒè¯•æ–¹æ³•è®º
5. è¯„ä¼°ä¸åŒæŠ€æœ¯è·¯çº¿çš„æƒè¡¡ï¼Œåšå‡ºç¬¦åˆä¸šåŠ¡éœ€æ±‚çš„æ¶æ„å†³ç­–

è®©æˆ‘ä»¬ä»ç¬¬ä¸€ä¸ªæ¡ˆä¾‹å¼€å§‹ï¼Œæ·±å…¥äº†è§£ ChatGPT ç±»ç³»ç»Ÿçš„æ„å»ºè¿‡ç¨‹ã€‚

## 10.1 ChatGPT ç±»å¯¹è¯ç³»ç»Ÿçš„å®Œæ•´å®ç°

æ„å»ºä¸€ä¸ªç”Ÿäº§çº§çš„å¯¹è¯ç³»ç»Ÿéœ€è¦ç³»ç»ŸåŒ–çš„å·¥ç¨‹æ–¹æ³•ã€‚æœ¬èŠ‚ä»¥ä¸€ä¸ªçœŸå®çš„ä¼ä¸šçº§åŠ©æ‰‹é¡¹ç›®ä¸ºä¾‹ï¼Œå±•ç¤ºä»é›¶å¼€å§‹æ„å»ºå¯¹è¯ç³»ç»Ÿçš„å®Œæ•´æµç¨‹ã€‚è¯¥ç³»ç»Ÿæœ€ç»ˆè¾¾åˆ°äº†æ—¥æ´»è·ƒç”¨æˆ· 100 ä¸‡+ï¼Œå¹³å‡å¯¹è¯è½®æ¬¡ 8.5 è½®çš„ç”Ÿäº§æŒ‡æ ‡ã€‚

### 10.1.1 ç³»ç»Ÿæ¶æ„è®¾è®¡

#### æ•´ä½“æ¶æ„

```
ç”¨æˆ·è¾“å…¥ â†’ é¢„å¤„ç† â†’ å®‰å…¨æ£€æŸ¥ â†’ æ¨¡å‹æ¨ç† â†’ åå¤„ç† â†’ å“åº”è¾“å‡º
     â†‘                                              â†“
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆä¼šè¯çŠ¶æ€ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### å…³é”®ç»„ä»¶è®¾è®¡

**1. ä¼šè¯ç®¡ç†å™¨**

ä¼šè¯çŠ¶æ€çš„è®¾è®¡ç›´æ¥å½±å“ç³»ç»Ÿæ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚æˆ‘ä»¬é‡‡ç”¨äº†åˆ†å±‚ç¼“å­˜ç­–ç•¥ï¼š

- **L1 ç¼“å­˜**ï¼šRedisï¼Œå­˜å‚¨æœ€è¿‘ 1000 ä¸ªæ´»è·ƒä¼šè¯
- **L2 ç¼“å­˜**ï¼šPostgreSQLï¼Œå®Œæ•´ä¼šè¯å†å²
- **çŠ¶æ€å‹ç¼©**ï¼šè¶…è¿‡ 10 è½®çš„å¯¹è¯è‡ªåŠ¨æ‘˜è¦

```
ä¼šè¯çŠ¶æ€ç»“æ„ï¼š
{
  session_id: str,
  user_id: str,
  messages: List[Message],
  context_summary: str,  # è‡ªåŠ¨ç”Ÿæˆçš„ä¸Šä¸‹æ–‡æ‘˜è¦
  metadata: {
    created_at: timestamp,
    last_active: timestamp,
    turn_count: int,
    tokens_used: int
  }
}
```

**2. æç¤ºå·¥ç¨‹æ¡†æ¶**

ç³»ç»Ÿæç¤ºï¼ˆSystem Promptï¼‰çš„è®¾è®¡é‡‡ç”¨æ¨¡å—åŒ–ç»“æ„ï¼š

```
åŸºç¡€äººè®¾ (200 tokens)
  â”œâ”€â”€ è§’è‰²å®šä¹‰
  â”œâ”€â”€ èƒ½åŠ›è¾¹ç•Œ
  â””â”€â”€ è¡Œä¸ºå‡†åˆ™

åŠ¨æ€ä¸Šä¸‹æ–‡ (variable)
  â”œâ”€â”€ ç”¨æˆ·ç”»åƒ
  â”œâ”€â”€ ä¼šè¯å†å²æ‘˜è¦
  â””â”€â”€ ç›¸å…³çŸ¥è¯†æ³¨å…¥

ä»»åŠ¡æŒ‡ä»¤ (100 tokens)
  â”œâ”€â”€ å½“å‰ä»»åŠ¡æè¿°
  â””â”€â”€ è¾“å‡ºæ ¼å¼è¦æ±‚
```

ğŸ’¡ **å®ç”¨æŠ€å·§**ï¼šå°†ç³»ç»Ÿæç¤ºåˆ†è§£ä¸ºé™æ€å’ŒåŠ¨æ€éƒ¨åˆ†ï¼Œé™æ€éƒ¨åˆ†å¯ä»¥é¢„å…ˆç¼–ç å¹¶ç¼“å­˜ï¼Œå‡å°‘æ¯æ¬¡æ¨ç†çš„ token å¼€é”€ã€‚

### 10.1.2 æ•°æ®æ”¶é›†ä¸é¢„å¤„ç†

#### æ•°æ®æ¥æºå¤šæ ·åŒ–

1. **ç§å­æ•°æ®**ï¼ˆ10K æ ·æœ¬ï¼‰
   - äººå·¥ç¼–å†™çš„é«˜è´¨é‡å¯¹è¯
   - æ¶µç›– 50+ åœºæ™¯ç±»åˆ«
   - æ¯ä¸ªæ ·æœ¬ç»è¿‡ 3 äººäº¤å‰éªŒè¯

2. **ç”¨æˆ·äº¤äº’æ•°æ®**ï¼ˆ1M+ æ ·æœ¬ï¼‰
   - çœŸå®ç”¨æˆ·å¯¹è¯æ—¥å¿—
   - éšç§è„±æ•å¤„ç†
   - è´¨é‡è¯„åˆ†ç­›é€‰ï¼ˆä¿ç•™ top 30%ï¼‰

3. **åˆæˆæ•°æ®**ï¼ˆ500K æ ·æœ¬ï¼‰
   - Self-Instruct ç”Ÿæˆ
   - ä¸»é¢˜æ§åˆ¶çš„å¤šæ ·æ€§é‡‡æ ·
   - è‡ªåŠ¨è´¨é‡è¿‡æ»¤

#### æ•°æ®é¢„å¤„ç†ç®¡é“

```
åŸå§‹æ•°æ® â†’ æ¸…æ´— â†’ æ ‡å‡†åŒ– â†’ è´¨é‡è¯„åˆ† â†’ å»é‡ â†’ å¹³è¡¡é‡‡æ · â†’ è®­ç»ƒé›†
           â†“        â†“         â†“         â†“        â†“
        å™ªå£°è¿‡æ»¤  æ ¼å¼ç»Ÿä¸€  å¯å‘å¼+æ¨¡å‹  MinHash  ç±»åˆ«å‡è¡¡
```

**å…³é”®å¤„ç†æ­¥éª¤**ï¼š

1. **å¤šè½®å¯¹è¯æ‹†åˆ†**ï¼š
   - ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§
   - æ»‘åŠ¨çª—å£é‡‡æ ·ï¼ˆstride=2ï¼‰
   - æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ 2048 tokens

2. **è´¨é‡è¯„åˆ†æ¨¡å‹**ï¼š
   ä½¿ç”¨ BERT-based åˆ†ç±»å™¨ï¼Œè¯„åˆ†ç»´åº¦åŒ…æ‹¬ï¼š
   - ç›¸å…³æ€§ï¼ˆ0-1ï¼‰
   - æµç•…æ€§ï¼ˆ0-1ï¼‰
   - ä¿¡æ¯é‡ï¼ˆ0-1ï¼‰
   - å®‰å…¨æ€§ï¼ˆ0-1ï¼‰
   
   ç»¼åˆè¯„åˆ† = 0.3Ã—ç›¸å…³æ€§ + 0.2Ã—æµç•…æ€§ + 0.3Ã—ä¿¡æ¯é‡ + 0.2Ã—å®‰å…¨æ€§

3. **å»é‡ç­–ç•¥**ï¼š
   - å®Œå…¨åŒ¹é…å»é‡
   - MinHash è¿‘ä¼¼å»é‡ï¼ˆç›¸ä¼¼åº¦é˜ˆå€¼ 0.85ï¼‰
   - è¯­ä¹‰å»é‡ï¼ˆåµŒå…¥å‘é‡ä½™å¼¦ç›¸ä¼¼åº¦ > 0.95ï¼‰

âš ï¸ **å¸¸è§é™·é˜±**ï¼šè¿‡åº¦æ¸…æ´—ä¼šå¯¼è‡´æ•°æ®åˆ†å¸ƒè¿‡äºç‹­çª„ï¼Œä¿ç•™ 5-10% çš„"å™ªå£°"æ•°æ®æœ‰åŠ©äºæé«˜æ¨¡å‹é²æ£’æ€§ã€‚

### 10.1.3 SFT åŸºçº¿è®­ç»ƒ

#### è®­ç»ƒé…ç½®

åŸºäº 7B å‚æ•°çš„åŸºåº§æ¨¡å‹ï¼ŒSFT è®­ç»ƒé…ç½®ï¼š

```yaml
training_config:
  base_model: "llama-2-7b"
  learning_rate: 2e-5
  warmup_steps: 1000
  total_steps: 50000
  batch_size: 128
  gradient_accumulation: 4
  max_length: 2048
  
  # å…³é”®ä¼˜åŒ–
  gradient_checkpointing: true
  mixed_precision: "bf16"
  flash_attention: true
  
  # æ­£åˆ™åŒ–
  weight_decay: 0.01
  dropout: 0.1
  label_smoothing: 0.1
```

#### è®­ç»ƒç­–ç•¥

**1. è¯¾ç¨‹å­¦ä¹ **

åˆ†ä¸‰ä¸ªé˜¶æ®µé€æ­¥å¢åŠ ä»»åŠ¡éš¾åº¦ï¼š

- **é˜¶æ®µ 1**ï¼ˆ20% stepsï¼‰ï¼šå•è½®ç®€å•å¯¹è¯
- **é˜¶æ®µ 2**ï¼ˆ40% stepsï¼‰ï¼šå¤šè½®å¯¹è¯ï¼Œæ— å¤æ‚æ¨ç†
- **é˜¶æ®µ 3**ï¼ˆ40% stepsï¼‰ï¼šå®Œæ•´æ•°æ®é›†ï¼ŒåŒ…å«å¤æ‚ä»»åŠ¡

**2. åŠ¨æ€é‡‡æ ·**

æ ¹æ®æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°åŠ¨æ€è°ƒæ•´æ•°æ®åˆ†å¸ƒï¼š

```python
def dynamic_sampling_weight(category_loss):
    """æŸå¤±è¶Šå¤§çš„ç±»åˆ«ï¼Œé‡‡æ ·æƒé‡è¶Šé«˜"""
    weights = np.exp(category_loss / temperature)
    return weights / weights.sum()
```

**3. æ£€æŸ¥ç‚¹ç­–ç•¥**

- æ¯ 1000 æ­¥ä¿å­˜æ£€æŸ¥ç‚¹
- ä¿ç•™éªŒè¯é›† loss æœ€ä½çš„ 5 ä¸ªæ£€æŸ¥ç‚¹
- æœ€ç»ˆæ¨¡å‹ = top-3 æ£€æŸ¥ç‚¹çš„å¹³å‡

#### è®­ç»ƒç›‘æ§

å®æ—¶ç›‘æ§çš„å…³é”®æŒ‡æ ‡ï¼š

1. **è®­ç»ƒæŒ‡æ ‡**
   - Loss æ›²çº¿ï¼ˆå¹³æ»‘çª—å£=100ï¼‰
   - æ¢¯åº¦èŒƒæ•°
   - å­¦ä¹ ç‡è°ƒåº¦
   - GPU åˆ©ç”¨ç‡

2. **éªŒè¯æŒ‡æ ‡**
   - Perplexity
   - BLEU-4 åˆ†æ•°
   - å“åº”å¤šæ ·æ€§ï¼ˆDistinct-1/2ï¼‰
   - å®‰å…¨æ€§è¯„åˆ†

3. **åœ¨çº¿æŒ‡æ ‡**ï¼ˆA/B æµ‹è¯•ï¼‰
   - ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ†
   - å¯¹è¯è½®æ¬¡
   - ä¼šè¯å®Œæˆç‡
   - å“åº”æ—¶é—´ï¼ˆP50/P95/P99ï¼‰

### 10.1.4 RLHF ä¼˜åŒ–æµç¨‹

#### å¥–åŠ±æ¨¡å‹è®­ç»ƒ

**æ•°æ®æ”¶é›†**ï¼š

1. **åå¥½æ ‡æ³¨**ï¼ˆ50K å¯¹ï¼‰
   - å¯¹äºåŒä¸€ promptï¼Œç”Ÿæˆ 4-8 ä¸ªå“åº”
   - 3 åæ ‡æ³¨å‘˜ç‹¬ç«‹æ’åº
   - Bradley-Terry æ¨¡å‹èšåˆåå¥½

2. **æ ‡æ³¨è´¨é‡æ§åˆ¶**
   - æ ‡æ³¨å‘˜ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆFleiss' Kappa > 0.6ï¼‰
   - é»„é‡‘æ ‡å‡†æµ‹è¯•ï¼ˆå‡†ç¡®ç‡ > 85%ï¼‰
   - å¼‚å¸¸æ ‡æ³¨è‡ªåŠ¨æ£€æµ‹

**æ¨¡å‹æ¶æ„**ï¼š

```
è¾“å…¥ â†’ Encoder â†’ [CLS] token â†’ Linear â†’ Scalar Reward
         â†“
    å…±äº« SFT æ¨¡å‹å‚æ•°ï¼ˆå†»ç»“å‰ N-2 å±‚ï¼‰
```

**è®­ç»ƒæŠ€å·§**ï¼š

- ä½¿ç”¨ Focal Loss å¤„ç†åå¥½å¼ºåº¦ä¸å¹³è¡¡
- åŠ å…¥ KL æ­£åˆ™åŒ–é˜²æ­¢å¥–åŠ± hacking
- å¤šä»»åŠ¡å­¦ä¹ ï¼šåŒæ—¶é¢„æµ‹åå¥½å’Œå“åº”è´¨é‡

#### PPO è®­ç»ƒ

**PPO é…ç½®**ï¼š

```yaml
ppo_config:
  kl_penalty: 0.1
  clip_range: 0.2
  value_loss_coef: 0.5
  entropy_coef: 0.01
  
  # é‡‡æ ·ç­–ç•¥
  rollout_batch_size: 512
  minibatch_size: 64
  ppo_epochs: 4
  
  # å¥–åŠ±è®¾è®¡
  reward_components:
    preference_score: 0.6
    kl_penalty: 0.2
    length_penalty: 0.1
    safety_score: 0.1
```

**å…³é”®ä¼˜åŒ–**ï¼š

1. **å¥–åŠ±å½’ä¸€åŒ–**
   ```python
   rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)
   ```

2. **KL æ•£åº¦è‡ªé€‚åº”**
   ```python
   if kl_divergence > target_kl * 1.5:
       kl_coef *= 1.5
   elif kl_divergence < target_kl * 0.5:
       kl_coef *= 0.7
   ```

3. **æ—©åœç­–ç•¥**
   - éªŒè¯é›†å¥–åŠ±ä¸å†æå‡
   - KL æ•£åº¦è¶…è¿‡é˜ˆå€¼
   - å“åº”å¤šæ ·æ€§æ˜¾è‘—ä¸‹é™

ğŸ“Œ **é‡è¦å‘ç°**ï¼šPPO è®­ç»ƒä¸­ï¼Œä¿æŒ KL æ•£åº¦åœ¨ 1-3 ä¹‹é—´é€šå¸¸èƒ½è·å¾—æœ€ä½³çš„èƒ½åŠ›-å¯¹é½å¹³è¡¡ã€‚

### 10.1.5 å®‰å…¨æ€§ä¸å¯¹é½

#### å¤šå±‚å®‰å…¨é˜²æŠ¤

```
è¾“å…¥å®‰å…¨æ£€æŸ¥ â†’ ç”Ÿæˆè¿‡ç¨‹å¹²é¢„ â†’ è¾“å‡ºå®‰å…¨è¿‡æ»¤ â†’ äººå·¥å®¡æ ¸ï¼ˆé‡‡æ ·ï¼‰
      â†“              â†“               â†“              â†“
  æ•æ„Ÿè¯è¿‡æ»¤    å®‰å…¨å¼•å¯¼ç”Ÿæˆ     æ¯’æ€§æ£€æµ‹      å¼‚å¸¸ä¸ŠæŠ¥
```

#### Constitutional AI å®ç°

è‡ªæˆ‘æ‰¹è¯„å’Œæ”¹è¿›å¾ªç¯ï¼š

1. **åˆå§‹å“åº”ç”Ÿæˆ**
2. **è‡ªæˆ‘æ‰¹è¯„**ï¼š"è¿™ä¸ªå›ç­”æ˜¯å¦å¯èƒ½é€ æˆä¼¤å®³ï¼Ÿ"
3. **ä¿®è®¢ç”Ÿæˆ**ï¼š"è¯·ä¿®æ”¹å›ç­”ï¼Œä½¿å…¶æ›´åŠ æœ‰å¸®åŠ©ä¸”æ— å®³"
4. **æœ€ç»ˆæ£€æŸ¥**ï¼šå¤–éƒ¨å®‰å…¨åˆ†ç±»å™¨éªŒè¯

#### çº¢é˜Ÿæµ‹è¯•

ç³»ç»ŸåŒ–çš„å¯¹æŠ—æµ‹è¯•ï¼š

- **è‡ªåŠ¨åŒ–æ”»å‡»**ï¼šä½¿ç”¨å¯¹æŠ—æ ·æœ¬ç”Ÿæˆå™¨
- **äººå·¥çº¢é˜Ÿ**ï¼šå®‰å…¨ä¸“å®¶å®šæœŸæµ‹è¯•
- **ä¼—åŒ…æµ‹è¯•**ï¼šä»˜è´¹ç”¨æˆ·å°è¯•"è¶Šç‹±"
- **æŒç»­ç›‘æ§**ï¼šç”Ÿäº§ç¯å¢ƒå¼‚å¸¸æ£€æµ‹

### 10.1.6 éƒ¨ç½²ä¸ç›‘æ§

#### æœåŠ¡æ¶æ„

```
         è´Ÿè½½å‡è¡¡å™¨
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                   â†“
æ¨ç†æœåŠ¡å™¨é›†ç¾¤      ç¼“å­˜å±‚(Redis)
    â†“                   â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
         æ¨¡å‹æœåŠ¡
    (TorchServe/Triton)
```

#### æ€§èƒ½ä¼˜åŒ–

1. **æ¨¡å‹ä¼˜åŒ–**
   - INT8 é‡åŒ–ï¼ˆç²¾åº¦æŸå¤± < 1%ï¼‰
   - Flash Attention
   - KV Cache ä¼˜åŒ–
   - åŠ¨æ€ batching

2. **ç³»ç»Ÿä¼˜åŒ–**
   - è¯·æ±‚çº§å¹¶å‘æ§åˆ¶
   - è‡ªé€‚åº”è¶…æ—¶è®¾ç½®
   - é¢„æµ‹æ€§é¢„åŠ è½½
   - ç»“æœç¼“å­˜ï¼ˆç›¸ä¼¼ queryï¼‰

#### ç›‘æ§æŒ‡æ ‡ä½“ç³»

**ä¸šåŠ¡æŒ‡æ ‡**ï¼š
- DAU/MAU
- å¹³å‡å¯¹è¯è½®æ¬¡
- ç”¨æˆ·æ»¡æ„åº¦ NPS
- ç•™å­˜ç‡

**æŠ€æœ¯æŒ‡æ ‡**ï¼š
- QPS/TPS
- å»¶è¿Ÿåˆ†å¸ƒï¼ˆP50/P95/P99ï¼‰
- é”™è¯¯ç‡
- GPU åˆ©ç”¨ç‡

**è´¨é‡æŒ‡æ ‡**ï¼š
- å“åº”ç›¸å…³æ€§ï¼ˆåœ¨çº¿è¯„ä¼°ï¼‰
- å®‰å…¨è¿è§„ç‡
- å¹»è§‰æ£€æµ‹ç‡
- A/B æµ‹è¯•èƒœç‡

#### æ•…éšœæ¢å¤

- **æ¨¡å‹å›æ»š**ï¼šä¿ç•™æœ€è¿‘ 3 ä¸ªç¨³å®šç‰ˆæœ¬
- **é™çº§ç­–ç•¥**ï¼šé«˜è´Ÿè½½æ—¶åˆ‡æ¢åˆ°å°æ¨¡å‹
- **ç†”æ–­æœºåˆ¶**ï¼šå¼‚å¸¸è¯·æ±‚è‡ªåŠ¨éš”ç¦»
- **ç¾å¤‡æ–¹æ¡ˆ**ï¼šå¤šåœ°åŸŸéƒ¨ç½²

## 10.2 å¤šæ¨¡æ€åŠ©æ‰‹çš„è®­ç»ƒæµç¨‹

å¤šæ¨¡æ€å¤§æ¨¡å‹çš„è®­ç»ƒæ¯”çº¯æ–‡æœ¬æ¨¡å‹å¤æ‚å¾—å¤šï¼Œéœ€è¦å¤„ç†ä¸åŒæ¨¡æ€é—´çš„å¯¹é½ã€èåˆå’ŒååŒã€‚æœ¬èŠ‚ä»‹ç»ä¸€ä¸ªæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€è¯­éŸ³çš„å¤šæ¨¡æ€åŠ©æ‰‹é¡¹ç›®ï¼Œè¯¥ç³»ç»Ÿåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ° SOTA æ€§èƒ½ã€‚

### 10.2.1 æ¨¡æ€èåˆæ¶æ„

#### æ¶æ„è®¾è®¡åŸåˆ™

1. **æ—©æœŸèåˆ vs æ™šæœŸèåˆ**

æˆ‘ä»¬é‡‡ç”¨æ··åˆèåˆç­–ç•¥ï¼š
- **æ—©æœŸèåˆ**ï¼šä½å±‚ç‰¹å¾é€šè¿‡ cross-attention äº¤äº’
- **æ™šæœŸèåˆ**ï¼šé«˜å±‚è¯­ä¹‰é€šè¿‡ gated fusion ç»“åˆ

```
è§†è§‰ç¼–ç å™¨ â”€â”€â”
            â”œâ†’ Cross-Attention â†’ Transformer Layers â†’ Gated Fusion â†’ è¾“å‡º
æ–‡æœ¬ç¼–ç å™¨ â”€â”€â”˜                         â†‘
                                    è¯­éŸ³ç¼–ç å™¨
```

2. **æ¨¡æ€å¯¹é½å±‚è®¾è®¡**

```python
class ModalityAligner(nn.Module):
    def __init__(self, visual_dim, text_dim, audio_dim, hidden_dim):
        super().__init__()
        # æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦
        self.visual_proj = nn.Linear(visual_dim, hidden_dim)
        self.text_proj = nn.Linear(text_dim, hidden_dim)
        self.audio_proj = nn.Linear(audio_dim, hidden_dim)
        
        # å¯å­¦ä¹ çš„æ¨¡æ€ embedding
        self.modality_embeddings = nn.Parameter(
            torch.randn(3, hidden_dim)
        )
        
    def forward(self, visual=None, text=None, audio=None):
        features = []
        if visual is not None:
            features.append(self.visual_proj(visual) + self.modality_embeddings[0])
        if text is not None:
            features.append(self.text_proj(text) + self.modality_embeddings[1])
        if audio is not None:
            features.append(self.audio_proj(audio) + self.modality_embeddings[2])
        return torch.cat(features, dim=1)
```

#### è§†è§‰ç¼–ç å™¨é€‰æ‹©

å¯¹æ¯”å®éªŒç»“æœï¼š

| ç¼–ç å™¨ | å‚æ•°é‡ | å›¾åƒç†è§£ | è®­ç»ƒé€Ÿåº¦ | å†…å­˜å ç”¨ |
|--------|--------|----------|----------|----------|
| CLIP ViT-L | 428M | 85.2% | 1.0x | 16GB |
| EVA-CLIP | 1B | 87.8% | 0.6x | 24GB |
| SigLIP | 400M | 86.5% | 1.2x | 14GB |
| DINOv2 | 1.1B | 88.1% | 0.5x | 28GB |

æœ€ç»ˆé€‰æ‹©ï¼šSigLIPï¼ˆæ€§èƒ½-æ•ˆç‡å¹³è¡¡æœ€ä¼˜ï¼‰

### 10.2.2 æ•°æ®å¯¹é½ç­–ç•¥

#### å¤šæ¨¡æ€æ•°æ®æ”¶é›†

1. **å›¾æ–‡å¯¹æ•°æ®**ï¼ˆ5M pairsï¼‰
   - LAION-5B ç­›é€‰ï¼ˆç¾å­¦åˆ†æ•° > 6ï¼‰
   - CC12M é«˜è´¨é‡å­é›†
   - å†…éƒ¨æ ‡æ³¨æ•°æ®ï¼ˆ100Kï¼‰

2. **è§†é¢‘-æ–‡æœ¬æ•°æ®**ï¼ˆ1M clipsï¼‰
   - WebVid-10M é‡‡æ ·
   - è‡ªåŠ¨å­—å¹•ç”Ÿæˆ + äººå·¥æ ¡éªŒ

3. **è¯­éŸ³-æ–‡æœ¬æ•°æ®**ï¼ˆ2M hoursï¼‰
   - LibriSpeech + CommonVoice
   - å¤šè¯­è¨€ã€å¤šå£éŸ³è¦†ç›–

#### æ•°æ®é¢„å¤„ç†ç®¡é“

**å›¾åƒå¤„ç†**ï¼š
```python
transform = Compose([
    RandomResizedCrop(224, scale=(0.8, 1.0)),
    RandomHorizontalFlip(p=0.5),
    ColorJitter(brightness=0.4, contrast=0.4),
    ToTensor(),
    Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
])
```

**æ–‡æœ¬å¢å¼º**ï¼š
- æ¨¡æ¿å˜æ¢ï¼šåŒä¸€è¯­ä¹‰çš„å¤šç§è¡¨è¾¾
- åå‘ç¿»è¯‘ï¼šè‹±â†’ä¸­â†’è‹± å¢åŠ å¤šæ ·æ€§
- æŒ‡ä»¤æ”¹å†™ï¼šå°†é™ˆè¿°å¥æ”¹ä¸ºæŒ‡ä»¤æ ¼å¼

**æ—¶åºå¯¹é½**ï¼š
```
è§†é¢‘å¸§é‡‡æ ·ç­–ç•¥ï¼š
- å‡åŒ€é‡‡æ ·ï¼šæ¯ç§’ 1 å¸§
- å…³é”®å¸§é‡‡æ ·ï¼šåœºæ™¯å˜åŒ–æ£€æµ‹
- å¯†é›†é‡‡æ ·ï¼šåŠ¨ä½œè¯†åˆ«ä»»åŠ¡ï¼ˆ8 fpsï¼‰
```

### 10.2.3 æ¸è¿›å¼è®­ç»ƒ

#### ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥

**é˜¶æ®µ 1ï¼šæ¨¡æ€å¯¹é½é¢„è®­ç»ƒ**ï¼ˆ100K stepsï¼‰

ç›®æ ‡ï¼šå­¦ä¹ ä¸åŒæ¨¡æ€çš„ç»Ÿä¸€è¡¨ç¤º

```yaml
stage1_config:
  frozen_modules: ["text_encoder", "visual_encoder"]
  trainable: ["projection_layers", "alignment_modules"]
  learning_rate: 1e-4
  tasks:
    - image_text_matching: 0.3
    - masked_language_modeling: 0.3
    - image_text_contrastive: 0.4
```

**é˜¶æ®µ 2ï¼šå¤šæ¨¡æ€ç†è§£è®­ç»ƒ**ï¼ˆ200K stepsï¼‰

ç›®æ ‡ï¼šè·¨æ¨¡æ€æ¨ç†èƒ½åŠ›

```yaml
stage2_config:
  frozen_modules: ["visual_encoder.layers[:-2]"]
  learning_rate: 5e-5
  tasks:
    - visual_question_answering: 0.25
    - image_captioning: 0.25
    - visual_reasoning: 0.25
    - audio_understanding: 0.25
```

**é˜¶æ®µ 3ï¼šæŒ‡ä»¤å¾®è°ƒ**ï¼ˆ50K stepsï¼‰

ç›®æ ‡ï¼šéµå¾ªå¤šæ¨¡æ€æŒ‡ä»¤

è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼š
- çº¯æ–‡æœ¬æŒ‡ä»¤ï¼š30%
- å›¾åƒç›¸å…³æŒ‡ä»¤ï¼š40%
- éŸ³é¢‘ç›¸å…³æŒ‡ä»¤ï¼š20%
- æ··åˆæ¨¡æ€æŒ‡ä»¤ï¼š10%

ğŸ’¡ **å…³é”®å‘ç°**ï¼šåœ¨é˜¶æ®µ 2 åŠ å…¥ 10% çš„çº¯æ–‡æœ¬æ•°æ®å¯ä»¥æœ‰æ•ˆé˜²æ­¢è¯­è¨€èƒ½åŠ›é€€åŒ–ã€‚

### 10.2.4 è·¨æ¨¡æ€èƒ½åŠ›è¯„ä¼°

#### è¯„ä¼°åŸºå‡†è®¾è®¡

1. **å•æ¨¡æ€åŸºå‡†**
   - æ–‡æœ¬ï¼šMMLU, HellaSwag, ARC
   - å›¾åƒï¼šImageNet, COCO Detection
   - éŸ³é¢‘ï¼šLibriSpeech WER

2. **è·¨æ¨¡æ€åŸºå‡†**
   - VQA v2ï¼šè§†è§‰é—®ç­”
   - NLVR2ï¼šè§†è§‰æ¨ç†
   - Flickr30Kï¼šå›¾æ–‡æ£€ç´¢
   - AVSDï¼šéŸ³è§†é¢‘å¯¹è¯

3. **è‡ªå»ºè¯„ä¼°é›†**
   - å¤šè·³æ¨ç†ï¼šéœ€è¦ç»“åˆå¤šä¸ªæ¨¡æ€ä¿¡æ¯
   - æŒ‡ä»¤æ³›åŒ–ï¼šæœªè§è¿‡çš„æŒ‡ä»¤ç»„åˆ
   - é²æ£’æ€§æµ‹è¯•ï¼šå¯¹æŠ—æ ·æœ¬ã€å™ªå£°è¾“å…¥

#### è¯„ä¼°æŒ‡æ ‡ä½“ç³»

```python
class MultiModalEvaluator:
    def __init__(self):
        self.metrics = {
            'accuracy': AccuracyMetric(),
            'bleu': BLEUMetric(),
            'clip_score': CLIPScoreMetric(),
            'perplexity': PerplexityMetric()
        }
    
    def evaluate(self, predictions, references, modalities):
        results = {}
        for modality in modalities:
            modal_preds = predictions[modality]
            modal_refs = references[modality]
            
            if modality == 'text':
                results[f'{modality}_bleu'] = self.metrics['bleu'](modal_preds, modal_refs)
                results[f'{modality}_ppl'] = self.metrics['perplexity'](modal_preds)
            elif modality == 'vision':
                results[f'{modality}_acc'] = self.metrics['accuracy'](modal_preds, modal_refs)
                results[f'{modality}_clip'] = self.metrics['clip_score'](modal_preds, modal_refs)
                
        # è·¨æ¨¡æ€ä¸€è‡´æ€§
        results['cross_modal_alignment'] = self.compute_alignment(predictions)
        return results
```

### 10.2.5 æ¨ç†ä¼˜åŒ–

#### æ¨¡æ€çº§ä¼˜åŒ–

1. **åŠ¨æ€æ¨¡æ€é€‰æ‹©**

æ ¹æ®è¾“å…¥è‡ªåŠ¨åˆ¤æ–­éœ€è¦æ¿€æ´»çš„ç¼–ç å™¨ï¼š

```python
def dynamic_forward(self, inputs):
    active_encoders = []
    if inputs.get('image') is not None:
        active_encoders.append(self.visual_encoder)
    if inputs.get('audio') is not None:
        active_encoders.append(self.audio_encoder)
    
    # åªè®¡ç®—å¿…è¦çš„ç¼–ç å™¨
    features = [enc(inp) for enc, inp in zip(active_encoders, inputs.values())]
    return self.fusion_layer(features)
```

2. **ç¼“å­˜ç­–ç•¥**

- **KV Cache**ï¼šæ ‡å‡† Transformer ç¼“å­˜
- **Visual Cache**ï¼šç›¸ä¼¼å›¾åƒçš„ç‰¹å¾å¤ç”¨
- **Instruction Cache**ï¼šå¸¸è§æŒ‡ä»¤çš„é¢„è®¡ç®—

3. **é‡åŒ–æ–¹æ¡ˆ**

ä¸åŒæ¨¡å—é‡‡ç”¨ä¸åŒé‡åŒ–ç­–ç•¥ï¼š

| æ¨¡å— | é‡åŒ–æ–¹æ³• | ç²¾åº¦æŸå¤± |
|------|----------|----------|
| è§†è§‰ç¼–ç å™¨ | INT8 åŠ¨æ€é‡åŒ– | < 0.5% |
| æ–‡æœ¬ç¼–ç å™¨ | FP16 | < 0.1% |
| èåˆå±‚ | INT8 é™æ€é‡åŒ– | < 1% |
| è¾“å‡ºå±‚ | FP32ï¼ˆä¸é‡åŒ–ï¼‰ | 0% |

#### æœåŠ¡åŒ–éƒ¨ç½²

```yaml
deployment_config:
  model_parallel: 2  # æ¨¡å‹å¹¶è¡Œåº¦
  data_parallel: 4   # æ•°æ®å¹¶è¡Œåº¦
  
  serving:
    max_batch_size: 32
    dynamic_batching: true
    timeout_ms: 5000
    
  optimization:
    use_flash_attention: true
    use_xformers: true
    compile_mode: "reduce-overhead"
```

âš ï¸ **éƒ¨ç½²é™·é˜±**ï¼šå¤šæ¨¡æ€æ¨¡å‹çš„ batch ç»„è£…éœ€è¦ç‰¹åˆ«æ³¨æ„ paddingï¼Œä¸åŒé•¿åº¦çš„æ–‡æœ¬å’Œä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒä¼šå¯¼è‡´å¤§é‡æ— æ•ˆè®¡ç®—ã€‚

## 10.3 é¢†åŸŸä¸“å®¶æ¨¡å‹çš„æ„å»º

é¢†åŸŸä¸“å®¶æ¨¡å‹éœ€è¦åœ¨ä¿æŒé€šç”¨èƒ½åŠ›çš„åŒæ—¶ï¼Œæ·±åº¦æŒæ¡ç‰¹å®šé¢†åŸŸçŸ¥è¯†ã€‚æœ¬èŠ‚ä»¥åŒ»ç–—é¢†åŸŸä¸ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•æ„å»ºä¸€ä¸ªæ—¢æ‡‚åŒ»å­¦çŸ¥è¯†åˆèƒ½è‡ªç„¶äº¤äº’çš„ä¸“å®¶åŠ©æ‰‹ã€‚

### 10.3.1 é¢†åŸŸçŸ¥è¯†æ³¨å…¥

#### çŸ¥è¯†æ¥æºä¸è´¨é‡æ§åˆ¶

**1. æƒå¨æ•°æ®æº**

- **åŒ»å­¦æ•™ç§‘ä¹¦**ï¼š200+ æœ¬æ ‡å‡†æ•™æ
- **ä¸´åºŠæŒ‡å—**ï¼šWHOã€CDC ç­‰æƒå¨æŒ‡å—
- **åŒ»å­¦æ–‡çŒ®**ï¼šPubMed è¿‘ 10 å¹´é«˜å¼•è®ºæ–‡
- **ç—…ä¾‹æ•°æ®**ï¼šè„±æ•çš„çœŸå®ç—…ä¾‹ï¼ˆ50K+ï¼‰
- **åŒ»å­¦ç™¾ç§‘**ï¼šMedlinePlusã€UpToDate

**2. çŸ¥è¯†å›¾è°±æ„å»º**

```
ç–¾ç—…å®ä½“ â”€â”€[ç—‡çŠ¶å…³ç³»]â”€â”€> ç—‡çŠ¶å®ä½“
    â†“                        â†‘
[æ²»ç–—å…³ç³»]              [æ£€æŸ¥å…³ç³»]
    â†“                        â†‘
è¯ç‰©å®ä½“ â†â”€â”€[ç›¸äº’ä½œç”¨]â”€â”€â†’ æ£€æŸ¥å®ä½“
```

çŸ¥è¯†ä¸‰å…ƒç»„ç¤ºä¾‹ï¼š
```python
knowledge_triples = [
    ("ç³–å°¿ç—…", "å¸¸è§ç—‡çŠ¶", "å¤šé¥®å¤šå°¿"),
    ("äºŒç”²åŒèƒ", "æ²»ç–—", "2å‹ç³–å°¿ç—…"),
    ("äºŒç”²åŒèƒ", "ç¦å¿Œç—‡", "è‚¾åŠŸèƒ½ä¸å…¨"),
    ("HbA1c", "è¯Šæ–­æ ‡å‡†", ">6.5%")
]
```

**3. çŸ¥è¯†éªŒè¯æµç¨‹**

```python
def validate_medical_knowledge(text, knowledge_base):
    """éªŒè¯åŒ»å­¦å†…å®¹çš„å‡†ç¡®æ€§"""
    claims = extract_medical_claims(text)
    
    for claim in claims:
        # 1. æ£€æŸ¥ä¸çŸ¥è¯†åº“çš„ä¸€è‡´æ€§
        kb_consistency = check_kb_consistency(claim, knowledge_base)
        
        # 2. äº¤å‰å¼•ç”¨éªŒè¯
        citations = find_citations(claim)
        citation_quality = evaluate_citation_quality(citations)
        
        # 3. ä¸“å®¶å®¡æ ¸æ ‡è®°
        if kb_consistency < 0.8 or citation_quality < 0.7:
            claim.mark_for_expert_review()
    
    return claims
```

#### çŸ¥è¯†æ³¨å…¥æ–¹æ³•

**1. ç»§ç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰**

åœ¨é€šç”¨æ¨¡å‹åŸºç¡€ä¸Šç»§ç»­é¢„è®­ç»ƒï¼š

```yaml
cpt_config:
  base_model: "llama-2-7b"
  learning_rate: 5e-5
  total_steps: 100000
  
  data_mixture:
    medical_textbooks: 0.3
    clinical_guidelines: 0.2
    medical_papers: 0.2
    general_corpus: 0.3  # é˜²æ­¢é—å¿˜
    
  curriculum:
    - phase: "basic"
      steps: 30000
      focus: "medical_terminology"
    - phase: "intermediate"
      steps: 40000
      focus: "disease_pathology"
    - phase: "advanced"
      steps: 30000
      focus: "clinical_reasoning"
```

**2. çŸ¥è¯†è’¸é¦**

ä»å¤§å‹åŒ»å­¦æ¨¡å‹è’¸é¦åˆ°éƒ¨ç½²è§„æ¨¡ï¼š

```python
class MedicalKnowledgeDistillation:
    def __init__(self, teacher_model, student_model):
        self.teacher = teacher_model
        self.student = student_model
        self.temp = 5.0
        
    def distillation_loss(self, inputs, alpha=0.7):
        with torch.no_grad():
            teacher_logits = self.teacher(inputs)
            
        student_logits = self.student(inputs)
        
        # KL divergence loss
        kl_loss = F.kl_div(
            F.log_softmax(student_logits / self.temp, dim=-1),
            F.softmax(teacher_logits / self.temp, dim=-1),
            reduction='batchmean'
        ) * (self.temp ** 2)
        
        # Combined with task loss
        task_loss = F.cross_entropy(student_logits, labels)
        
        return alpha * kl_loss + (1 - alpha) * task_loss
```

### 10.3.2 ä¸“ä¸šæ•°æ®é‡‡é›†

#### æ•°æ®é‡‡é›†ç­–ç•¥

**1. ä¸»åŠ¨å­¦ä¹ é‡‡æ ·**

ä¼˜å…ˆé‡‡é›†æ¨¡å‹ä¸ç¡®å®šçš„æ ·æœ¬ï¼š

```python
def uncertainty_sampling(model, unlabeled_pool, n_samples=1000):
    """åŸºäºä¸ç¡®å®šæ€§çš„ä¸»åŠ¨å­¦ä¹ """
    uncertainties = []
    
    for sample in unlabeled_pool:
        with torch.no_grad():
            logits = model(sample)
            probs = F.softmax(logits, dim=-1)
            
            # ç†µä½œä¸ºä¸ç¡®å®šæ€§åº¦é‡
            entropy = -(probs * probs.log()).sum(dim=-1)
            uncertainties.append(entropy.item())
    
    # é€‰æ‹©ä¸ç¡®å®šæ€§æœ€é«˜çš„æ ·æœ¬
    indices = np.argsort(uncertainties)[-n_samples:]
    return [unlabeled_pool[i] for i in indices]
```

**2. ä¸“å®¶æ ‡æ³¨ç³»ç»Ÿ**

åˆ†çº§æ ‡æ³¨æµç¨‹ï¼š

```
åˆçº§æ ‡æ³¨å‘˜ï¼ˆåŒ»å­¦ç”Ÿï¼‰
    â†“ [åŸºç¡€æ ‡æ³¨]
è´¨é‡æ£€æŸ¥ç‚¹ 1
    â†“ [é€šè¿‡ç‡ > 90%]
ä¸­çº§å®¡æ ¸å‘˜ï¼ˆä½é™¢åŒ»å¸ˆï¼‰
    â†“ [ä¸´åºŠéªŒè¯]
è´¨é‡æ£€æŸ¥ç‚¹ 2
    â†“ [åˆ†æ­§æ¡ˆä¾‹]
é«˜çº§ä¸“å®¶ï¼ˆä¸»æ²»åŒ»å¸ˆï¼‰
    â†“ [æœ€ç»ˆç¡®è®¤]
å…¥åº“
```

**3. åˆæˆæ•°æ®ç”Ÿæˆ**

åŸºäºæ¨¡æ¿çš„ç—…ä¾‹ç”Ÿæˆï¼š

```python
def generate_synthetic_cases(templates, knowledge_base, n_cases=10000):
    """ç”Ÿæˆåˆæˆç—…ä¾‹æ•°æ®"""
    cases = []
    
    for _ in range(n_cases):
        template = random.choice(templates)
        
        # å¡«å……ç–¾ç—…ä¿¡æ¯
        disease = sample_disease(knowledge_base)
        symptoms = get_symptoms(disease, knowledge_base)
        treatments = get_treatments(disease, knowledge_base)
        
        # ç”Ÿæˆç—…ä¾‹æè¿°
        case = template.format(
            age=random.randint(20, 80),
            gender=random.choice(['ç”·', 'å¥³']),
            symptoms=', '.join(symptoms[:3]),
            duration=random.randint(1, 30),
            diagnosis=disease,
            treatment=treatments[0]
        )
        
        cases.append(case)
    
    return cases
```

### 10.3.3 æŒç»­å­¦ä¹ æœºåˆ¶

#### å¢é‡å­¦ä¹ æ¡†æ¶

**1. å¼¹æ€§æƒé‡å·©å›ºï¼ˆEWCï¼‰**

é˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼š

```python
class EWC:
    def __init__(self, model, dataset, importance=1000):
        self.model = model
        self.importance = importance
        self.params = {n: p.clone() for n, p in model.named_parameters()}
        self.fisher = self._compute_fisher(dataset)
    
    def _compute_fisher(self, dataset):
        """è®¡ç®— Fisher ä¿¡æ¯çŸ©é˜µ"""
        fisher = {}
        model.eval()
        
        for data in dataset:
            model.zero_grad()
            output = model(data)
            loss = F.cross_entropy(output, data.labels)
            loss.backward()
            
            for n, p in model.named_parameters():
                if n not in fisher:
                    fisher[n] = p.grad.data.clone() ** 2
                else:
                    fisher[n] += p.grad.data.clone() ** 2
        
        for n in fisher:
            fisher[n] /= len(dataset)
            
        return fisher
    
    def penalty(self):
        """è®¡ç®— EWC æƒ©ç½šé¡¹"""
        loss = 0
        for n, p in self.model.named_parameters():
            if n in self.fisher:
                loss += (self.fisher[n] * (p - self.params[n]) ** 2).sum()
        return self.importance * loss
```

**2. çŸ¥è¯†é‡æ”¾æœºåˆ¶**

```python
class ExperienceReplay:
    def __init__(self, buffer_size=10000):
        self.buffer = deque(maxlen=buffer_size)
        self.priorities = deque(maxlen=buffer_size)
    
    def add(self, experience, priority=1.0):
        self.buffer.append(experience)
        self.priorities.append(priority)
    
    def sample(self, batch_size, alpha=0.6):
        """ä¼˜å…ˆçº§é‡‡æ ·"""
        probs = np.array(self.priorities) ** alpha
        probs /= probs.sum()
        
        indices = np.random.choice(
            len(self.buffer), 
            batch_size, 
            p=probs
        )
        
        return [self.buffer[i] for i in indices]
```

### 10.3.4 æ€§èƒ½åŸºå‡†è®¾è®¡

#### åŒ»ç–—é¢†åŸŸè¯„ä¼°åŸºå‡†

**1. çŸ¥è¯†å‡†ç¡®æ€§æµ‹è¯•**

- **MedQA**ï¼šåŒ»å­¦è€ƒè¯•é¢˜ï¼ˆUSMLE styleï¼‰
- **PubMedQA**ï¼šåŸºäºæ–‡çŒ®çš„é—®ç­”
- **MedMCQA**ï¼šå¤šé€‰é¢˜åŒ»å­¦çŸ¥è¯†

**2. ä¸´åºŠæ¨ç†èƒ½åŠ›**

```python
def evaluate_clinical_reasoning(model, test_cases):
    """è¯„ä¼°ä¸´åºŠæ¨ç†èƒ½åŠ›"""
    metrics = {
        'diagnosis_accuracy': 0,
        'treatment_appropriateness': 0,
        'safety_score': 0
    }
    
    for case in test_cases:
        # ç”Ÿæˆè¯Šæ–­
        diagnosis = model.generate_diagnosis(case.symptoms)
        metrics['diagnosis_accuracy'] += (
            diagnosis == case.gold_diagnosis
        )
        
        # ç”Ÿæˆæ²»ç–—æ–¹æ¡ˆ
        treatment = model.suggest_treatment(diagnosis)
        metrics['treatment_appropriateness'] += evaluate_treatment(
            treatment, case.gold_treatment
        )
        
        # å®‰å…¨æ€§æ£€æŸ¥
        contraindications = check_contraindications(
            treatment, case.patient_info
        )
        metrics['safety_score'] += (len(contraindications) == 0)
    
    # å½’ä¸€åŒ–
    for key in metrics:
        metrics[key] /= len(test_cases)
    
    return metrics
```

**3. å¯¹è¯è´¨é‡è¯„ä¼°**

- ä¸“ä¸šæœ¯è¯­ä½¿ç”¨å‡†ç¡®æ€§
- è§£é‡Šçš„å¯ç†è§£æ€§
- å›ç­”çš„å®Œæ•´æ€§
- å®‰å…¨å»ºè®®çš„é€‚å½“æ€§

### 10.3.5 çŸ¥è¯†æ›´æ–°ç­–ç•¥

#### å®šæœŸæ›´æ–°æµç¨‹

**1. æ–°çŸ¥è¯†è¯†åˆ«**

```python
def identify_new_knowledge(recent_papers, existing_kb):
    """è¯†åˆ«éœ€è¦æ›´æ–°çš„çŸ¥è¯†"""
    updates = {
        'new_diseases': [],
        'updated_treatments': [],
        'revised_guidelines': []
    }
    
    for paper in recent_papers:
        entities = extract_medical_entities(paper)
        
        for entity in entities:
            if entity.type == 'disease' and entity not in existing_kb:
                updates['new_diseases'].append(entity)
            elif entity.type == 'treatment':
                if has_significant_change(entity, existing_kb):
                    updates['updated_treatments'].append(entity)
    
    return updates
```

**2. å¢é‡è®­ç»ƒç®¡é“**

```yaml
update_pipeline:
  frequency: "monthly"
  
  steps:
    - name: "collect_updates"
      sources: ["pubmed", "clinical_trials", "fda_approvals"]
      
    - name: "validate_updates"
      validators: ["expert_review", "consistency_check"]
      
    - name: "prepare_training_data"
      augmentation: true
      balance_with_existing: 0.3
      
    - name: "incremental_training"
      method: "ewc"
      epochs: 5
      learning_rate: 1e-5
      
    - name: "evaluation"
      benchmarks: ["medqa", "safety_tests"]
      threshold: 0.95  # ç›¸å¯¹äºå‰ç‰ˆæœ¬
      
    - name: "deployment"
      strategy: "gradual_rollout"
      monitoring_period: "7d"
```

ğŸ“Œ **å…³é”®ç»éªŒ**ï¼šåŒ»ç–—é¢†åŸŸæ¨¡å‹æ›´æ–°æ—¶ï¼Œå®å¯ä¿å®ˆä¹Ÿä¸èƒ½å¼•å…¥é”™è¯¯ä¿¡æ¯ã€‚æ¯æ¬¡æ›´æ–°éƒ½éœ€è¦å®Œæ•´çš„å›å½’æµ‹è¯•ã€‚